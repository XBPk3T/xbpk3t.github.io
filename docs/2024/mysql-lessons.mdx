---
title: 《MySQL 45讲》读书笔记
slug: /2024/mysql-lessons
date: 2024-09-30
---




## 《MySQL 是怎样运行的：从根儿上理解 MySQL》

[《MySQL 是怎样运行的：从根儿上理解 MySQL》](https://relph1119.github.io/mysql-learning-notes/#/)

[Relph1119/mysql-learning-notes: MySQL学习《MySQL 是怎样运行的：从根儿上理解 MySQL》，在线阅读：https://relph1119.github.io/mysql-learning-notes/](https://github.com/Relph1119/mysql-learning-notes)




### x

```markdown
截止到服务器程序完成了查询优化为止，还没有真正的去访问真实的数据表，MySQL服务器把数据的存储和提取操作都封装到了一个叫存储引擎的模块里。我们知道表是由一行一行的记录组成的，但这只是一个逻辑上的概念，物理上如何表示记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上，这都是存储引擎负责的事情。为了实现不同的功能，MySQL提供了各式各样的存储引擎，不同存储引擎管理的表具体的存储结构可能不同，采用的存取算法也可能不同。

小贴士：为什么叫`引擎`呢？因为这个名字更拉风～ 其实这个存储引擎以前叫做`表处理器`，后来可能人们觉得太土，就改成了`存储引擎`的叫法，它的功能就是接收上层传下来的指令，然后对表中的数据进行提取或写入操作。

```

“表处理器”其实更直白地说明了storage engine的本质（正如docker的cgroup原本的名称 process container这么直白的说明了“docker容器的本质是进程”），其实就是用来存放数据的东西。只不过因为数据类型不同（数据量大小、冷热、读写操作频率等），所以就需要不同的storage engine来满足其需求（***数据在不同SE中存放的格式通常是不同的，比如说memory都不用磁盘来存储数据，也就是说关闭服务器后表中的数据就消失了。再想想myisam和innodb的区别，index什么的。***）。

还是拿图书馆类比，mysql server的所有处理过程其实都与书架上的书籍无关（“没有访问到真实的数据表”）。





### 4、InnoDB 数据页结构 & 记录结构

[4、从一条记录说起—— InnoDB 记录结构 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/81.html)

[5、盛放记录的大盒子 —— InnoDB 数据页结构 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/82.html)

---


![innodb-table-space.webp](img/mysql-lessons/innodb-table-space.webp)


InnoDB有4种行格式，分别是 compact, redundant, dynamic, compressed.


---

![innodb-page.webp](img/mysql-lessons/innodb-page.webp)

```markdown
一个数据页可以被大致划分为7个部分，分别是

File Header，表示页的一些通用信息，占固定的38字节。
Page Header，表示数据页专有的一些信息，占固定的56个字节。
Infimum + Supremum，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的26个字节。
User Records：真实存储我们插入的记录的部分，大小不固定。
Free Space：页中尚未使用的部分，大小不确定。
Page Directory：页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插入的记录越多，这个部分占用的空间越多。
File Trailer：用于检验页是否完整的部分，占用固定的8个字节。
```

这里就是innodb page的数据结构


---

```markdown
4、InnoDB会把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个槽，存放在Page Directory中，所以在一个页中根据主键查找记录是非常快的，分为两步：

	1、通过二分法确定该记录所在的槽。

	2、通过记录的next_record属性遍历该槽所在的组中的各个记录。

5、每个数据页的File Header部分都有上一个和下一个页的编号，所以所有的数据页会组成一个双链表。

6、为保证从内存中同步到磁盘的页的完整性，在页的首部和尾部都会存储页中数据的校验和和页面最后修改时对应的LSN值，如果首部和尾部的校验和和LSN值校验不成功的话，就说明同步过程出现了问题。
```

page directory, page header, file header, file trailer
















:::danger


```yaml
- "*InnoDB, arch? InnoDB数据页的数据结构? How does it works?*"
- innodb 行格式 有哪4种?
- innodb page由哪7个部分组成?


```


各个数据页可以组成一个 双向链表 ，而每个数据页中的记录会按照主键值从小到大的顺序组成一个 单向链表，每个数据页都会为存储在它里边儿的记录生成一个页目录 ，在通过主键查找某条记录的时候可以在 页目录 中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录(如果你对这段话有一丁点儿疑惑，那么接下来的部分不适合你，返回去看一下数据页结构吧)。

通过双向链表相关联

---

所有类型的page（11种page类型）都有 file header和 file trailer两部分

```markdown
File Header：记录页面的一些通用信息

File Trailer：校验页是否完整，保证从内存到磁盘刷新时内容的一致性。
```





:::





### 9、存放页面的大池子 —— InnoDB 的表空间

[9、存放页面的大池子 —— InnoDB 的表空间 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/86.html)

---

```markdown
通过前边儿的内容大家知道，表空间是一个抽象的概念，对于系统表空间来说，对应着文件系统中一个或多个实际文件；对于每个独立表空间来说，对应着文件系统中一个名为表名.ibd的实际文件。大家可以把表空间想象成被切分为许许多多个页的池子，当我们想为某个表插入一条记录的时候，就从池子中捞出一个对应的页来把数据写进去。本章内容会深入到表空间的各个细节中，带领大家在InnoDB存储结构的池子中畅游。
```


```markdown
再一次强调，InnoDB是以页为单位管理存储空间的，我们的聚簇索引（也就是完整的表数据）和其他的二级索引都是以B+树的形式保存到表空间的，而B+树的节点就是数据页。我们前边说过，这个数据页的类型名其实是：FIL_PAGE_INDEX，除了这种存放索引数据的页面类型之外，InnoDB也为了不同的目的设计了若干种不同类型的页面，为了唤醒大家的记忆，我们再一次把各种常用的页面类型提出来：
```

***因为table space中的page太多了，为了更好地管理这些page，所以规定连续的64个page就是一个extent（也就是一个extent默认占用1MB空间）***

而256个extent划分为一组

![innodb-extent.webp](img/mysql-lessons/innodb-extent.webp)


```markdown
第一个组最开始的3个页面的类型是固定的，也就是说extent 0这个区最开始的3个页面的类型是固定的，分别是：
...

其余各组最开始的2个页面的类型是固定的，也就是说extent 256、extent 512这些区最开始的2个页面的类型是固定的，分别是：
...

好了，宏观的结构介绍完了，里边儿的名词大家也不用记清楚，只要大致记得：表空间被划分为许多连续的区，每个区默认由64个页组成，每256个区划分为一组，每个组的最开始的几个页面类型是固定的就好了。
```

---


```markdown
为啥好端端的提出一个区（extent）的概念呢？我们以前分析问题的套路都是这样的：表中的记录存储到页里边儿，然后页作为节点组成B+树，这个B+树就是索引，然后吧啦吧啦一堆聚簇索引和二级索引的区别。这套路也没啥不妥的呀～

是的，如果我们表中数据量很少的话，比如说你的表中只有几十条、几百条数据的话，的确用不到区的概念，因为简单的几个页就能把对应的数据存储起来，但是你架不住表里的记录越来越多呀。

？？啥？？表里的记录多了又怎样？B+树的每一层中的页都会形成一个双向链表呀，File Header中的FIL_PAGE_PREV和FIL_PAGE_NEXT字段不就是为了形成双向链表设置的么？

是的是的，您说的都对，从理论上说，不引入区的概念只使用页的概念对存储引擎的运行并没啥影响，但是我们来考虑一下下边这个场景：

我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+树的节点中插入数据。而B+树的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表相邻的两个页之间的物理位置可能离得非常远。我们介绍B+树索引的适用场景的时候特别提到范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了，而如果链表中相邻的两个页物理位置离得非常远，就是所谓的随机I/O。再一次强调，磁盘的速度和内存的速度差了好几个数量级，随机I/O是非常慢的，所以我们应该尽量让链表中相邻的页的物理位置也相邻，这样进行范围查询的时候才可以使用所谓的顺序I/O。

所以，所以，所以才引入了区（extent）的概念，一个区就是在物理位置上连续的64个页。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以一次性分配多个连续的区。虽然可能造成一点点空间的浪费（数据不足填充满整个区），但是从性能角度看，可以消除很多的随机I/O，功大于过嘛！
```








```markdown
XDES Entry链表
到现在为止，我们已经提出了五花八门的概念，什么区、段、碎片区、附属于段的区、XDES Entry结构吧啦吧啦的概念，走远了千万别忘了自己为什么出发，我们把事情搞这么麻烦的初心仅仅是想提高向表插入数据的效率又不至于数据量少的表浪费空间。现在我们知道向表中插入数据本质上就是向表中各个索引的叶子节点段、非叶子节点段插入数据，也知道了不同的区有不同的状态，再回到最初的起点，捋一捋向某个段中插入数据的过程：

```

“我们把事情搞这么麻烦的初心仅仅是想提高向表插入数据的效率，又不至于数据量少的表浪费空间”

[//]: # (TODO 给这个搞个qs：是怎么通过extent, segment, ... 来实现提高插入效率，又没有浪费空间的)








---


```markdown
到现在为止我们已经大概清楚了表空间、段、区、XDES Entry、INODE Entry、各种以XDES Entry为节点的链表的基本概念了，可是总有一种飞在天上不踏实的感觉，每个区对应的XDES Entry结构到底存储在表空间的什么地方？直属于表空间的FREE、FREE_FRAG、FULL_FRAG链表的基节点到底存储在表空间的什么地方？每个段对应的INODE Entry结构到底存在表空间的什么地方？我们前边介绍了每256个连续的区算是一个组，想解决刚才提出来的这些个疑问还得从每个组开头的一些类型相同的页面说起，接下来我们一个页面一个页面的分析，真相马上就要浮出水面了。
```


- 每个区对应的XDES Entry结构到底存储在表空间的什么地方？
- 直属于表空间的FREE、FREE_FRAG、FULL_FRAG链表的基节点到底存储在表空间的什么地方？
- 每个段对应的INODE Entry结构到底存在表空间的什么地方？










---


```markdown
了解完了独立表空间的基本结构，系统表空间的结构也就好理解多了，系统表空间的结构和独立表空间基本类似，只不过由于整个MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面，所以会比独立表空间多出一些记录这些信息的页面。因为这个系统表空间最牛逼，相当于是表空间之首，所以它的表空间 ID（Space ID）是0。
```

```markdown
可以看到，系统表空间和独立表空间的前三个页面（页号分别为0、1、2，类型分别是FSP_HDR、IBUF_BITMAP、INODE）的类型是一致的，只是页号为3～7的页面是系统表空间特有的，我们来看一下这些多出来的页面都是干啥使的：
```

***系统表空间和独立表空间的前三个page的type相同（分别是 FSP_HDR, IBUF_BITMAP, INODE），后面5个不同***

```markdown
除了这几个记录系统属性的页面之外，系统表空间的extent 1和extent 2这两个区，也就是页号从64~191这128个页面被称为Doublewrite buffer，也就是双写缓冲区。不过上述的大部分知识都涉及到了事务和多版本控制的问题，这些问题我们会放在后边的章节集中唠叨，现在讲述太影响用户体验，所以现在我们只唠叨一下有关InnoDB数据字典的知识，其余的概念在后边再看。
```

Doublewrite buffer





:::danger

```yaml
- mysql innodb 独立表空间 的 table space, extent, segment 分别是啥? 啥关系?
- mysql为什么需要系统表空间
- mysql 系统表空间和独立表空间 有啥区别

```





:::





### 6、快速查询的秘籍 —— B+ 树索引

[6、快速查询的秘籍 —— B+ 树索引 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/83.html) 分别介绍了没有使用索引和（Innodb中）使用索引，这两种情况下各自的查找过程，

---



```markdown
前边我们详细唠叨了InnoDB数据页的7个组成部分，知道了各个数据页可以组成一个双向链表，而每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录（如果你对这段话有一丁点儿疑惑，那么接下来的部分不适合你，返回去看一下数据页结构吧）。页和记录的关系示意图如下：
```

![innodb-page.png](img/mysql-lessons/innodb-page.png)
<center>*page之间双向链表连接*</center>


---




:::danger

```yaml
-
```


:::











### 7、好东西也得先学会怎么用-B+树索引的使用

[第7章 好东西也得先学会怎么用-B+树索引的使用](https://relph1119.github.io/mysql-learning-notes/#/mysql/07-%E5%A5%BD%E4%B8%9C%E8%A5%BF%E4%B9%9F%E5%BE%97%E5%85%88%E5%AD%A6%E4%BC%9A%E6%80%8E%E4%B9%88%E7%94%A8-B+%E6%A0%91%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8)

---


bptree index 适用情况 和 失效情况 正反都要说


```markdown
  我们前面详细、详细又详细的介绍了InnoDB存储引擎的B+树索引，我们必须熟悉下面这些结论：

每个索引都对应一棵B+树，B+树分为好多层，最下面一层是叶子节点，其余的是内节点。所有用户记录都存储在B+树的叶子节点，所有目录项记录都存储在内节点。

InnoDB存储引擎会自动为主键（如果没有它会自动帮我们添加）建立聚簇索引，聚簇索引的叶子节点包含完整的用户记录。

我们可以为自己感兴趣的列建立二级索引，二级索引的叶子节点包含的用户记录由索引列 + 主键组成，所以如果想通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引找到主键值之后再到聚簇索引中查找完整的用户记录。

B+树中每层节点都是按照索引列值从小到大的顺序排序而组成了双向链表，而且每个页内的记录（不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单链表。如果是联合索引的话，则页面和记录先按照联合索引前面的列排序，如果该列值相同，再按照联合索引后边的列排序。

通过索引查找记录是从B+树的根节点开始，一层一层向下搜索。由于每个页面都按照索引列的值建立了Page Directory（页目录），所以在这些页面中的查找非常快。
```

几个关键字，内节点 叶子结点 双向链表 page directory

再加上 innodb page结构和 记录结构


节点之间双向链表，节点内部单向链表

这怎么实现范围查询呢

单向链表 倒序查询 怎么搞

为啥不是双向




---

```markdown
时间上的代价

  每次对表中的数据进行增、删、改操作时，都需要去修改各个B+树索引。而且我们讲过，B+树每层节点都是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录（也就是不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单向链表。而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收什么的操作来维护好节点和记录的排序。如果我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作，这还能不给性能拖后腿么？
```

可以认为 内节点 是对叶子节点的一层冗余吗

![index-struct.png](img/mysql-lessons/index-struct.png)


```markdown
  为了方便大家理解，我们特意标明了哪些是内节点，哪些是叶子节点。再次强调一下，内节点中存储的是目录项记录，叶子节点中存储的是用户记录（由于不是聚簇索引，所以用户记录是不完整的，缺少country列的值）。从图中可以看出，这个idx_name_birthday_phone_number索引对应的B+树中页面和记录的排序方式就是这样的：

先按照name列的值进行排序。
如果name列的值相同，则按照birthday列的值进行排序。
如果birthday列的值也相同，则按照phone_number的值进行排序。
  这个排序方式十分、特别、非常、巨、very very very重要，因为只要页面和记录是排好序的，我们就可以通过二分法来快速定位查找。下面的内容都仰仗这个图了，大家对照着图理解。

```

索引记录是有排序的







:::danger

[//]: # (TODO index)

```yaml

- "***Index 创建原则?***"
- "***使用 mysql 索引时，可能会导致索引失效的错误用法?***"


```





---

[MySQL索引失效的常见场景 - 随心的风 - 博客园](https://www.cnblogs.com/suixing123/p/13859436.html) where使用 mysql内置函数、负向查询、or（需要注意的是，实际上指的是where使用内置函数会导致索引失效，在select子句中使用还会走索引。需要注意的是隐式转换和列运算也可归入此类）、最左原则（包括“like通配符”也可归入此类）




:::








### ***10、条条大路通罗马 —— 单表访问方法***


[10、条条大路通罗马 —— 单表访问方法 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/87.html#38j2rl) 这章其实就是 explain 的几种type，也就是几种常用的单表sql语句，通常会使用哪种索引type。之后的“注意事项”，用来说明几种索引失效的情况

---

```markdown
设计MySQL的大叔把查询的执行方式大致分为下边两种：

使用全表扫描进行查询 （这种执行方式很好理解，就是把表的每一行记录都扫一遍嘛，把符合搜索条件的记录加入到结果集就完了。不管是啥查询都可以使用这种方式执行，当然，这种也是最笨的执行方式。）



使用索引进行查询 （因为直接使用全表扫描的方式执行查询要遍历好多记录，所以代价可能太大了。如果查询语句中的搜索条件可以使用到某个索引，那直接使用索引来执行查询可能会加快查询执行的时间。使用索引来执行查询的方式五花八门，又可以细分为许多种类：）

	针对主键或唯一二级索引的等值查询

	针对普通二级索引的等值查询

	针对索引列的范围查询

	直接扫描整个索引
```

![index-type.png](img/mysql-lessons/index-type.png)



- const 主键索引、唯一索引等只有一条记录的
- ref 普通索引
- ref_or_null 普通索引，类似ref但是还要查找null
- range 范围查询
- index 全索引扫描
- all 全表扫描




:::danger


```yaml
- mysql访问类型？或者说，explain的几种type（const, ref, ref_or_null, range, index, all）分别是啥意思?
- 为什么不同sql会走不同type，以及执行这些type时各自的具体执行流程？
- mysql 索引 失效，有哪些常见场景?
```





:::






### 11、连接的原理


[11、两个表的亲密接触 —— 连接的原理 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/88.html#5c23c8) 前半部分join使用很简单，主要看后半部分的原理。

简单来说，就是先在驱动表（主表）中查到数据集，再根据被驱动表（副表）的where在这个数据集里查数据。在此基础上，就有了内连接和外连接的区别。内连接就是 主表的记录在副表中找不到匹配记录，该记录不会加入到最终的结果集。外连接则相反。

---


Nested-Loop Join

基于块的嵌套循环连接（Block Nested-Loop Join）

[MySQL中的Join 的算法（NLJ、BNL、BKA） - Booksea - 博客园](https://www.cnblogs.com/booksea/p/17380941.html)

[MySQL优化器特性（四）表关联之BNL（Block Nested Loop）和Hash Join - 技术文章 - 云掣](https://yunche.pro/blog/?id=348)


![hash-join.png](img/mysql-lessons/hash-join.png)






:::danger

```yaml
- join的本质是啥？
- optimizer对join的优化（NLJ, BNL, BKA）各自的工作机制？

```





:::




### ~~12、谁最便宜就选谁 —— MySQL 基于成本的优化~~

[12、谁最便宜就选谁 —— MySQL 基于成本的优化 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/89.html)

---










### ~~13、兵马未动，粮草先行 —— InnoDB 统计数据是如何收集的~~

[13、兵马未动，粮草先行 —— InnoDB 统计数据是如何收集的 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/90.html) 这章比较简单，innodb的数据肯定是部分做了持久化，部分暂存在内存。这个不用说。这章就是相关的一些具体设置。


---





### ***14、不好看就要多整容 —— MySQL 基于规则的优化***

[14、不好看就要多整容 —— MySQL 基于规则的优化（内含关于子查询优化二三事儿） - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/91.html) 这章就回答了“mysql 的 optimizer有哪些优化方法（有哪些“查询重写”优化方法）”

---

前面“条件化简”这部分其实就是 一些常用的编译器优化操作，常量传播cp、常量折叠 cf、死码消除、CSE、BCE、LICM

---

外连接消除

***内连接的主表和副表可以互相转换，据此optimizer就会自动进行优化。而外连接则无法转换，所以无法进行自动优化。外连接消除就是optimizer自动把（可以转换为内连接的）外连接转内连接***。文章举了一个 reject-NULL 的例子。


---

- 子查询在MySQL中是怎么执行的





---


ICP and index dive, (MRR, BKA, BNL)

- `ICP索引条件下推(Index Condition Pushdown)` 用索引筛选的 where 条件在存储引擎一侧进行筛选，而不是将所有 index access 的结果都放在 server 端进行 where 筛选
- `MRR索引多范围查找(Multi-Range Read)` 优化器将随机 io 转化为顺序 io，以降低查询过程中 io 开销的一种手段
- `BKA(Batched Key Access)`，，在表连接过程中为了提升 join 性能而使用的 join buffer，其作用是在读取被 join 表的记录时，使用顺序 io(BKA 被使用的标识是执行计划的 extra 信息中会有 BKA 信息)。BKA优化技术在join中使用，特别是在执行连接操作时，如果一个表上的索引已经排序，而另一个表上的连接列也是有序的，那么MySQL可以使用BKA来批量访问这两个表。它允许优化器批量访问索引，减少索引访问的次数，从而提高join的性能。
- `BNL(Block Nested Loop)` BNL优化技术也是在join中使用的。当join无法使用更高级的连接算法（如索引连接或哈希连接）时，MySQL会使用BNL。BNL通过逐行读取两个表的数据，并执行循环匹配操作，以获取满足连接条件的结果。虽然BNL可能会导致性能较低，但在某些情况下，它仍然是执行join的一种有效方法。

---

```markdown
ICP的原理很简单。当 MySQL 执行查询语句时，它会根据查询条件选择合适的索引来访问数据。在传统的执行方式中，MySQL 首先通过索引找到满足条件的记录的主键，然后再根据主键值从数据表中获取记录。而索引条件下推则在索引访问阶段就进行条件过滤，只返回满足查询条件的记录的主键，避免了不必要的主键查找操作。

这样做的好处是减少了磁盘 IO 和网络传输，提高了查询效率。特别是对于那些返回记录较多但满足查询条件的记录较少的查询，索引条件下推可以大幅提升性能。
```

这些概念太抽象了，简单来说就是“ICP就是把本应executor执行的，推给SE来执行”

仍然用图书馆类比的话，ICP相当于在图书检索系统操作员（executor）正式检索之前，由图书馆工作人员（存储引擎）利用索引目录（索引）进行的预筛选，这样可以减少操作员需要检查的书籍数量，提高整体检索效率。

BKA和BNL都是在join操作时才会使用的优化技术

```markdown
- ICP（Index Condition Pushdown）：ICP在优化器中是一项重要的优化技术，它类似于图书馆的索引目录。在图书馆中，索引目录帮助读者快速找到所需书籍的位置。类比到MySQL中，ICP会尽可能将查询条件下推至存储引擎层级，以减少不必要的数据读取，提高查询效率。
- MRR（Multi-Range Read）：MRR是一种批量读取技术，类似于在图书馆中一次性获取多本书。MRR允许MySQL在存储引擎层级批量读取满足查询条件的多个数据块，以减少磁盘I/O操作，提高查询性能。
- BKA（Batch Key Access）：BKA是一种批量键访问技术，类似于在图书馆中通过预定书架号快速获取多本书。在MySQL中，BKA允许优化器批量访问索引，以减少索引访问的次数，提高查询速度。
- BNL（Block Nested Loop）：BNL是一种块嵌套循环技术，类似于在图书馆中通过遍历多个书架来查找所需书籍。在MySQL中，BNL用于处理连接操作，它会逐行读取两个表的数据，并执行循环匹配操作，以获取符合连接条件的结果。
- Index Dive：Index Dive类似于在图书馆中通过索引快速定位到需要的书籍的过程。在MySQL中，Index Dive是一种优化技术，它允许优化器通过索引的跳跃访问，直接定位到满足查询条件的数据，而无需完全扫描索引。
```

ICP就是“把查询条件放到存储引擎，能提高查询效率”，通俗来说就是，在查询过程中，直接在查询引擎层的 API 获取数据时，实现“非直接索引”过滤条件的筛选，而不是查询引擎层查询出来之后在 server 层筛选。

再则，ICP更适合那种大量数据，但是其中只有极少数满足查询条件的场景。

```markdown
MRR是一种针对读取操作的优化技术。它通过在一个请求中读取多个连续范围的数据，以减少读取磁盘的次数。MRR通常用于处理顺序扫描（Sequential Scan）或范围查询（Range Query）等需要从磁盘读取大量连续数据的场景。通过减少磁盘IO次数，MRR可以显著提高读取操作的性能。
```

MRR主要关注的是优化读取操作的效率

这些优化器技术都旨在提高查询性能，减少不必要的磁盘I/O和数据扫描








:::danger

```yaml

```

:::











### 15、Explain

[15、查询优化的百科全书 —— Explain 详解（上） - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/92.html)

[16、查询优化的百科全书 —— Explain 详解（下） - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/93.html)

---


![index-type.png](img/mysql-lessons/index-type.png)


---

extra提供了一些额外信息


```markdown
No tables used

Impossible WHERE

No matching min/max row

Using index

Using index condition

Using where

Using join buffer (Block Nested Loop)

Not exists

Using intersect(...)、Using union(...)和Using sort_union(...)

Zero limit

Using filesort

Using temporary

Start temporary, End temporary

LooseScan

FirstMatch(tbl_name)
```


---

```mysql
EXPLAIN FORMAT=JSON SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s1.common_field = 'a'\G
```

用 EXPLAIN FORMAT=JSON 给 explain加上估算执行cost

通过结果集中的 cost_info 查看


:::danger

```yaml
- mysql explain语句的 type
- mysql explain语句的 extra
- explain format=json 怎么用


```

:::



---


[MySQL查询优化分析 - 常用分析方法](http://mysql.taobao.org/monthly/2024/05/02/)



[MySQL EXPLAIN结果集分析 - 附带大量案例](https://mp.weixin.qq.com/s/p5UKuh1yY3P4zrOzVBmY1w)











### 17、神兵利器 —— optimizer trace 的神奇功效

[17、神兵利器 —— optimizer trace 的神奇功效 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/94.html)

---

```markdown
对于MySQL 5.6以及之前的版本来说，查询优化器就像是一个黑盒子一样，你只能通过EXPLAIN语句查看到最后优化器决定使用的执行计划，却无法知道它为什么做这个决策。这对于一部分喜欢刨根问底的小伙伴来说简直是灾难：“我就觉得使用其他的执行方案比EXPLAIN输出的这种方案强，凭什么优化器做的决定和我想的不一样呢？”

在MySQL 5.6以及之后的版本中，设计MySQL的大叔贴心的为这部分小伙伴提出了一个optimizer trace的功能，
```

***optimizer trace 用来展示具体的决策过程（也就是为啥会选择这样的“执行计划”），换句话就是用来解释为啥explain会决定使用这个“执行计划”，而不是其他的***

后面就是讲了下具体怎么使用 optimizer-trace

---

```markdown
不过杂乱之中其实还是蛮有规律的，优化过程大致分为了三个阶段：

prepare阶段

optimize阶段

execute阶段

我们所说的基于成本的优化主要集中在optimize阶段，对于单表查询来说，我们主要关注optimize阶段的"rows_estimation"这个过程，这个过程深入分析了对单表查询的各种执行方案的成本；对于多表连接查询来说，我们更多需要关注"considered_execution_plans"这个过程，这个过程里会写明各种不同的连接方式所对应的成本。反正优化器最终会选择成本最低的那种方案来作为最终的执行计划，也就是我们使用EXPLAIN语句所展现出的那种方案。

如果有小伙伴对使用EXPLAIN语句展示出的对某个查询的执行计划很不理解，大家可以尝试使用optimizer trace功能来详细了解每一种执行方案对应的成本，相信这个功能能让大家更深入的了解MySQL查询优化器。

```

确实如此，***查询计划由optimizer提供（也就是基于预估cost的），而执行详细信息的收集则是由executo提供。***


:::danger

```yaml
- 【optimizer-trace】怎么用optimizer-trace来优化sql？ 如何分析trace来改善查询的执行效率？
- optimizer-trace 和 explain-analyzer 有啥区别? 各自用来针对sql优化的哪个方面? # ***查询计划的解释是由optimizer提供的，而执行详细信息的收集是由executor提供的。*** 这点在mysql和postgres里是一样的。*也就是说几个mysql常用的优化命令，optimizer-trace是optimizer提供的，explain analyze 是 executor提供的，show status 则是一个数据汇总的命令，*

```

:::



### ***18、调节磁盘和CPU的矛盾 —— InnoDB 的 Buffer Pool***

[18、调节磁盘和CPU的矛盾 —— InnoDB 的 Buffer Pool - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/95.html) 这章涉及到


---

```markdown
通过前边的唠叨我们知道，对于使用InnoDB作为存储引擎的表来说，不管是用于存储用户数据的索引（包括聚簇索引和二级索引），还是各种系统数据，都是以页的形式存放在表空间中的，而所谓的表空间只不过是InnoDB对文件系统上一个或几个实际文件的抽象，也就是说我们的数据说到底还是存储在磁盘上的。但是各位也都知道，磁盘的速度慢的跟乌龟一样，怎么能配得上“快如风，疾如电”的CPU呢？所以InnoDB存储引擎在处理客户端的请求时，当需要访问某个页的数据时，就会把完整的页的数据全部加载到内存中，也就是说即使我们只需要访问一个页的一条记录，那也需要先把整个页的数据加载到内存中。将整个页加载到内存中后就可以进行读写访问了，在进行完读写访问之后并不着急把该页对应的内存空间释放掉，而是将其缓存起来，这样将来有请求再次访问该页面时，就可以省去磁盘IO的开销了。
```

***buffer pool本质上是innodb向os申请的一段连续内存空间。这段连续内存由控制块和缓存页组成。每个控制块和缓存页都是一一对应的，在填充足够多的控制块和缓存页的组合后，Buffer Pool剩余的空间可能产生不够填充一组控制块和缓存页，这部分空间不能被使用，也被称为碎片。***






```markdown
1、Buffer Pool本质上是InnoDB向操作系统申请的一段连续的内存空间，可以通过innodb_buffer_pool_size来调整它的大小。


2、Buffer Pool向操作系统申请的连续内存由控制块和缓存页组成，每个控制块和缓存页都是一一对应的，在填充足够多的控制块和缓存页的组合后，Buffer Pool剩余的空间可能产生不够填充一组控制块和缓存页，这部分空间不能被使用，也被称为碎片。


3、InnoDB使用了许多链表来管理Buffer Pool。

4、free链表中每一个节点都代表一个空闲的缓存页，在将磁盘中的页加载到Buffer Pool时，会从free链表中寻找空闲的缓存页。

5、为了快速定位某个页是否被加载到Buffer Pool，使用表空间号 + 页号作为key，缓存页作为value，建立哈希表。

6、在Buffer Pool中被修改的页称为脏页，脏页并不是立即刷新，而是被加入到flush链表中，待之后的某个时刻同步到磁盘上。

7、LRU链表分为young和old两个区域，可以通过innodb_old_blocks_pct来调节old区域所占的比例。首次从磁盘上加载到Buffer Pool的页会被放到old区域的头部，在innodb_old_blocks_time间隔时间内访问该页不会把它移动到young区域头部。在Buffer Pool没有可用的空闲缓存页时，会首先淘汰掉old区域的一些页。

8、我们可以通过指定innodb_buffer_pool_instances来控制Buffer Pool实例的个数，每个Buffer Pool实例中都有各自独立的链表，互不干扰。

9、自MySQL 5.7.5版本之后，可以在服务器运行过程中调整Buffer Pool大小。每个Buffer Pool实例由若干个chunk组成，每个chunk的大小可以在服务器启动时通过启动参数调整。

```





:::danger

```yaml
#- topic: InnoDB 缓冲池(buffer-pool)

- 什么是缓冲池 buffer-pool? # 避免每次读操作都进行磁盘 IO，具体来说，缓冲池缓存了大量数据页，让 CPU 读取和写入数据时，直接和缓冲区交互，不需要操作磁盘，从而避免磁盘拖慢数据库性能的问题（*注意缓冲池是 innoDB 引擎的特性，而不是 mysql 的*）
- 缓冲池存哪些数据？ # 缓存表数据与索引数据，把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘 IO，起到加速访问的作用。
- 缓冲池的工作机制？

- 缓存页的哈希处理
- flush链表的管理
- LRU链表的管理

```




:::






#### 脏页刷新



![innodb-page-flushing.svg](img/mysql-lessons/innodb-page-flushing.svg)




```markdown
当然，以下是InnoDB存储引擎中脏页刷新（Page Flush）过程的概述，涵盖了所有关键点：

1. **事务修改页**：当事务对表中的数据进行修改时，这些修改首先在内存中的页（buffer pool中的页）上进行。一旦页被修改，它就变成一个脏页。

2. **重做日志记录**：在事务提交之前，InnoDB会将修改记录到重做日志（redo log）中。这是为了确保在发生故障时可以使用这些日志来恢复数据。

3. **事务提交**：事务提交后，修改的页仍然是脏页，因为它们还没有被写回到磁盘上。

4. **脏页刷新触发**：InnoDB有几种机制来触发脏页的刷新：
   - **后台刷新**：后台线程（Page Cleaner）定期刷新脏页。
   - **Checkpoint触发**：当重做日志的头部（head）和尾部（tail）之间的距离（checkpoint age）达到一定阈值时，会触发刷新。
   - **缓冲池压力**：当缓冲池中脏页的比例过高或需要为新的读操作腾出空间时，会触发脏页刷新。

5. **刷新邻接页**：如果启用了刷新邻接页（Flush Neighbor Page）功能，InnoDB在刷新一个脏页时，会检查同一区（extent）内的所有页，如果这些页也是脏的，它们也会被一起刷新。

6. **自适应刷新**：InnoDB的自适应刷新算法根据当前的写入负载和磁盘性能动态调整刷新速率，以避免刷新风暴（flush storm）。

7. **刷新操作**：脏页被写回到磁盘上，这一过程可能涉及异步IO操作，以提高效率。

8. **刷新完成**：一旦脏页被成功写回到磁盘，它们就不再是脏页。InnoDB会更新重做日志的尾部位置，减少checkpoint age。

9. **日志文件管理**：随着脏页的刷新，之前记录的重做日志可以被覆盖，以便日志文件可以循环使用。

10. **性能监控与调优**：通过监控刷新操作的性能，如通过`show engine innodb status`命令，DBA可以对刷新过程进行调优，例如调整`innodb_page_cleaners`、`innodb_adaptive_flushing_lwm`、`innodb_io_capacity`等参数。

11. **刷新争用处理**：在高负载情况下，刷新操作可能会与其他数据库操作（如查询和索引构建）竞争资源，需要适当调整以避免性能瓶颈。

12. **系统状态反馈**：InnoDB通过日志和状态信息提供刷新操作的反馈，帮助DBA了解系统的当前状态并做出相应的调整。

整个刷新过程是InnoDB保证数据持久性和系统性能的关键机制之一。通过智能地管理脏页的刷新，InnoDB可以在保持高性能的同时，确保数据的安全性和完整性。

```






dirty pages

```markdown
在整个InnoDB的脏页刷新（Flush）过程中，涉及到以下特性：

1. **缓冲池（Buffer Pool）**：InnoDB使用缓冲池来缓存频繁访问的数据和索引页，减少对磁盘的I/O操作。

2. **脏页（Dirty Pages）**：在缓冲池中被修改但尚未写入磁盘的页。

3. **重做日志（Redo Log）**：事务提交前，修改操作首先记录到重做日志中，确保数据恢复的一致性。

4. **LSN（Log Sequence Number）**：用于记录重做日志的位置，每个事务都会生成一个新的LSN。

5. **Checkpoint**：刷新过程中，InnoDB会更新磁盘上数据页的状态，Checkpoint机制用于标记哪些数据已经刷新到磁盘。

6. **刷新邻接页（Flush Neighbor Page）**：当刷新一个脏页时，如果该页所在的区（extent）内还有其他脏页，它们也会被一起刷新。

7. **自适应刷新（Adaptive Flushing）**：根据当前的系统负载和性能指标，动态调整刷新速率。

8. **异步IO（Asynchronous IO）**：InnoDB支持异步IO操作，允许脏页刷新操作与其他数据库操作并发执行。

9. **刷新线程（Page Cleaner Threads）**：InnoDB使用专门的后台线程来刷新脏页。

10. **刷新控制参数**：
    - `innodb_page_cleaners`：控制刷新脏页的线程数。
    - `innodb_purge_threads`：控制清除操作的线程数。
    - `innodb_io_capacity`：定义InnoDB刷新磁盘时的IO容量。
    - `innodb_adaptive_flushing`：控制是否启用自适应刷新算法。
    - `innodb_adaptive_flushing_lwm`：自适应刷新的最低水位参数。
    - `innodb_flush_neighbors`：控制是否启用刷新邻接页特性。

11. **刷新争用处理**：在高负载情况下，InnoDB需要处理刷新操作与其他数据库操作之间的资源争用。

12. **性能监控**：通过`show engine innodb status`等命令监控刷新操作的性能。

13. **刷新风暴（Flush Storm）**：当重做日志的空间不足以容纳新的事务提交时，InnoDB会高速刷新脏页以释放空间，这可能导致性能问题。

14. **日志文件管理**：刷新过程中，InnoDB需要管理重做日志文件，确保日志文件的循环使用。

15. **系统状态反馈**：InnoDB通过日志和状态信息提供刷新操作的反馈，帮助数据库管理员了解系统的当前状态。

这些特性共同工作，确保InnoDB存储引擎能够有效地管理脏页刷新，同时保持高性能和数据的持久性。

```



InnoDB的redolog就是WAL嘛，必然会产生脏页



为啥会出现脏页? page flush的时机? 刷新策略?


能否给我概述一下整个page flush的过程？整个flush过程中涉及到哪些innodb的特性？



flush page 就是把内存中修改过的页（脏页）写回到磁盘上，以确保数据的持久性和一致性。

之所以产生脏页就是因为InnoDB用WAL来防止宕机数据丢失，也就是事务提交时，先写redolog，再修改内存数据页，这样就产生了脏页。

那为啥要刷新呢？因为不可能把所有 buffer pool 所以需要把buffer pool里的脏页都刷新到磁盘里

InnoDB通过LSN（每条log的结束点，用字节偏移量来表示。每个page有LSN，redo log也有LSN，Checkpoint也有LSN）来标记版本

Checkpoint机制每次刷新多少页，从哪里取脏页，什么时间触发刷新？












:::danger

```yaml
- topic: InnoDB 预读
  qs:
    - q: 什么是预读？
      x: 磁盘按页读取，如果要读取的数据就在页中，就能节省后面的磁盘 io，提高效率。数据访问遵循`集中读写`的原则，使用一些数据，大概率会使用附近的数据，这就是`局部性原理`
    - q: 什么是预读失败？
    - q: 如何对预读失败进行优化？
    - q: 什么是缓冲池污染？
    - q: 怎么解决缓冲池污染的问题？
```

:::










### 19、从猫爷被杀说起 —— 事务简介

[19、从猫爷被杀说起 —— 事务简介 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/96.html)

---
















### ***20、redo日志***

[第20章 说过的话就一定要办到-redo日志（上）](https://relph1119.github.io/mysql-learning-notes/#/mysql/20-%E8%AF%B4%E8%BF%87%E7%9A%84%E8%AF%9D%E5%B0%B1%E4%B8%80%E5%AE%9A%E8%A6%81%E5%8A%9E%E5%88%B0-redo%E6%97%A5%E5%BF%97%EF%BC%88%E4%B8%8A%EF%BC%89)


```markdown
redo日志是什么
  我们知道InnoDB存储引擎是以页为单位来管理存储空间的，我们进行的增删改查操作其实本质上都是在访问页面（包括读页面、写页面、创建新页面等操作）。我们前面介绍Buffer Pool的时候说过，在真正访问页面之前，需要把在磁盘上的页缓存到内存中的Buffer Pool之后才可以访问。但是在介绍事务的时候又强调过一个称之为持久性的特性，就是说对于一个已经提交的事务，在事务提交后即使系统发生了崩溃，这个事务对数据库中所做的更改也不能丢失。但是如果我们只在内存的Buffer Pool中修改了页面，假设在事务提交后突然发生了某个故障，导致内存中的数据都失效了，那么这个已经提交了的事务对数据库中所做的更改也就跟着丢失了，这是我们所不能忍受的（想想ATM机已经提示狗哥转账成功，但之后由于服务器出现故障，重启之后猫爷发现自己没收到钱，猫爷就被砍死了）。那么如何保证这个持久性呢？一个很简单的做法就是在事务提交完成之前把该事务所修改的所有页面都刷新到磁盘，但是这个简单粗暴的做法有些问题：


```


```markdown
  咋办呢？再次回到我们的初心：我们只是想让已经提交了的事务对数据库中数据所做的修改永久生效，即使后来系统崩溃，在重启后也能把这种修改恢复出来。所以我们其实没有必要在每次事务提交时就把该事务在内存中修改过的全部页面刷新到磁盘，只需要把修改了哪些东西记录一下就好，比方说某个事务将系统表空间中的第100号页面中偏移量为1000处的那个字节的值1改成2我们只需要记录一下：
```

只记录操作，不记录被修改后的数据，因为成本太高


---



```markdown
这句话可以从以下几个关键点来理解InnoDB的redo log以及它如何实现WAL（Write-Ahead Logging）策略：

1. **WAL策略**：WAL是一种常见的数据库日志技术，核心思想是在数据实际写入磁盘之前，先将对数据的修改操作记录到日志中。这样做可以提高性能，因为写日志通常比直接写磁盘要快，并且可以减少对磁盘的I/O操作。

2. **事务的持久性**：事务的持久性是ACID原则中的"D"，指的是一旦事务提交，它对数据库的改变就是永久性的，即使系统发生故障也不会丢失。InnoDB通过redo log来实现这一点：当事务提交时，相关的修改操作已经记录在redo log中，如果系统发生故障，InnoDB可以重放redo log中的操作，从而恢复未持久化到磁盘的数据。

3. **先记录日志再写入数据**：这是WAL策略的具体实现。在InnoDB中，当事务需要修改数据时，首先会在redo log中记录这次修改的详细信息，然后再将修改后的页（数据）写入内存中的缓冲池。这样做可以确保即使在数据页写入磁盘之前系统崩溃，通过redo log也能够恢复数据。

4. **Checkpoint技术**：Checkpoint是InnoDB中用于管理redo log空间和优化恢复时间的一种机制。它在redo log中标记了一个点，表示在这个点之前的所有事务都已经将数据持久化到磁盘。这样，当系统需要恢复时，只需要重放Checkpoint之后的部分日志，而不是整个日志文件，从而大大减少了恢复所需的时间。

5. **有效管理日志空间**：由于redo log是循环使用的，Checkpoint还有助于释放不再需要的日志空间。一旦数据页被刷新到磁盘并且对应的事务已经提交，从Checkpoint点之前的日志就可以被清除，为新的事务日志腾出空间。

综上所述，InnoDB的redo log通过WAL策略确保了事务的持久性，并通过Checkpoint技术有效管理了日志空间和恢复时间，从而提供了高性能和数据安全性。

```







:::danger

```yaml

- 什么是inndob的redolog? 是怎么通过redolog实现WAL的?

```


:::





### ***22、undo日志***


[第23章 后悔了怎么办-undo日志（下）](https://relph1119.github.io/mysql-learning-notes/#/mysql/23-%E5%90%8E%E6%82%94%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E-undo%E6%97%A5%E5%BF%97%EF%BC%88%E4%B8%8B%EF%BC%89?id=undo%e6%97%a5%e5%bf%97%e5%85%b7%e4%bd%93%e5%86%99%e5%85%a5%e8%bf%87%e7%a8%8b)


---


```markdown
undo日志具体写入过程
段（Segment）的概念
  如果你有认真看过表空间那一章的话，对这个段的概念应该印象深刻，我们当时花了非常大的篇幅来介绍这个概念。简单讲，这个段是一个逻辑上的概念，本质上是由若干个零散页面和若干个完整的区组成的。比如一个B+树索引被划分成两个段，一个叶子节点段，一个非叶子节点段，这样叶子节点就可以被尽可能的存到一起，非叶子节点被尽可能的存到一起。每一个段对应一个INODE Entry结构，这个INODE Entry结构描述了这个段的各种信息，比如段的ID，段内的各种链表基节点，零散页面的页号有哪些等信息（具体该结构中每个属性的意思大家可以到表空间那一章里再次重温一下）。我们前面也说过，为了定位一个INODE Entry，设计InnoDB的大佬设计了一个Segment Header的结构：


```


```markdown
知道了表空间ID、页号、页内偏移量，不就可以唯一定位一个INODE Entry的地址了么～
```


undolog page 链表是哪来的 干啥的




### 24、一条记录的多幅面孔 —— 事务的隔离级别与MVCC

[24、一条记录的多幅面孔 —— 事务的隔离级别与MVCC - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/101.html)

---




### 25、工作面试老大难 —— 锁

[25、工作面试老大难 —— 锁 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/102.html)

---










### 27、MySQL的server层和存储引擎层是如何交互的

[27、MySQL的server层和存储引擎层是如何交互的 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/104.html)

---





### 28、MySQL查询成本和扫描区间


[28、专题式讲解—MySQL查询成本和扫描区间(MySQL中IS NULL、IS NOT NULL - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/105.html)

---



### 29、听说有一个最左原则

[29、听说有一个最左原则？这回终于讲清楚了 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/106.html)


---





### 32、MySQL使用索引执行IN子句


[32、MySQL使用索引执行IN子句 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/109.html)

---

### 33、MySQL的COUNT语句是怎么执行的

[33、MySQL的COUNT语句是怎么执行的 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/110.html)

---





### 40、Innodb到底是怎么加锁的

[40、Innodb到底是怎么加锁的 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/117.html)


---





### 41、语句加锁分析实例


[41、语句加锁分析实例 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/118.html)

---





### 42、MySQL如何查看事务加锁情况

[42、MySQL如何查看事务加锁情况 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/119.html)

---






### 43、专题式讲解 -MySQL介于普通读和锁定读的加锁方式


[43、专题式讲解 -MySQL介于普通读和锁定读的加锁方式——semi-consistent rea - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/120.html)


---





### 44、两条一样的INSERT语句竟然引发了死锁？


[44、两条一样的INSERT语句竟然引发了死锁？ - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/121.html)

---





### 45、binlog


[45、binlog那些事儿（一） - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/122.html)


[46、binlog那些事儿（二） - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/123.html)

---























### 47、redo、undo、buffer pool、binlog，谁先谁后，有点儿乱

[47、redo、undo、buffer pool、binlog，谁先谁后，有点儿乱 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/124.html)

---



```markdown
我们讨论的是基于InnoDB存储引擎的表，数据会被保存在硬盘上的表空间（文件系统中的一个或多个文件）中。

InnoDB会将磁盘中的数据看成是若干个页的集合，页的大小默认是16KB。其中某些页面用于存储关于系统的一些属性，某些页面用于存储undo日志，某些页面用于存储B+树的节点（也就是包含记录的页面），反正总共有十来种不同类型的页面。

不过不论是什么类型的页面，每当我们从页面中读取或写入数据时，都必须先将其从硬盘上加载到内存中的buffer pool中（也就是说内存中的页面其实就是硬盘中页面的一个副本），然后才能对内存中页面进行读取或写入。如果要修改内存中的页面，为了减少磁盘I/O，修改后的页面并不立即同步到磁盘，而是作为脏页继续呆在内存中，等待后续合适时机将其刷新到硬盘（一般是有后台线程异步刷新）。
```




### 48、XA事务与两阶段提交

[48、XA事务与两阶段提交 - 《MySQL 是怎样运行的：从根儿上理解 MySQL》 · IT书架](https://itshujia.com/read/mysql/125.html)


```markdown
跨行转账是一个典型的分布式事务的实例。各个银行都有自己的服务，如果狗哥在招商银行存了10块钱，他想把这10块钱转给猫爷在建设银行的账户，那么招商银行先得给狗哥账户扣10块，然后建设银行给猫爷账户增10块。而招商银行和建设银行根本就不是一个系统，招商银行给狗哥扣钱的业务放到了自己的一个事务里，建设银行给猫爷加钱的业务放到了自己的一个事务里，这两个事务其实在各自的系统中并没有什么关系，完全有可能招商银行的事务提交了，而建设银行的事务由于系统宕机而失败了，这就导致狗哥扣了钱，却没有转给猫爷的惨剧发生。所以我们必须引入一些机制，来实现分布式事务。
```

:::danger

```yaml




```

:::






## 《MySQL 45讲》读书笔记



```markdown
00 开篇词 这一次，让我们一起来搞懂MySQL.md
01 基础架构：一条SQL查询语句是如何执行的？.md
02 日志系统：一条SQL更新语句是如何执行的？.md
03 事务隔离：为什么你改了我还看不见？.md
04 深入浅出索引（上）.md
05 深入浅出索引（下）.md
06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？.md
07 行锁功过：怎么减少行锁对性能的影响？.md
08 事务到底是隔离的还是不隔离的？.md
09 普通索引和唯一索引，应该怎么选择？.md
10 MySQL为什么有时候会选错索引？.md
11 怎么给字符串字段加索引？.md
12 为什么我的MySQL会“抖”一下？.md
13 为什么表数据删掉一半，表文件大小不变？.md

14 count()这么慢，我该怎么办？.md
15 答疑文章（一）：日志和索引相关问题.md
16 “order by”是怎么工作的？.md
17 如何正确地显示随机消息？.md
18 为什么这些SQL语句逻辑相同，性能却差异巨大？.md

19 为什么我只查一行的语句，也执行这么慢？.md
20 幻读是什么，幻读有什么问题？.md
21 为什么我只改一行的语句，锁这么多？.md


22 MySQL有哪些“饮鸩止渴”提高性能的方法？.md
23 MySQL是怎么保证数据不丢的？.md

24 MySQL是怎么保证主备一致的？.md
25 MySQL是怎么保证高可用的？.md
26 备库为什么会延迟好几个小时？.md
27 主库出问题了，从库怎么办？.md
28 读写分离有哪些坑？.md

29 如何判断一个数据库是不是出问题了？.md
30 答疑文章（二）：用动态的观点看加锁.md
31 误删数据后除了跑路，还能怎么办？.md
32 为什么还有kill不掉的语句？.md
33 我查这么多数据，会不会把数据库内存打爆？.md
34 到底可不可以使用join？.md
35 join语句怎么优化？.md
36 为什么临时表可以重名？.md
37 什么时候会使用内部临时表？.md
38 都说InnoDB好，那还要不要使用Memory引擎？.md
39 自增主键为什么不是连续的？.md
40 insert语句的锁为什么这么多？.md
41 怎么最快地复制一张表？.md
42 grant之后要跟着flush privileges吗？.md
43 要不要使用分区表？.md
44 答疑文章（三）：说一说这些好问题.md
45 自增id用完怎么办？.md
我的MySQL心路历程.md
结束语 点线网面，一起构建MySQL知识网络.md
```




### 01 基础架构：一条SQL查询语句是如何执行的？

[01 基础架构：一条SQL查询语句是如何执行的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/01%20%20%e5%9f%ba%e7%a1%80%e6%9e%b6%e6%9e%84%ef%bc%9a%e4%b8%80%e6%9d%a1SQL%e6%9f%a5%e8%af%a2%e8%af%ad%e5%8f%a5%e6%98%af%e5%a6%82%e4%bd%95%e6%89%a7%e8%a1%8c%e7%9a%84%ef%bc%9f.md)

:::tip

从 sql查询语句的执行，引申出 mysql arch（也就是cpoe）

:::



---

如果拿图书馆来类比mysql的话，就很好理解了。假设我们的需求是进入图书馆获取n本符合我们需要的书。

- connector就相当于门卫，只有预约（相当于auth）过才能进入，我们可以通过调整连接数（就是预约人数）来动态调整图书馆的负载。
- parser就相当于图书馆的前台，是把汉语转化成该书的ISBD号等MACS专用信息（将查询语句转换为内部数据结构，相当于compiler），并且提供这些书的位置和路线（提供查询计划）。mysql的parser其实就是compiler，词法分析、语法分析啥的。
- optimizer就相当于优化我们去找到这本书的路线（找到最优路线，提高查询效率）。
- executor则相当于“图书馆操作员”，负责执行优化后的查询计划（也就是带着我们），从图书馆书架（存储引擎）里查找所有需要的数据，这也解释了查询操作关键字的执行顺序，当然要先确定这些书籍的大概区域（也就是FROM），如果需要把这些书按序排列的话，就最后再执行Order这种已经拿到所有书籍之后无关紧要的操作。那中间肯定就是来获取查找这些书了，也就是各种条件（where和groupby/having和select），当然书肯定不需要重复的（也就是Distinct去重操作）。

***如果我们把存储引擎比做图书馆的所有书架的话，表、页、行分别类比成什么呢？*** 表可以类比成图书馆的某个区域，每个区域存放着特定类型的书籍。页可以看作是该区域的某个书架，每个书架上放着一定数量的书籍。行可以类比成某一排书，每一排上放着一本书。

进一步的，我们可以用这些继续类比myisam和innodb，myisam就是每个分类（比如工业技术、交通运输、历史地理等等，具体查看《中国图书馆分类法》）都会有一个单独的目录，并且不允许很多人同时查找（不支持并发查找，也就是不支持事务），进行查找时直接锁表，相应的，我们可以直接通过这个单独的MYI索引文件查找对应的图书，非常快。

InnoDB就灵活的多了，他是以书架为单位进行查找和存储的，所以他的目录（索引）是和某排图书在一起的（相当于每排书一个索引（主键索引），索引id都贴在书架该层的最前面，这时就存在两种情况，一种就是直接查目录（索引）就可以获得数据，不需要再查数据表，这个就是“索引覆盖”（或者说Index Dive，都是类似意思）。如果目录中查不到我们需要的数据，就需要“回表”了，那么我们根据索引id来看需要的书是不是在这排（再多说一句，这也是为什么主键id最好单调递增的原因））。他是支持多人同时查找的。并且在读写操作时只锁定某排书（也就是行级锁定），粒度更细，这样就更能频繁地执行读操作和写操作。

***需要注意的是mysql还支持同时使用多种存储引擎***，也就是说在图书馆里如果有一些冷门分类，很少有新书入库的，那就用myisam这种类型的管理方式，如果非常热门的分类，每天都有很多用户来买书，每天书店也需要频繁补货的，就应该用innodb。当然，如果我们把mysql看作是图书馆的话，不同图书馆的特性（规矩、规章制度）也不同，比如说oracle或者sql server这种的就比较死板，图书馆开店营业之前就定好了所有书架的管理模式（也就是存储引擎），之后再也不能修改，更不存在说不同分类使用不同的管理模式一说了。

另外，还需要注意一个问题，编织目录（索引）的具体方法和该“图书分类”（存储引擎）的映射关系。众所周知，对于不同图书分类也应该使用不同的方式来编写目录。比如说R树适用于myisam（也有B+Tree），hash适用于memory，B+Tree则适用于InnoDB。





:::tip

```yaml
- "***mysql 的查询语句的具体执行？比如 sql 语句有 select from where orderby，为啥查询语句执行的先后顺序是 FWG(H)SDO (from-where-group by-having-select-order by)？***"


```




:::











### 02 日志系统：一条SQL更新语句是如何执行的？

[02 日志系统：一条SQL更新语句是如何执行的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/02%20%20%e6%97%a5%e5%bf%97%e7%b3%bb%e7%bb%9f%ef%bc%9a%e4%b8%80%e6%9d%a1SQL%e6%9b%b4%e6%96%b0%e8%af%ad%e5%8f%a5%e6%98%af%e5%a6%82%e4%bd%95%e6%89%a7%e8%a1%8c%e7%9a%84%ef%bc%9f.md)

```markdown
分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。
```

还是从cpoe入手，parser经过lexical analysis知道是更新语句，executor负责执行具体的更新操作

```markdown
与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。
```
redolog和binlog，2PC

因为更新操作涉及到一致性问题（以及分布式下的一致性问题），本质上是DT的2PC方案


```markdown
不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。

如果有人要赊账或者还账的话，掌柜一般有两种做法：

一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；
另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。
在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。

这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？

同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。

而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。

具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。

与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。
```

![redolog.png](img/mysql-lessons/redolog.png)

```markdown
write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。

要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。
```


这个粉板和账本的类比很恰当。

redolog就是粉板，




:::tip

[//]: # (TODO x)


结合 [庖丁解InnoDB之REDO LOG | CatKang的博客](https://catkang.github.io/2020/02/27/mysql-redo.html)

所以这段内容就解决了以下问题：

```yaml
- redolog 是啥？为什么需要记录 redolog？
- 需要什么样的 redolog？
- redolog 中记录了什么内容？
- redolog 是怎么组织的？
- 如何高效地写 redolog？
- 如何安全地清除 redolog？
- "***checkpoint是啥? 只跟redolog 相关吗? 跟其他日志有关吗?***"
```

*undolog是逻辑日志，redolog是物理日志。但是redolog是由undolog产生的*

redolog其实就是WAL，通过先记录日志再写入数据的方式，确保了事务的持久性，并通过Checkpoint技术有效管理了日志空间和恢复时间

为了获得更好的读写性能，innoDB 将数据缓存到内存 (innoDB Buffer Pool)，对磁盘数据的修改也会落后于内存，如果进程崩溃就会导致内存数据丢失，所以 innoDB 就维护了 redolog，内存数据丢失后，innoDB 会在重启时，通过重放 REDO，恢复数据



如何安全地清除 redolog?

其实就是刷盘操作（当然还有其他刷盘操作，具体的触发条件、执行方式和优化策略不同，比如同步写入、异步写、定时写等等）

用来把内存中的脏页（尚未写入磁盘的修改数据页）写入磁盘，并更新相关的日志信息，这个操作是为了保证数据的一致性，以防止系统崩溃时数据丢失。

- sharp checkpoint: mysql关闭时，会触发把所有的脏页都刷入到磁盘上
- fuzzy checkpoint: mysql运行时，部分刷入磁盘

:::







### 12 为什么我的MySQL会“抖”一下？

[12 为什么我的MySQL会“抖”一下？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/12%20%20%e4%b8%ba%e4%bb%80%e4%b9%88%e6%88%91%e7%9a%84MySQL%e4%bc%9a%e2%80%9c%e6%8a%96%e2%80%9d%e4%b8%80%e4%b8%8b%ef%bc%9f.md)









### 03 事务隔离：为什么你改了我还看不见？

[03 事务隔离：为什么你改了我还看不见？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/03%20%20%e4%ba%8b%e5%8a%a1%e9%9a%94%e7%a6%bb%ef%bc%9a%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%a0%e6%94%b9%e4%ba%86%e6%88%91%e8%bf%98%e7%9c%8b%e4%b8%8d%e8%a7%81%ef%bc%9f.md)







### 06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？


[06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/06%20%20%e5%85%a8%e5%b1%80%e9%94%81%e5%92%8c%e8%a1%a8%e9%94%81%20%ef%bc%9a%e7%bb%99%e8%a1%a8%e5%8a%a0%e4%b8%aa%e5%ad%97%e6%ae%b5%e6%80%8e%e4%b9%88%e6%9c%89%e8%bf%99%e4%b9%88%e5%a4%9a%e9%98%bb%e7%a2%8d%ef%bc%9f.md)



### 07 行锁功过：怎么减少行锁对性能的影响？



### 08 事务到底是隔离的还是不隔离的？


[08 事务到底是隔离的还是不隔离的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/08%20%20%e4%ba%8b%e5%8a%a1%e5%88%b0%e5%ba%95%e6%98%af%e9%9a%94%e7%a6%bb%e7%9a%84%e8%bf%98%e6%98%af%e4%b8%8d%e9%9a%94%e7%a6%bb%e7%9a%84%ef%bc%9f.md) 这章就是MVCC相关了














## index




[//]: # (TODO index bptree)


```yaml

    - q: innodb索引树的高度由什么决定?
      u: https://www.bilibili.com/video/BV1jb421e7iS/
      x: 单条数据的大小会影响索引树的高度。bptree是由16k的page组成的，非叶子node只存index，叶子node存储index和数据本身。

```

[面试爱问的MySQL索引，一个动画就了解了！ - YouTube](https://www.youtube.com/watch?v=93f0xoqR2aU)



### index 创建原则

```yaml
- 左选小写修（最左前缀索引、选择性、小字段、写操作频率、修改索引） # 最主要的索引创建原则其实就是最左前缀和选择性。除此之外就是一些tips，比如什么查询频率、写操作频率（更新非常频繁的字段不适合创建索引）、小字段（对于大的文本字段甚至超长字段，不要建索引）、反向开闭（用修改代替新增）之类的
- 在什么情况下会使用最左前缀?
- 最左前缀的本质是啥? # “最左前缀”实际上就是前缀索引在复合索引场景下的使用，也就是说，复合索引中field顺序也要按照“index创建原则”来排序。最左前缀的本质就是ICP，ICP只在满足"最左前缀"条件时起作用。如果查询条件中包含了索引的非最左前缀列，ICP将无法生效，MySQL会在存储引擎层面进行完整的行过滤，这可能会导致性能下降。总结来说，"最左前缀"原则和ICP的本质是基于索引列的前缀进行索引范围扫描，以减少需要访问的行数，提高查询性能。
- Index选择性是啥?  # 就是字段不重复的比例 `count(distinct col)/count(*)`（不重复的索引值（也称为基数 cardinality) 和数据表的记录总数的比值），区间为`(0,1]`，***识别度越高，扫描相同行数，需要的次数就越少，这是由 B+ 树的性质决定的***
- 前缀索引、 ***尽量使用前缀来索引，如果索引字段的值很长，最好使用值的前缀来索引*** 例如，TEXT 和 BLOG 类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度

```






### 09 普通索引和唯一索引，应该怎么选择？

[09 普通索引和唯一索引，应该怎么选择？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/09%20%20%e6%99%ae%e9%80%9a%e7%b4%a2%e5%bc%95%e5%92%8c%e5%94%af%e4%b8%80%e7%b4%a2%e5%bc%95%ef%bc%8c%e5%ba%94%e8%af%a5%e6%80%8e%e4%b9%88%e9%80%89%e6%8b%a9%ef%bc%9f.md) 开篇抛出来的问题好啊，很常见的应用场景，身份证号要加unique index还是index。这种场景我一直是加唯一索引的。但是本文通过读操作和写操作两种场景，尤其是时写操作下change buffer机制对index的优化。




### 10 MySQL为什么有时候会选错索引？

[10 MySQL为什么有时候会选错索引？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/10%20%20MySQL%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e6%97%b6%e5%80%99%e4%bc%9a%e9%80%89%e9%94%99%e7%b4%a2%e5%bc%95%ef%bc%9f.md)



### 11 怎么给字符串字段加索引？


```markdown
在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：

直接创建完整索引，这样可能比较占用空间；
创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。


在实际应用中，你要根据业务字段的特点选择使用哪种方式。

```

这章很实用啊














## mysql replication


### 23 MySQL是怎么保证数据不丢的？

[23 MySQL是怎么保证数据不丢的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/23%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e6%95%b0%e6%8d%ae%e4%b8%8d%e4%b8%a2%e7%9a%84%ef%bc%9f.md)



redolog和binlog是mysql最核心的两个日志，“只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复”，***如果想实现replication，首先就要确保redolog能够写入磁盘***


```markdown
其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。

可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。

图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。
```

![binlog-write.png](img/mysql-lessons/binlog-write.png)
<center>*binlog写入机制*</center>


---

redolog写入机制





:::tip

```yaml

```

总结：

这章讲的是binlog和redolog的写入机制

- binlog写入机制：正如上图所示，***分为事务执行和事务提交两部分，事务提交之后就是write+fsync，而事务执行可以理解为大文件分片上传，有个组装逻辑***，事务执行时把日志写入binlog cache，事务提交时，executor吧binlog cache里的完整事务写入binlog（就是write），再fsync到disk
- redolog写入机制

:::







### 24 MySQL是怎么保证主备一致的？]

[24 MySQL是怎么保证主备一致的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/24%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e4%b8%bb%e5%a4%87%e4%b8%80%e8%87%b4%e7%9a%84%ef%bc%9f.md)



![replication.png](img/mysql-lessons/replication.png)



这章都是一些binlog相关的基础知识，


:::tip

```yaml
- binlog 有哪些日志格式？
- binlog的刷盘时机（什么时候把 binlog 从内存刷到磁盘）？

```


- `mixd`，*mix 是 statement 和 row 的混合。正常而言都是用 statement 来存，但是像主从这种没有逻辑的则用 row 格式来存*
- `statement`，每一条会修改数据的 sql 都会记录在 binlog 中
- `row`，binlog 中可以不记录执行的 sql 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了

---

binlog 的刷盘时机？什么时候把 binlog 从内存刷到磁盘？(跟 redis 的 sync 机制类似)



mysql 用`sync_binlog`参数控制 binlog 的刷盘时机，默认设置为 1

- 0：不去强制要求，由系统自行判断何时写入磁盘
- 1：每次 commit 的时候都要将 binlog 写入磁盘，最安全的设置
- N：每 N 个事务，才会将 binlog 写入磁盘


:::




### 25 MySQL是怎么保证高可用的？

[25 MySQL是怎么保证高可用的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/25%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e9%ab%98%e5%8f%af%e7%94%a8%e7%9a%84%ef%bc%9f.md) 这章就是讲 replication lagging 了








:::tip


:::





### 26 备库为什么会延迟好几个小时？


[26 备库为什么会延迟好几个小时？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/26%20%20%e5%a4%87%e5%ba%93%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bc%9a%e5%bb%b6%e8%bf%9f%e5%a5%bd%e5%87%a0%e4%b8%aa%e5%b0%8f%e6%97%b6%ef%bc%9f.md)


:::tip

:::




### 27 主库出问题了，从库怎么办？










### 28 读写分离有哪些坑？



[28 读写分离有哪些坑？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/28%20%20%e8%af%bb%e5%86%99%e5%88%86%e7%a6%bb%e6%9c%89%e5%93%aa%e4%ba%9b%e5%9d%91%ef%bc%9f.md)



```markdown
接下来，我们就看一下客户端直连和带 proxy 的读写分离架构，各有哪些特点。

1. 客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。 你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。
2. 带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。
理解了这两种方案的优劣，具体选择哪个方案就取决于数据库团队提供的能力了。但目前看，趋势是往带 proxy 的架构方向发展的。

但是，不论使用哪种架构，你都会碰到我们今天要讨论的问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。

这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。

前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能 100% 避免的。

不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。

接下来，我们就来讨论怎么处理过期读问题。

这里，我先把文章中涉及到的处理过期读的方案汇总在这里，以帮助你更好地理解和掌握全文的知识脉络。这些方案包括：

- 强制走主库方案；
- sleep 方案；
- 判断主备无延迟方案；
- 配合 semi-sync 方案；
- 等主库位点方案；
- 等 GTID 方案。
```





[gtid](http://mysql.taobao.org/monthly/2020/05/09/)


:::danger






:::





### 29 如何判断一个数据库是不是出问题了？

[29 如何判断一个数据库是不是出问题了？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/29%20%20%e5%a6%82%e4%bd%95%e5%88%a4%e6%96%ad%e4%b8%80%e4%b8%aa%e6%95%b0%e6%8d%ae%e5%ba%93%e6%98%af%e4%b8%8d%e6%98%af%e5%87%ba%e9%97%ae%e9%a2%98%e4%ba%86%ef%bc%9f.md)













## 其他



### 13 为什么表数据删掉一半，表文件大小不变？

[13 为什么表数据删掉一半，表文件大小不变？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/13%20%20%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a1%a8%e6%95%b0%e6%8d%ae%e5%88%a0%e6%8e%89%e4%b8%80%e5%8d%8a%ef%bc%8c%e8%a1%a8%e6%96%87%e4%bb%b6%e5%a4%a7%e5%b0%8f%e4%b8%8d%e5%8f%98%ef%bc%9f.md)


### 14 count()这么慢，我该怎么办？

[14 count()这么慢，我该怎么办？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/14%20%20count%28%29%e8%bf%99%e4%b9%88%e6%85%a2%ef%bc%8c%e6%88%91%e8%af%a5%e6%80%8e%e4%b9%88%e5%8a%9e%ef%bc%9f.md)







### 31 误删数据后除了跑路，还能怎么办？


### 32 为什么还有kill不掉的语句？



### 33 我查这么多数据，会不会把数据库内存打爆？



### 34 到底可不可以使用join？


### 35 join语句怎么优化？



### 36 为什么临时表可以重名？



### 37 什么时候会使用内部临时表？






### 38 都说InnoDB好，那还要不要使用Memory引擎？

[38 都说InnoDB好，那还要不要使用Memory引擎？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/38%20%20%e9%83%bd%e8%af%b4InnoDB%e5%a5%bd%ef%bc%8c%e9%82%a3%e8%bf%98%e8%a6%81%e4%b8%8d%e8%a6%81%e4%bd%bf%e7%94%a8Memory%e5%bc%95%e6%93%8e%ef%bc%9f.md)

```markdown
可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：

- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
- 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。

---
从中我们可以看出，这两个引擎的一些典型不同：

- InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
- 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
- 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
- InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
- InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

```

:::tip

这里延伸出的问题：

***heap table(堆表), IOT(索引组织表Index Organization Table), HOT(Heap Organized Table) 的区别***

- heap table: pgsql, mysql memory
- IOT: mysql innodb
- HOT: mysql myisam

oracle中既支持堆表，也支持IOT

:::


```markdown

Innodb的PAGE结构与HEAP结构的类似，不过在空闲空间管理上是完全不同的。前面是FILE HEADER/PAGE HEADER，中间是数据记录，数据记录也是从低地址往高地址写，和Oracle相反。这是因为BTREE存储结构不需要和slotted page一样，在块里放一个指示器，其行指示器的功能被BTREE替代了。

Innodb的这种存储结构，并不存在一个十分友好的类似Oracle的记录物理地址的ROWID这样的结构。所以要想定位某条数据记录，需要使用主键或者簇主键的方式来实现。主键可以定义某条记录的唯一性地址，因此Mysql的某张表上的其他索引(secondary index)的索引中存储的键值不像Oracle那样存储ROWID就可以了，而是存储的是主键中这一行的地址指针。基于一个secondary index的查询首先找出某些行的主键，然后再去扫描一次主键索引，才能找到相关行的地址，再找到这条记录。比起有rowid的Oracle数据库，这里多了一次主键索引的扫描。

可能有些朋友会觉得，是不是heap结构一定优于BTREE结构呢?其实还是回到今天的标题，没有完美的存储引擎。针对不同的应用场景，heap和BTREE各有优势。BTREE结构写入数据时按主键排序的，而且并发写入时数据并不是按照插入顺序写入数据块，如果主键存在一定的无序性，那么并发写入的数据可以被打散到多个块中，从而缓解热块冲突的压力。而二级索引的结构虽然对读取数据的操作有影响，对于存在多条索引的数据写入，数据修改，是有优势的。因为只要主键的键值不变，行数据的变化，行在数据块中存储的变化，不需要变更第二索引。

因此我们可以十分明确的肯定，不同的存储结构都各有利弊，并不能很直接的说哪种更好。不过在开发高并发，大数据量的系统的时候，了解存储引擎的一些特点，可以有效的避免一些问题。比如在Mysql、达梦等数据库中建表，尽可能定义一个显式的主键，从而避免系统自动添加主键。另外如果某张表的热块冲突特别严重的时候，主键可以考虑选择随机性的数据，而不是单边增长的数据，就可以有效的进行数据打散，从而降低热块冲突的可能性。

```



```markdown
Heap表，即使用MEMORY存储引擎的表，这种表的数据存储在内存中，由于硬件问题或者断电，数据容易丢失，所以只能从其他数据表中读取数据作为临时表或者只读缓存来使用。
```

storage, transaction, persist 几个方面




### 39 自增主键为什么不是连续的？

这个问题在之前看 [为什么 MySQL 的自增主键不单调也不连续 - 面向信仰编程](https://draveness.me/whys-the-design-mysql-auto-increment/) 时，就大概了解。

我先简要写下我目前的回答：

主键自增很重要，是为了保证使用bptree（innodb）能够尽量顺序写，避免页分裂嘛。但是在mysql8之前，auto_increment都是直接存在内存里的，如果mysql挂了重启，这个数据就没了。会重新根据主键id+1，重新获取auto_increment值，





### 41 mysql 数据复制


### 42 grant之后要跟着flush privileges吗？


### 43 分区表有什么问题，为什么公司规范不让使用分区表呢？



### 45 自增id用完怎么办？


```markdown
今天这篇文章，我给你介绍了 MySQL 不同的自增 id 达到上限以后的行为。数据库系统作为一个可能需要 7*24 小时全年无休的服务，考虑这些边界是非常有必要的。

每种自增 id 有各自的应用场景，在达到上限后的表现也不同：

- 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
- row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
- Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
- InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
- thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。

当然，在 MySQL 里还有别的自增 id，比如 table_id、binlog 文件序号等，就留给你去验证和探索了。
```





## [2024-10-15]





:::tip

[浅析数据库并发控制机制 | CatKang的博客](https://catkang.github.io/2018/09/19/concurrency-control.html)

其实就是三种，乐观锁、悲观锁和ts。也就是 MV-2PL(悲观锁)和MV-OCC(乐观锁，读写时不做验证，延迟到提交时验证)，以及MV-TO(ts-based)

- *CC 由数据库的调度器负责，事务本身感知不到可能导致数据一致性的冲突事务，调度器会 delay 或者 abort*，如果 delay 就延迟到合法时机，如果 abort 就直接回滚
- 本质上是一个取舍问题，*乐观锁不维护锁，吞吐很高，但是相应回滚也会比较多，而回滚比延迟的成本要高很多，所以在冲突较少和 validation 开销小的情况下，使用 OCC。LBCC 的方案则相反*

CC 的方法

- Lock，2PL，事务开始时，delay，
- timestamp，操作进行时，delay/abort，
- validation，最终提交前，abort，

*MVCC 可以基于乐观锁和悲观锁实现 OCC 和 PCC*，也就是

- `MV-2PL`，2PL，LBCC，lock，基于锁实现 MVCC，比如 MySQL
- `MV-TO`，timestamp，基于时间排序实现 MVCC，比如 PgSQL
- `MV-OCC`，OCC，validation，读写时不做验证，延迟到提交时验证

---

```markdown
这里从两个维度，对常见的并发控制机制进行分类：

1. 乐观程度
不同的实现机制，基于不同的对发生冲突概率的假设，悲观方式认为只要两个事务访问相同的数据库对象，就一定会发生冲突，因而应该尽早阻止；而乐观的方式认为，冲突发生的概率不大，因此会延后处理冲突的时机。如上图横坐标所示，乐观程度从左向右增高：

1、基于Lock：最悲观的实现，需要在操作开始前，甚至是事务开始前，对要访问的数据库对象加锁，对冲突操作Delay；
2、基于Timestamp：乐观的实现，每个事务在开始时获得全局递增的时间戳，期望按照开始时的时间戳依次执行，在操作数据库对象时检查冲突并选择Delay或者Abort；
3、基于Validation：更乐观的实现，仅在Commit前进行Validate，对冲突的事务Abort

可以看出，不同乐观程度的机制本质的区别在于，检查或预判冲突的时机，Lock在事务开始时，Timestamp在操作进行时，而Validation在最终Commit前。相对于悲观的方式，乐观机制可以获得更高的并发度，而一旦冲突发生，Abort事务也会比Delay带来更大的开销。
```

```markdown
对应上述每种乐观程度，都可以有多版本的实现方式，多版本的优势在于，可以让读写事务与只读事务互不干扰，因而获得更好的并行度，也正是由于这一点成为几乎所有主流数据库的选择。为了实现多版本的并发控制，需要给每个事务在开始时分配一个唯一标识TID，并对数据库对象增加以下信息：

txd-id，创建该版本的事务TID
begin-ts及end-ts分别记录该版本创建和过期时的事务TID
pointer: 指向该对象其他版本的链表

其基本的实现思路是，每次对数据库对象的写操作都生成一个新的版本，用自己的TID标记新版本begin-ts及上一个版本的end-ts，并将自己加入链表。读操作对比自己的TID与数据版本的begin-ts，end-ts，找到其可见最新的版本进行访问。根据乐观程度多版本的机制也分为三类：
```

以 乐观程度 和 是否MV 为横纵坐标，可以看到pgsql就使用MVTO，而mysql（InnoDB）和oracle则使用MVRC(MM read consistency)

```markdown
PostgreSQL uses multi-version timestamp ordering (MVTO) while InnoDB and Oracle use multi-version read consistency (MVRC). The main difference is that PostgreSQL is with-REDO/no-UNDO because it stores every row version in the main table, while Oracle/InnoDB implements with-REDO/with-UNDO where they reconstruct a block and/or row image from the log to provide read consistency.
```

*MVCC具体起到什么作用？我知道MVCC是用来实现再db中并发读写操作时保证数据一致性，那从CAP的角度出发，是为了保证Consistency吗？*

与其说MVCC是为了保证C，不如说是为了保证在C和A之间的平衡（想想之所以说InnoDB是50%C +50%A，就知道了）


:::



---

:::tip

[数据库事务隔离发展历史 | CatKang的博客](https://catkang.github.io/2018/08/31/isolation-level.html)

```markdown
ANSI SQL标准(1992)：基于异象
A Critique of ANSI(1995)：基于锁
A Generalized Theory(1999)：基于序列化图

Cursor Stability
Snapshot Ioslation
```

ANSI SQL92 用三种并发异常（Anomaly），划分出四种不同的隔离级别，将这种利弊权衡进行了（糟糕的）标准化

:::


---


:::tip

- `Consistency`，*一致性是最基本属性，其他三种都是为了实现一致性而存在的*
- `Isolation`，用事务的`隔离级别`保证事务的隔离性，为了保证并发场景下的一致性，引入隔离性，不同事务之间互不影响
- `Atomic`，用 undolog 保证事务执行失败后，直接回滚
- `Durability`，用 redolog 保证事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失

事务的 ACID 特性分别是什么？

- `Atomic`，事务里的所有操作要么全部完成，要么全部失败
- `Consistency`，事务执行一定要保证系统的一致性
- `Isolation`，事务与事务之间不会互相影响，一个事务的中间状态不会被其他事务感知
- `Durability`，事务一旦完成，所有写操作都要持久化

:::

---


:::tip


[事务隔离级别备忘 | 三点水](https://lotabout.me/2020/QQA-Isolation-Level-of-Database/)

---

隔离就是类似linux kernel的可见性，通过可见性来解决事务在并发请求（包括读写操作）时的数据一致性问题。比如什么RU、RC、RR、SR，随着隔离级别的加强，分别解决了脏写、脏读、不可重复读和幻读的问题。隔离级别越来越高，并发性就越差。当多个事务并发时，MySQL 利用加锁和阻塞来保证事务之间不同等级的隔离性。

RU、RC、RR、SR 分别是什么？

- `RU`读操作不加锁，可能会`脏读`(解决了`脏写`问题)
- `RC`只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近。所以在多次读操作时，会发生`不可重复读`(解决了`脏读`问题)
- `RR`多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能会发生`幻读`(解决了`不可重复读`问题)
- `SR`InnoDB 隐式地将全部查询语句加上共享锁，解决了`幻读`问题，但是性能很差

---

RC隔离

Read Committed（读取已提交）

- 只读取提交的数据，并等待其他事务释放排他锁。
- 这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。
- 它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。
- 这种隔离级别也支持所谓的不可重复读，因为同一事务的其他实例在该实例处理期间，可能会有新的 commit，所以同一个 select 可能返回不同结果

RU隔离

Read Uncommitted（读取未提交内容）

- 在读数据时，不会检查或者使用任何锁。
- 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。*RU 很少被使用，因为它的性能比其他隔离级别好不了太多，并且会导致脏读*

RR隔离

Repeatable Read（可重复读）

事务 A 读取一条数据后，事务 B 对该数据修改并提交，事务 A 再读取该数据，读到的还是原来的内容

- 像 RC 那样读数据，但会保持共有锁，直到事务结束
- 这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。
- 不过理论上，这会导致另一个棘手的问题：幻读，简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。
- InnoDB 和 Falcon 存储引擎通过 MVCC 机制解决了该问题。(*其实多版本只是解决不可重复读问题，而加上间隙锁 (也就是它这里所谓的并发控制) 才解决了幻读问题*)

SR隔离

Serializable（可串行化）

- 工作方式类似于可重复读。但它不仅会锁定受影响的数据，还会锁定这个范围。这就阻止了新数据插入查询所涉及的范围。
- 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。


:::

---


:::tip

- `脏读`，t1 在修改之前提交，t2 读取，t1 回滚，t2 读取了从未提交的数据，*读未提交时，读事务直接读取主记录，无论更新事务是否完成*
- `不可重复读`t1 读取，t2 修改该数据并提交，t1 重新读取，数据已被修改，数据不同
- `幻读`数据不同*每次都能读到最新数据*

---

*不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差*，对于不同的事务，采用不同的隔离级别分别有不同的结果

- `脏读`一个事务可以读取另一个尚未提交事务的修改数据 (一个事务内修改了数据，另一个事务读取并使用了这个数据)
- `不可重复读`在同一个事务中，同一个查询在 T1 时间读取某一行，在 T2 时间重新读取这一行时候，这一行的数据已经发生修改，可能被更新了，也可能被删除了 (一个事务内连续读了两次数据，中间另一个事务修改了这个数据，导致第一个事务前后两次读的数据不一致)
- `幻读`在同一事务中，同一查询多次进行时候，由于其他 insert 的事务提交，导致每次返回不同的结果集 (一个事务内修改了涉及全表的数据，另一个事务往这个表里面插入了新的数据，第一个事务出现幻读)
- `更新丢失`一个事务内变更了数据，另一个事务修改了这个数据，最后前一个事务 commit 导致另一个事务的变更丢失

:::


---



:::tip

***MVCC 机制的原理和实现：MVCC 是什么?ReadView 是什么？高水位、低水位?***

---

InnoDB 使用 MVCC 来支持高并发，并且实现了四个标准的隔离级别，通过间隙锁 next-key locking 策略防止幻读的出现

- MVCC 就是*读请求直接访问对应版本的数据，从而避免读写事务和只读事务互相阻塞*，同一个数据有多个版本，*最大的好处是读写不冲突，只有同时写操作冲突，可以很大程度上提升性能*
- MVCC 的目的就是，实现数据库的隔离级别

***MVCC=版本链+ReadView（就是快照，用来做可见性判断）***

通过版本链的 trx_id 和 ReadView 的高低水位比较后，决定使用哪个版本

- ReadView 的结构
	- m_ids
	- min_trx_id 低水位
	- max_trx_id 高水位
	- creator_trx_id
- undolog 版本链的结构
	- trx_id，事务 id
	- roll_pointer 回滚指针

:::


---



:::tip

[《MySQL技术内幕：InnoDB存储引擎（第2版）》 | 三点水](https://lotabout.me/2020/Book-Notes-InnoDB-Engine-2nd-edition/)

---

- 事务相关：支持 ACID 事务、MVCC、InnoDB 锁机制、redolog
- 性能相关：插入缓冲、double write、BP(buffer pool)、AHI(Adaptive Hash Index)自适应哈希索引

但是实际上事务相关特性，本质上也还是为了优化性能，比如说之所以用 MVCC 就是为了能够并发事务，而 InnoDB 锁机制和 redolog 本质上来说都是为了保证 MVCC 正常运行。

另外，也有一些其他特性，比如外键、行级锁定、共享表空间和独立表空间等等，这些都比较简单，就不太重要了。

- `插入缓冲 (insert buffer)`，*加速插入操作*，插入缓冲用于非聚簇索引的插入和更新操作，先判断插入的非聚簇索引是否在缓存池中，如果在则直接插入，否则插入到`插入缓存对象`中。再以一定的频率进行插入缓冲和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，提高对非聚簇索引的插入性能
- `二次写 (double write)`由两部分组成，一部分是内存中的`double write buffer`，大小为 2MB，另一部分是物理磁盘上共享表空间连续的 128 个页，大小也为 2MB。在对缓冲池的脏页刷新时，并不直接写磁盘，而是通过 memcpy 函数将脏页先复制到内存中的该区域，之后通过`double write buffer`再分两次，每次 1MB 顺序地写入共享空间的物理磁盘上，然后马上调用 fsync 函数，同步磁盘，避免 OS 缓冲写带来的问题
- `自适应哈希索引 (adaptive hash index)`*自动在内存中创建 hash 索引来加速读操作*，innoDB 会根据访问的频率和模式，为热点页建立哈希索引，来提高查询效率。索引通过缓存池的 B+ 树页构造而来，因此建立速度很快，innoDB 存储引擎会监控对表上各个索引页的查询，如果观察到建立哈希索引可以带来速度上的提升，则建立哈希索引，所以叫做`自适应哈希索引`
- `缓存池`为了提高数据库的性能，引入缓存池的概念，通过参数可以设置缓存池的大小和实例个数，缓存池可以存储一下内容：索引页、数据页、undo 页、插入缓冲、自适应哈希索引、innoDB 存储的锁信息和数据字典信息 (data dict)
- *使用可预测读作为磁盘数据读取方式*


:::


---



:::tip

[这次终于懂了，InnoDB的七种锁（收藏）](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651967369&idx=1&sn=d639abf6772a72c25cc2537749258163)


- [innodb源码分析之基础数据结构 · innodb源码分析 · 看云](https://www.kancloud.cn/digest/innodb-zerok/195085)
- [MySQL 之 InnoDB 锁系统源码分析 - 掘金](https://juejin.cn/post/7075853223625490468)
- [秒懂InnoDB的锁 - 菜刚RyuGou的博客](https://i6448038.github.io/2019/02/23/mysql-lock/)
- [MySQL 全局锁、表级锁、行级锁，你搞清楚了吗？](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247496937&idx=1&sn=398da5cc033c93f5a73e75c585fc9dde)

[秒懂InnoDB的锁 - 菜刚RyuGou的博客](https://i6448038.github.io/2019/02/23/mysql-lock/)



---

- 共享锁 (S锁, shared lock)
- 排他锁 (X锁, exclusive lock)
- 意向锁  (I锁, intention lock)
- 意向共享锁 (IS锁, 表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁)
- 意向排他锁 (IX锁, 类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁)
- 插入意向锁  (insert intention lock)
- 自增锁  auto-inc lock

行锁

- 记录锁  (record lock)
- 间隙锁  (gap lock)
- 临键锁  (next-key lock)

我说下我的理解哈，shared lock和exclusive lock就是mutex和rwmutex,所有语言里都有类似的锁机制，不多说。intention lock其实就是IsLocked，用来判断是否加锁，进而决定下一步操作是sleep还是spin什么的，也很常用。下面的gaplock，next-key lock 都是MVCC相关的锁，可以理解。自增锁auto-inc lock是用来保证自增字段唯一性的，防止并发插入时，某个自增字段的数据重复。我不太理解record lock和insert intention lock有啥用。mutex(exclusive lock)不是已经能够在写操作时的行级锁定了吗?为什么还需要record lock呢?还有不是已经有intention lock了吗?为什么还需要insert intention lock?


:::

---


:::tip

MySQL 选择使用 B+树而不是 B 树作为其存储引擎主要基于以下考虑:

- B+ 树的叶子节点形成有序链表，使得范围查询更加高效。在数据库中，范围查询是非常常见的操作，因此 B+树更适合处理这类查询。
- B+树的内部节点只存储索引信息，相比之下，B树的内部节点也存储实际数据。这使得 B+树更加紧凑，可以存储更多的索引数据在内存中，提高查询性能。
- B+ 树的有序链表叶子节点可以更好地支持顺序访问，对于按顺序获取数据的查询操作，B+ 树的性能更好。

综上所述，MySQL 选择使用 B+ 树作为其存储引擎是为了提高范围查询和顺序访问的性能，并且能够更好地利用内存空间。


:::


- [这句简单的sql，如何加索引？颠覆了我多年的认知](https://mp.weixin.qq.com/s/uuavfy3O6UiKLfCesddCUA)
- [浅析MySQL代价模型：告别盲目使用EXPLAIN，提前预知索引优化策略_后端_京东零售技术_InfoQ写作社区](https://xie.infoq.cn/article/51903ec540dbcea0debeb1cff)





---



```yaml

qs:

  - q: 为什么会产生分布式DB？
    u: https://lvwenhan.com/tech-epic/507.html


  - q: DB的演化

  - q: DB 故障恢复机制的演化
    u: https://catkang.github.io/2019/01/16/crash-recovery.html

  - q: OLTP (Online Transaction Processing，联机事务处理), OLAP (Online Analytical Processing，联机分析处理), HTAP (Hybrid Transactional and Analytical Processing) 成为主流数据库的一项基础能力
    x: |
      分别针对不同的应用场景和需求

      - OLTP 侧重于事务处理，强调快速响应和数据的一致性。
      - OLAP 侧重于数据分析，强调数据的读取速度和多维分析能力。
      - HTAP 尝试结合OLTP和OLAP的特点，支持在一个系统中同时进行事务处理和数据分析。

      从应用场景、数据模型、查询类型、性能要求、数据量、数据更新频率、系统架构都不同
  - q: 湖仓一体是啥? 数据仓库、数据湖
    x: 数据仓库里的是结构化数据，但是全部数据（structured, semi-structured, non-structured）都可以忘数据湖里扔

  - q: "***B+Tree SE***"
    u: https://www.youtube.com/watch?v=9XtACKzFIRc
    x: 这个视频相当有干货，从存储引擎为什么使用bptree说起，到各种tree的比较，再到写操作时bptree会执行哪些操作，再到这几种使用bptree的存储引擎分别是怎么保证ACID的，再到innodb和boltdb使用bptree的具体细节。


```


```yaml
- q: "***监控 MySQL 需要采集哪些指标？怎么监控 MySQL 的流量？***"
  x: |
    - `主从复制`，比如复制线程运行状态、延迟时间
    - `查询吞吐量`，比如 Questions 计数器
    - `慢查询`
    - `连接数`，比如最大连接数、当前连接数、活跃连接数、累计连接数
    - `innoDB 缓冲池`，比如缓冲池的总页数、空闲页数、利用率等参数
  qs:
    - q: 怎么用prom监控和analyze redis的big-keys, hot-keys?
    - q: redis metrics

```








## [archive] mysql InnoDB


花了40min码了一下mysql相关内容，发现其实大部分都是InnoDB相关的东西，包括之前的一些认知都是错误的。

比如说压根就没有什么“MySQL锁机制”，只有“InnoDB锁机制”。index也是存储引擎实现的。

换句话说，之前说的“搞懂了InnoDB，就搞懂了mysql存储引擎”还是说小了，应该说“搞懂了InnoDB，就搞懂了80%的mysql（剩下20%就是cpoe，还有mysql replication, mysql cluster了）”


---

:::tip

InnoDB 是 MySQL 的默认存储引擎，搞懂了 InnoDB，基本上就可以说搞懂 MySQL 的存储引擎。

关于 InnoDB 的知识点太杂了，各种特性，每个都很难搞，因为 InnoDB 的特性确实强大。但是实际上大部分文档都是把这些特性拆开了说，就让人一头雾水，实际上无非是两种：

- 事务相关：支持 ACID 事务、MVCC、InnoDB 锁机制、redolog
- 性能相关：插入缓冲、二次写、缓冲池、自适应哈希索引

但是实际上事务相关特性，本质上也还是为了优化性能，比如说之所以用 MVCC 就是为了能够并发事务，而 InnoDB 锁机制和 redolog 本质上来说都是为了保证 MVCC 正常运行。

另外，也有一些其他特性，比如外键、行级锁定、共享表空间和独立表空间等等，这些都比较简单，就不太重要了。

:::



### ***index***

索引覆盖

:::tip
索引覆盖就是直接查索引就可以获得数据，不需要再查数据表。
:::


```markdown

索引覆盖（Index Covering）是指当一个查询可以完全使用索引来满足时，不需要进行额外的磁盘访问，即索引包含了查询所需的所有列。这意味着查询可以直接从索引中获取结果，而无需回表查询实际的数据行。

当一个查询需要返回的列都在某个索引中存在，并且查询的条件可以通过该索引进行筛选时，就可以实现索引覆盖。这样的查询可以直接从索引中获取满足条件的数据行，而不需要额外的磁盘访问来获取实际的数据。

索引覆盖对查询性能有很大的影响。通过避免回表查询，可以减少磁盘访问的次数，从而提高查询的速度和效率。特别是当查询的结果集较大或者需要进行范围查询时，索引覆盖可以显著提升查询性能。

需要注意的是，并非所有的查询都可以实现索引覆盖。如果查询需要返回的列不完全包含在索引中，或者查询的条件无法通过索引进行筛选，那么就无法实现索引覆盖，需要进行回表查询来获取完整的数据行。

因此，在设计数据库索引时，可以考虑创建适合查询的索引，以尽可能实现索引覆盖，提高查询性能。

```

---

索引算法

常见索引算法有B+ Tree, B Tree, R Tree, Hash

最重要的就是B+树，R树适用于myisam，hash适用于memory

---

```markdown
MRR和索引都是为了把随机IO变成顺序IO，但是这两种方法有啥区别呢？

---

MRR（Multi-Range Read，多范围读取）和索引（Index）都是用于优化随机IO操作，将其转换为更高效的顺序IO操作。虽然它们的目标相似，但是它们的实现方式和应用场景有一些区别。

**MRR** 是一种针对读取操作的优化技术。它通过在一个请求中读取多个连续范围的数据，以减少读取磁盘的次数。MRR通常用于处理顺序扫描（Sequential Scan）或范围查询（Range Query）等需要从磁盘读取大量连续数据的场景。通过减少磁盘IO次数，MRR可以显著提高读取操作的性能。

**索引** 是一种数据结构，用于快速定位和访问存储在数据库或文件系统中的数据。索引通常基于某种键值（Key）或属性（Attribute）来组织数据，以便在查询时能够快速定位所需的数据。通过使用索引，可以减少需要扫描的数据量，从而提高查询的效率。索引适用于各种读取和写入操作，特别是在需要快速查找或过滤数据时非常有用。

因此，MRR主要关注的是优化读取操作的效率，而索引则提供了一种更快速地定位和访问数据的方式。它们可以在不同的场景中使用，根据具体的需求选择适当的方法来优化IO操作。

```

```markdown
mysql的默认索引算法是什么？

---

MySQL的默认索引算法是B+树（B+ Tree）。

B+树是一种平衡的多叉树数据结构，它能够有效地支持范围查询和快速的数据插入与删除操作。B+树的特点包括：

1. 所有数据都存储在叶子节点上，而非叶子节点只存储索引信息，这样可以减少磁盘访问次数。
2. 叶子节点之间通过指针连接成一个有序链表，方便范围查询操作。
3. B+树的节点是有序的，每个节点都有一个上下界，使得查找操作可以快速定位到目标节点。
4. B+树的高度相对较低，使得磁盘IO开销较小。

由于B+树的特性，它在数据库系统中被广泛应用于索引的实现。MySQL默认使用B+树作为索引算法，无论是主键索引、唯一索引还是普通索引，都是基于B+树实现的。这使得MySQL能够高效地支持各种查询和数据操作，并提供良好的性能和可扩展性。

```

```markdown
### 索引原理 (索引是怎么实现的？)

**索引类似目录，把关键词提取出来，查询时直接读取 keyword，或者按照 keyword 查询**

没有索引，就像是一本工具书，想找与 xxx 相关的内容，还需要从第一个字，一行一行地翻，就很麻烦。

索引就是按照某个具体算法（哈希，二叉树，B 树等），将数据从全部数据里进行提取，维护成一个索引文件，然后系统在进行数据查询的时候，发现如果查询条件刚好满足索引条件，就可以从索引文件中快速定位数据所在的位置。
```

这个说法不能说完全正确。

---


聚簇索引和非聚簇索引，分别是什么？

:::tip
*聚簇索引和非聚簇索引的区别就是，叶子节点是不是存有行数据*

聚簇索引不是主键索引，聚簇索引也不是三星索引，总是有人把这三个概念搞混。

聚簇索引是一种物理存储方式，它决定了数据在磁盘上的物理排序顺序。聚簇索引的目的是将相关的行物理上存储在一起，以提高范围查询的性能。

:::


聚簇索引是以主键 ID 为节点生成的，非子节点都是 id，叶子节点（最下面一层）会相互连接变成双向链表，并且叶子节点会存储对应的行记录。

而非聚簇索引的节点是基于索引列，找到了对应叶子节点的索引值后，会根据叶子节点存储的行记录们指针们，回到聚簇索引去查找行记录（这个过程也叫做回表）。


---

explain

extra, type

extra: index, temporary, filesort

type: const, range, index, ALL, ref, fulltext (system, eq_type, ref_or_null, index_merge, unique_subquery, index_subquery)

- *[MySQL EXPLAIN 结果集分析 - 附带大量案例](https://mp.weixin.qq.com/s/p5UKuh1yY3P4zrOzVBmY1w)*
- [这句简单的 sql，如何加索引？颠覆了我多年的认知](https://mp.weixin.qq.com/s/uuavfy3O6UiKLfCesddCUA)


---



```markdown

MySQL 选择使用 B+ 树而不是 B 树作为其存储引擎主要基于以下考虑：


- B+ 树的叶子节点形成有序链表，使得范围查询更加高效。在数据库中，范围查询是非常常见的操作，因此 B+ 树更适合处理这类查询。
- B+ 树的内部节点只存储索引信息，相比之下，B 树的内部节点也存储实际数据。这使得 B+ 树更加紧凑，可以存储更多的索引数据在内存中，提高查询性能。
- B+ 树的有序链表叶子节点可以更好地支持顺序访问，对于按顺序获取数据的查询操作，B+ 树的性能更好。


综上所述，MySQL 选择使用 B+ 树作为其存储引擎是为了提高范围查询和顺序访问的性能，并且能够更好地利用内存空间。

```


---

**索引的创建原则**

:::tip
创建索引的几个关键字：

左选小写修

最左前缀索引、选择性、小字段、写操作频率、修改索引

:::


```markdown

- `选择性/识别度` *识别度越高的字段应该放在前面，使用识别度高的字段作为索引*，什么是识别度？就是字段不重复的比例`count(distinct col)/count(*)`（不重复的索引值（也称为基数 cardinality) 和数据表的记录总数的比值），区间为`(0,1]`，*识别度越高，扫描相同行数，需要的次数就越少，这是由 B+ 树的性质决定的*
- `前缀索引` *尽量使用前缀来索引，如果索引字段的值很长，最好使用值的前缀来索引*例如，TEXT 和 BLOG 类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度

---

- `最左前缀原则` 实际上就是前缀索引在复合索引场景下的使用，复合索引可以减少开销、覆盖索引、性能（相比单列索引）更好
- `索引拓展原则（用修改代替新建）`比如表中已有 a 的索引，现在要加（a,b）的索引，那么只要修改原来的索引即可

- `索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引` *尽量使用数据量少的索引（高频但是数据量少的），如果索引的值很长，那么查询的速度会受到影响*例如，对一个 CHAR(100) 类型的字段进行全文检索需要的时间肯定要比对 CHAR(10) 类型的字段需要的时间要多。
- 更新非常频繁的字段不适合创建索引
- =和 in 可以乱序，MySQL 查询优化器会帮你优化成索引可以识别的形式

```



```shell
# 获取该字段的选择性
select 1.0*count(distinct <column_name>)/count(*) from <table_name>
# 通过修改num
select 1.0*count(distinct left(<FirstName>,<num>))/count(*) from <table_name>
# 添加索引，如果num=5，则
alter table <table_name> add key(FirstName(5))
```

```markdown
非常抱歉，我误解了你的问题。在MySQL中，"最左前缀原则"是一个重要的原则，用于创建复合索引时的考虑。下面是关于"最左前缀原则"的一些要点：

1. **最左前缀匹配**：在一个复合索引中，MySQL只能使用索引的最左前缀来进行匹配。这意味着只有在查询中包含复合索引的最左边的列时，索引才会被使用。例如，如果索引是 (col1, col2, col3)，那么查询中只包含 col1 或 (col1, col2) 才能使用该索引。

2. **索引顺序的重要性**：复合索引的列的顺序非常重要。根据查询的频率和过滤条件的选择，将最常用的列放在索引的最左边。这样可以更好地利用索引进行过滤和排序操作。

3. **覆盖索引**：在某些情况下，复合索引可以成为覆盖索引。如果查询只需要索引中的列而不需要访问实际的表数据，那么查询可以通过索引本身完成，而无需额外的表访问操作。这可以提高查询的性能。

4. **选择合适的前缀长度**：可以选择在复合索引中使用前缀长度，以减少索引的大小。但是需要权衡索引大小和查询的效率。选择适当的前缀长度，既能减小索引的存储空间，又能保持查询的效率。

遵循"最左前缀原则"可以帮助合理设计和使用复合索引，提高查询性能和索引效率。请根据具体的查询模式和业务需求，合理选择索引的顺序和前缀长度。
```

```markdown

除了“最左前缀”，还有哪些索引创建原则？

---
除了"最左前缀"原则之外，还有一些其他索引创建原则和最佳实践，包括：

选择唯一性：选择具有唯一性的列作为索引列，这样可以确保索引的准确性和有效性。

避免过度索引：不要过度使用索引，因为每个索引都需要占用存储空间并带来额外的维护开销。仅在需要时创建必要的索引。

选择高基数列：选择具有高基数（不同值数量）的列作为索引列。高基数的列可以更好地过滤和定位数据。

考虑查询频率：考虑查询的频率和重要性，在经常使用的列上创建索引，以提高查询性能。

考虑排序和分组操作：如果查询需要进行排序或分组操作，可以在排序或分组的列上创建索引，以提高排序和分组的效率。

```

其实，最主要的索引创建原则其实就是最左前缀和唯一性。除此之外就是一些tips，比如什么查询频率、尽量不使用符合索引、不要过度索引、考虑排序和分组操作。

最左前缀的本质是ICP。

```markdown
ICP只在满足"最左前缀"条件时起作用。如果查询条件中包含了索引的非最左前缀列，ICP将无法生效，MySQL会在存储引擎层面进行完整的行过滤，这可能会导致性能下降。

总结来说，"最左前缀"原则和ICP的本质是基于索引列的前缀进行索引范围扫描，以减少需要访问的行数，提高查询性能。
```

我们还是拿图书馆举例，






---

复合索引：

- *慎重建立复合索引，尽量用单字段索引代替*
- 正确选择复合索引中的主列字段，通常是可选择性高的字段。
- 如果复合索引的几个字段经常同时以 AND 方式出现在 where 子句，建立复合索引；如果只是单独出现在 where 子句，只需要单字段索引。
- 复合索引的字段最好不要超过 3 个。

三星索引




### lock

- innoDB 间隙锁是啥？有啥缺点？
- innoDB 间隙锁是什么？InnoDB 的锁定是通过在指向数据记录的第一个索引键之前和最后一个索引键之后的空域空间标记锁定信息实现的。这种锁定方式被称为 "NEXT-KEY locking"（间隙锁）
- innoDB 间隙锁有哪些缺点？锁定一个范围之后，即使某些不存在的键值也会被无辜锁定，造成锁定的时候无法插入键值锁定内的任何数据

---

*[这次终于懂了，InnoDB 的七种锁（收藏）](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651967369&idx=1&sn=d639abf6772a72c25cc2537749258163)*

[秒懂 InnoDB 的锁 - 菜刚 RyuGou 的博客](https://i6448038.github.io/2019/02/23/mysql-lock/)


```markdown

innoDB 锁类型


- 共享锁，排他锁  shared and exclusive lock
- 意向锁  intention lock

---

- 记录锁  record lock
- 间隙锁  gap lock
- 临键锁  next-key lock
- 插入意向锁  insert intention lock
- 自增锁  auto-inc lock

```


```markdown
行锁分为共享锁和排他锁，但是 InnoDB 还有两种内部使用的意向锁，这两种意向锁都是表锁；
而为了允许行锁和表锁共存，这就是“多粒度锁机制”
```

```markdown

我说下我的理解哈，shared lock和exclusive lock就是mutex和rwmutex，所有语言里都有类似的锁机制，不多说。intention lock其实就是IsLocked，用来判断是否加锁，进而决定下一步操作是sleep还是spin什么的，也很常用。下面的gap lock, next-key lock 都是MVCC相关的锁，可以理解。自增锁auto-inc lock是用来保证自增字段唯一性的，防止并发插入时，某个自增字段的数据重复。我不太理解record lock和insert intention lock有啥用。mutex(exclusive lock)不是已经能够在写操作时的行级锁定了吗？为什么还需要record lock呢？还有不是已经有intention lock了吗？为什么还需要insert intention lock？

```


---


[MySQL 全局锁、表级锁、行级锁，你搞清楚了吗？](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247496937&idx=1&sn=398da5cc033c93f5a73e75c585fc9dde)

table lock和page lock都不需要担心，

row lock, column lock

当然是锁粒度更小的，开销更小、加锁更快，这个是毫无疑问的。



### ***transaction/MVCC***

:::tip
整理这部分内容之前，我先根据现有知识概述一下这部分内容

首先，事务锁隔离是牢不可分的，也都是innodb相关的知识

隔离就是类似linux kernel的可见性，通过可见性来解决事务在并发请求（包括读写操作）时的数据一致性问题。比如什么RU、RC、RR、SR，随着隔离级别的加强，分别解决了脏写、脏读、不可重复读和幻读的问题。隔离级别越来越高，并发性就越差。

那隔离级别是怎么实现的呢？隔离级别就是通过MVCC实现的。

MVCC=版本链+ReadView

:::

---

innodb是怎么保证ACID的？

- `一致性`，*一致性是最基本属性，其他三种都是为了实现一致性而存在的*
- `隔离性`，用事务的`隔离级别`保证事务的隔离性，为了保证并发场景下的一致性，引入隔离性，不同事务之间互不影响
- `原子性`，用 undolog 保证事务执行失败后，直接回滚
- `持久性`，用 redolog 保证事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失

---

隔离级别是什么？RU、RC、RR、SR 分别是什么？各自会解决和导致什么问题？

- *隔离级别是一种约定，告诉我们可能会有哪些问题，一定不会有哪些问题*
- *RU/RC/RR/SR，随着隔离级别的加强，分别解决了脏写/脏读/不可重复读/幻读的问题*


RU、RC、RR、SR 分别是什么？

- `RU`读操作不加锁，可能会`脏读`(解决了`脏写`问题)
- `RC`只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近。所以在多次读操作时，会发生`不可重复读`(解决了`脏读`问题)
- `RR`多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能会发生`幻读`(解决了`不可重复读`问题)
- `SR`InnoDB 隐式地将全部查询语句加上共享锁，解决了`幻读`问题，但是性能很差


`脏读`、`不可重复读`、`幻读`分别是什么？

- `脏读`，t1 在修改之前提交，t2 读取，t1 回滚，t2 读取了从未提交的数据，*读未提交时，读事务直接读取主记录，无论更新事务是否完成*
- `不可重复读`t1 读取，t2 修改该数据并提交，t1 重新读取，数据已被修改，数据不同
- `幻读`数据不同*每次都能读到最新数据*


---

事务的四种隔离级别？

事务中最复杂的问题都是由事务隔离性引起的。
*当多个事务并发时，MySQL 利用加锁和阻塞来保证事务之间不同等级的隔离性*
完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务，这样会严重影响性能。



```mdx-code-block
<Tabs>
<TabItem value="RC隔离">
```

Read Committed（读取已提交）


- 只读取提交的数据，并等待其他事务释放排他锁。
- 这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。
- 它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。
- 这种隔离级别也支持所谓的不可重复读，因为同一事务的其他实例在该实例处理期间，可能会有新的 commit，所以同一个 select 可能返回不同结果


```mdx-code-block
</TabItem>
<TabItem value="RU隔离">
```

Read Uncommitted（读取未提交内容）

- 在读数据时，不会检查或者使用任何锁。
- 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。*RU 很少被使用，因为它的性能比其他隔离级别好不了太多，并且会导致脏读*


```mdx-code-block
</TabItem>
<TabItem value="RR隔离">
```

Repeatable Read（可重复读）

事务 A 读取一条数据后，事务 B 对该数据修改并提交，事务 A 再读取该数据，读到的还是原来的内容

- 像 RC 那样读数据，但会保持共有锁，直到事务结束
- 这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。
- 不过理论上，这会导致另一个棘手的问题：幻读，简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。
- InnoDB 和 Falcon 存储引擎通过 MVCC 机制解决了该问题。(*其实多版本只是解决不可重复读问题，而加上间隙锁 (也就是它这里所谓的并发控制) 才解决了幻读问题*)


```mdx-code-block
</TabItem>
<TabItem value="SR隔离">
```

Serializable（可串行化）

- 工作方式类似于可重复读。但它不仅会锁定受影响的数据，还会锁定这个范围。这就阻止了新数据插入查询所涉及的范围。
- 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

```mdx-code-block
</TabItem>
</Tabs>
```

---

不同隔离级别，可能导致哪些问题？

*不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差*，对于不同的事务，采用不同的隔离级别分别有不同的结果

- `脏读`一个事务可以读取另一个尚未提交事务的修改数据 (一个事务内修改了数据，另一个事务读取并使用了这个数据)
- `不可重复读`在同一个事务中，同一个查询在 T1 时间读取某一行，在 T2 时间重新读取这一行时候，这一行的数据已经发生修改，可能被更新了，也可能被删除了 (一个事务内连续读了两次数据，中间另一个事务修改了这个数据，导致第一个事务前后两次读的数据不一致)
- `幻读`在同一事务中，同一查询多次进行时候，由于其他 insert 的事务提交，导致每次返回不同的结果集 (一个事务内修改了涉及全表的数据，另一个事务往这个表里面插入了新的数据，第一个事务出现幻读)
- `更新丢失`一个事务内变更了数据，另一个事务修改了这个数据，最后前一个事务 commit 导致另一个事务的变更丢失


---



```markdown
什么是 CC？有哪些单版本的 CC 方法？基于这些单版本 CC 方法，MVCC 有哪些不同的实现？

- *CC 由数据库的调度器负责，事务本身感知不到可能导致数据一致性的冲突事务，调度器会 delay 或者 abort*，如果 delay 就延迟到合法时机，如果 abort 就直接回滚
- 本质上是一个取舍问题，*乐观锁不维护锁，吞吐很高，但是相应回滚也会比较多，而回滚比延迟的成本要高很多，所以在冲突较少和 validation 开销小的情况下，使用 OCC。LBCC 的方案则相反*


CC 的方法

- Lock，2PL，事务开始时，delay，
- timestamp，操作进行时，delay/abort，
- validation，最终提交前，abort，

*MVCC 可以基于乐观锁和悲观锁实现 OCC 和 PCC*，也就是

- `MV-2PL`，2PL，LBCC，lock，基于锁实现 MVCC，比如 MySQL
- `MV-TO`，timestamp，基于时间排序实现 MVCC，比如 PgSQL
- `MV-OCC`，OCC，validation，读写时不做验证，延迟到提交时验证

```

---

- `Lost Update`和`Constraint Violation`都是`Fuzzy Read`的变种
- 怎么设置隔离级别？`set transaction isolation level Read`


---

MVCC 是什么？ReadView 是什么？高水位、低水位？


:::tip

InnoDB 使用 MVCC 来支持高并发，并且实现了四个标准的隔离级别，通过间隙锁 next-key locking 策略防止幻读的出现

- MVCC 就是*读请求直接访问对应版本的数据，从而避免读写事务和只读事务互相阻塞*，同一个数据有多个版本，*最大的好处是读写不冲突，只有同时写操作冲突，可以很大程度上提升性能*
- MVCC 的目的就是，实现数据库的隔离级别
- `MVCC=版本链+ReadView`，*通过版本链的 trx_id 和 ReadView 的高低水位比较后，决定使用哪个版本*
- ReadView 就是快照，用来做可见性判断


:::


```markdown
- ReadView 的结构
 - m_ids
 - min_trx_id 低水位
 - max_trx_id 高水位
 - creator_trx_id
- undolog 版本链的结构
 - trx_id，事务 id
 - roll_pointer 回滚指针
```

---


RC 和 RR 有什么区别？RC 和 RR 的 MVCC 机制为什么不同？

*RC 和 RR 的区别在于 ReadView 快照生成时机不同，导致可见性不同*

- RC 在每次读取数据前都生成一个 ReadView
- RR 在第一次读取数据时生成一个 ReadView

---

- RR 和 RC 在锁方面的区别？
- RR 和 RC 在复制方面的区别？
- RR 和 RC 在一致性读方面的区别？RC 支持半一致性读，RR 不支持

为什么 MySQL 把 RR 作为默认的隔离级别呢？

MySQL 数据库的默认隔离级别是 RR，但是实际情况是使用 RR 和 RC 都不少，比如淘宝和网易都是使用的 RC 隔离级别



---

二段锁 2PL 是啥？


```markdown
还是不懂，2PL和怎么和事务隔离级别和MVCC结合使用的

---

在 MySQL 中，2PL 和事务隔离级别是并发控制的两个不同概念，而 MVCC 是 MySQL 使用的一种实现并发控制的机制。

2PL 是一种并发控制协议，它确定了如何获取和释放锁来控制事务对数据的访问。它是一种实现并发控制的方法，用于确保事务的隔离性和一致性。
事务隔离级别是数据库管理系统提供的一种机制，用于控制事务之间的隔离程度。MySQL 提供了多个事务隔离级别，如读未提交、读提交、可重复读和串行化。这些隔离级别定义了事务在并发执行时能否看到其他事务进行的修改。

因此，2PL 是一种并发控制协议，用于控制事务对数据的访问，而事务隔离级别和 MVCC 是 MySQL 提供的机制和方法，用于实现事务的隔离性和并发性能。它们之间的关系是：MySQL 使用 2PL 和 MVCC 来实现不同的事务隔离级别，以满足不同的隔离要求，并提供适当的并发控制机制。

---

意思是MVCC和2PL都是实现不同事务隔离级别的方法？

---

不完全正确。请允许我澄清一下：

MVCC（多版本并发控制）和2PL（两阶段锁定）是两种不同的并发控制方法，用于实现事务的隔离性和并发性能。它们都可以与不同的事务隔离级别结合使用，但并不是说 MVCC 实现了所有事务隔离级别，而 2PL 实现了其他的事务隔离级别。

具体来说：

1. MVCC 是一种并发控制机制，通过使用版本控制来解决并发读写冲突。在 MVCC 中，每个数据项都有多个版本，每个版本与事务的时间戳相关联。读操作只能看到在其开始时间之前已经提交的版本，而对于在其开始时间之后修改的版本是不可见的。MVCC 可以在一定程度上提高并发性能。

2. 2PL 是一种并发控制协议，它通过加锁和释放锁的方式来控制事务对数据项的访问。事务在需要访问某个数据项时请求获取锁，如果该数据项已被其他事务锁定，则当前事务必须等待锁的释放。2PL 可以确保事务的隔离性和一致性。

3. 事务隔离级别是数据库管理系统提供的一种机制，用于控制事务之间的隔离程度。MySQL 提供了多个事务隔离级别，如读未提交、读提交、可重复读和串行化。不同的隔离级别决定了事务在并发执行时能否看到其他事务进行的修改。

在 MySQL 中，MVCC 通常与可重复读隔离级别结合使用，这是 MySQL 默认的隔离级别。这意味着在可重复读隔离级别下，MySQL 使用 MVCC 来提供一致性读取，通过使用快照来创建事务的数据视图，从而避免了读操作被锁阻塞的情况。

总结来说，MVCC 和 2PL 是不同的并发控制方法，用于实现事务的隔离性和并发性能。它们可以与不同的事务隔离级别结合使用，而不是 MVCC 实现了所有事务隔离级别，而 2PL 实现了其他的事务隔离级别。

```

MVCC和2PL都是用来实现事务隔离级别的

---

事务中的加锁和解锁时机？

- 对记录进行更新操作，或者`select for update`(X 锁)、`lock in share mode`(S 锁) 时，会对记录进行加锁，锁的种类很多，不赘述
- 在一个事务中，只有在`commit`或者`rollback`时，才会解锁

---

```markdown

- S 锁 加 S 锁后其他事务可读，不可写，直至加锁事务结束
- X 锁 加 X 锁后其他事务均不可以读或写，直至事务结束

事务执行的过程分为两个阶段，一是获得封锁阶段，二是释放封锁阶段；2PL 可能产生死锁；
2PL 可以防止读脏数据、丢失修改等；是事务可串行化的必要条件，不是充分条件；

可串行化：多个操作并发执行时，如不进行并发控制，可能出现错误的结果。但如果把所有并发操作全部串行执行，又失去了并发操作的优势。所以提出了可串行化的概念。可串行性：当且仅当一组事务的交叉执行结果与某一串行执行的执行结果一致时，这组事务具有可串行性；

---

- 一级锁。所有写操作之前加 X 锁，事务结束释放，可以防止丢失修改。
- 二级锁。所有写操作之前加 X 锁，事务结束释放；所有读操作前加 S 锁，操作结束释放，可以防止丢失修改和读脏数据。
- 三级锁。所有写操作之前加 X 锁，事务结束释放；所有读操作前加 S 锁，事务结束释放，可以防止丢失修改、读数据和不可重复读。

```

```markdown
按照我的理解，2PL就是通过组合使用innodb的S锁和X锁来在保证事务隔离的情况下，提高并发性能，对吗？

---

您的理解基本正确。2PL（两阶段锁定）是一种并发控制协议，通过使用锁来实现事务的隔离性和一致性。在 InnoDB 存储引擎中，使用了 2PL 协议来支持事务的并发执行。

InnoDB 通过使用共享锁（S锁）和排他锁（X锁）来控制事务对数据的访问。这些锁的使用遵循两个阶段：

1. 申请阶段：在事务执行期间，当需要读取或修改某个数据项时，事务首先申请相应的锁。共享锁（S锁）允许多个事务同时读取同一个数据项，而排他锁（X锁）则阻止其他事务读取或修改该数据项。

2. 释放阶段：事务在不再需要访问某个数据项时，释放相应的锁，以允许其他事务进行操作。

2PL 协议的目的是通过合理的锁管理来避免事务之间的冲突，从而确保数据的一致性和隔离性。它可以提高并发性能，因为它允许多个事务同时读取数据，只有在需要修改数据时才会阻塞其他事务。

在 InnoDB 中，2PL 是默认的并发控制协议，并与事务隔离级别结合使用。例如，在可重复读隔离级别下，InnoDB 使用锁和多版本并发控制（MVCC）来提供一致性读取。它使用 S 锁和 X 锁来控制并发访问，并使用 MVCC 机制来处理读取操作的一致性。

因此，您可以将 2PL 理解为 InnoDB 存储引擎中实现事务隔离性和并发性能的一种机制，它通过使用 S 锁和 X 锁来控制事务对数据的访问，并与事务隔离级别和 MVCC 结合使用，以满足并发控制的要求。

```

2PL就是通过组合使用innodb的S锁和X锁来在保证事务隔离的情况下，提高并发性能




### 性能相关特性


```markdown

- `插入缓冲 (insert buffer)`，*加速插入操作*，插入缓冲用于非聚簇索引的插入和更新操作，先判断插入的非聚簇索引是否在缓存池中，如果在则直接插入，否则插入到`插入缓存对象`中。再以一定的频率进行插入缓冲和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，提高对非聚簇索引的插入性能
- `二次写 (double write)`由两部分组成，一部分是内存中的`double write buffer`，大小为 2MB，另一部分是物理磁盘上共享表空间连续的 128 个页，大小也为 2MB。在对缓冲池的脏页刷新时，并不直接写磁盘，而是通过 memcpy 函数将脏页先复制到内存中的该区域，之后通过`double write buffer`再分两次，每次 1MB 顺序地写入共享空间的物理磁盘上，然后马上调用 fsync 函数，同步磁盘，避免 OS 缓冲写带来的问题
- `自适应哈希索引 (adaptive hash index)`*自动在内存中创建 hash 索引来加速读操作*，innoDB 会根据访问的频率和模式，为热点页建立哈希索引，来提高查询效率。索引通过缓存池的 B+ 树页构造而来，因此建立速度很快，innoDB 存储引擎会监控对表上各个索引页的查询，如果观察到建立哈希索引可以带来速度上的提升，则建立哈希索引，所以叫做`自适应哈希索引`
- `缓存池`为了提高数据库的性能，引入缓存池的概念，通过参数可以设置缓存池的大小和实例个数，缓存池可以存储一下内容：索引页、数据页、undo 页、插入缓冲、自适应哈希索引、innoDB 存储的锁信息和数据字典信息 (data dict)
- *使用可预测读作为磁盘数据读取方式*



### 缓冲池

- 什么是缓冲池 buffer-pool？
- *避免每次读操作都进行磁盘 IO*，具体来说，缓冲池缓存了大量数据页，让 CPU 读取和写入数据时，直接和缓冲区交互，不需要操作磁盘，从而避免磁盘拖慢数据库性能的问题（*注意缓冲池是 innoDB 引擎的特性，而不是 mysql 的*）
- 缓冲池存哪些数据？
- *缓存表数据与索引数据*，把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘 IO，起到加速访问的作用。
- 缓冲池的工作机制？


### 预读

- 什么是预读？磁盘按页读取，如果要读取的数据就在页中，就能节省后面的磁盘 io，提高效率。数据访问遵循`集中读写`的原则，使用一些数据，大概率会使用附近的数据，这就是`局部性原理`
- 什么是预读失败？
- 如何对预读失败进行优化？
- 什么是缓冲池污染？
- 怎么解决缓冲池污染的问题？


```


### redolog

- redolog 是啥？为什么需要记录 redolog？
- 需要什么样的 redolog？
- redolog 中记录了什么内容？
- redolog 是怎么组织的？
- 如何高效地写 redolog？
- 如何安全地清除 redolog？




![redo-log-commit.webp](https://cdn.wrss.top/docs/2023/12/03/redo-log-commit.webp)



```markdown


- 为了获得更好的读写性能，innoDB 将数据缓存到内存 (`innoDB Buffer Pool`)，对磁盘数据的修改也会落后于内存，如果进程崩溃就会导致内存数据丢失，所以 innoDB 就维护了 redolog，*内存数据丢失后，innoDB 会在重启时，通过重放 REDO，恢复数据*



- 需要基于正确的 page 状态上重放 REDO
- 需要保证 REDO 重放的幂等

- 作用于 page 的 redo
- 作用于 space 的 redo
- 提供额外信息的`logic redo`

- 逻辑 redo
- 物理 redo
- 文件层


- redo 的产生
- 写入 InnoDB Log Buffer
- 写入 page cache
- 刷盘
- 唤醒用户线程


```




### MySQL checkpoint 机制


:::tip

checkpoint 机制也是 InnoDB 引擎的特性之一

其实就是刷盘操作（当然还有其他刷盘操作，具体的触发条件、执行方式和优化策略不同，比如同步写入、异步写、定时写等等）

用来把内存中的脏页（尚未写入磁盘的修改数据页）写入磁盘，并更新相关的日志信息。这个操作是为了保证数据的一致性，以防止系统崩溃时数据丢失。

:::


```markdown


checkpoint 只跟 redolog 相关吗？跟其他日志有关吗？

抱歉，我给出的解释不够准确。checkpoint 机制在 MySQL 中与多个日志类型相关联，而不仅仅是 redo 日志。

具体来说，checkpoint 机制涉及以下几个日志类型：

1. Redo 日志：在执行 checkpoint 时，MySQL 会将脏页（尚未写入磁盘的修改数据页）写入 redo 日志，以便在崩溃恢复时进行数据恢复。

2. Undo 日志：在事务回滚或 MVCC（多版本并发控制）操作中，MySQL 会使用 undo 日志来撤消事务对数据的修改。在执行 checkpoint 时，可能需要更新 undo 日志的相关信息。

3. Binlog 日志：Binlog 日志记录了数据库的逻辑变更，包括对表结构和数据的修改。在执行 checkpoint 时，可能需要更新 binlog 日志的相关信息。

checkpoint 的目的是将内存中的脏页刷新到磁盘，以确保数据的持久性和一致性。因此，涉及到的日志类型不仅包括 redo 日志，还包括 undo 日志和 binlog 日志。

请原谅我之前的不准确解释，如果你有其他问题或需要更多的详细信息，请随时提问。我将尽力为你提供准确的解答。


---


checkpoint 时 mysql 本身实现的，还是 innoDB 存储引擎实现的？



checkpoint 机制在 MySQL 中是由 InnoDB 存储引擎实现的，而不是 MySQL 本身的实现。

InnoDB 是 MySQL 的默认存储引擎，它负责管理数据的存储和访问。InnoDB 存储引擎使用了自己的缓冲池来管理数据页，这些数据页在内存中进行修改后，需要定期刷新到磁盘上的数据文件中，以确保数据的持久性和一致性。

当执行 checkpoint 操作时，InnoDB 存储引擎会根据一定的策略和算法，将内存中的脏页（尚未写入磁盘的修改数据页）写入磁盘，同时更新相关的日志信息。这个过程是由 InnoDB 存储引擎内部的后台线程（如刷新线程）来完成的。

MySQL 本身提供了一些参数和配置选项，用于控制和调整 InnoDB 存储引擎的 checkpoint 行为。但具体的实现和执行是由 InnoDB 存储引擎负责的。

希望这次我给出的解释更准确了。如果你有其他问题，请随时提问。



```


- [MySQL checkpoint 深入分析 - GeaoZhang - 博客园](https://www.cnblogs.com/geaozhang/p/7341333.html)
- [【mysql】关于 checkpoint 机制 - 知乎](https://zhuanlan.zhihu.com/p/86601861)
- [MySQL Checkpoint 机制详解 -51CTO.COM](https://www.51cto.com/article/680990.html)






### [archive] mysql HA (mycat/vitess)


***[云数据库是不是杀猪盘 - 知乎](https://zhuanlan.zhihu.com/p/602509170)***

```markdown
云数据库是不是智商税？荒谬的定价成本刺客足够好吗？适用的场景让DBA下岗？垄断的威胁应对的方案参考

荒谬的定价

公有云上什么最花钱？正常来说，如果不是把公有云单纯当作一个 IDC 2.0 或者 CDN供应商来用，最费钱的服务就是云数据库。公有云上的存储、计算、网络资源贵吗？严格来说不算特别离谱。IDC托管物理机代维的核月成本大约为二三十块，而公有云上一核 CPU 算力用一个月的价格，大概在七八十块到一两百块，考虑到各种折扣与活动，以及弹性溢价，基本处于薄利多销的状态。

公有云上的存储、计算、网络资源贵吗？严格来说不算特别离谱。IDC托管物理机代维的核月成本大约为二三十块，而公有云上一核 CPU 算力用一个月的价格，大概在七八十块到一两百块，考虑到各种折扣与活动，以及弹性溢价，基本处于薄利多销的状态。


不过云数据库就非常离谱了，同样是一核算力用一个月，云数据库价格比起对应规格的硬件可以翻几倍乃至十几倍。 便宜一些阿里云，核月单价三四百，贵一些的 AWS，核月单价可以上千。

```

咋说呢，RDS之类的各种云数据库从来都被公认是“公有云杀猪刀一哥”

非常牛逼的文章，一文破除对各种云数据库的

核月单价


```markdown
我觉得主要卖的是配套服务。
一些高可用性的架构配置，数据可靠性需要的自动备份，主备复制，日志备份等等，AWS 这些都是有现有方案的，同时还有安全保护，漏洞修复，监控告警，工单处理等等；当然，这些基本都有开源方案，你自建当然也可以实现，如果你的项目是个人项目用来测试用来个人使用，那你用自建的无所谓。而从企业的角度来看，如果要自建，那还需要配套一个专门的 DBA 甚至一个运维团队来负责，算上这些费用，以及增加的风险，为什么不直接买现有的 AWS 服务呢？
```

TiDB Cloud

RDS&DRDS

PolarDB


```markdown
共用云厂商的资源定价向来都是计算资源（例如 ECS ）会非常便宜，并且是主要的促销对象（类似于星巴克里面的依云矿泉水，消费者在对比咖啡和水的时候就不会觉得咖啡贵了）； RDS 数据库（包括类似的 Redis 、Kafka ）和不同类型的对象存储才是云厂商的利润点，如果简单的和自建的服务器资源对比，可能会相差几十上百倍。

小规模并且业务增长和实时性要求不高的业务场景可以直接购买 ECS 服务器，然后在 ECS 服务器上安装对应的数据库也能使用。不足之处是需要自己做好数据库的维护，优点是同等配置的 ECS 自己配置数据库（即使是高可用配置）也比 RDS 服务器便宜好几倍。

涉及实时性要求高且重要的业务（例如支付类）在自有技术配置不足的情况下，还是建议直接使用 RDS ，毕竟只要简单操作就能使用，并且具备高可用和性能扩展的特点
```

---

read-write separation

sharding

mycat2, vitess, gaea

TDDL, Atlas(360), DBProxy(based on Atlas), mysql-proxy, mysql-fabric, sharding-JDBC


---

vitess, [vitessio/vitess: Vitess is a database clustering system for horizontal scaling of MySQL.](https://github.com/vitessio/vitess)


---

*MySQL 中间件有哪些核心需求？*


数据库中间件，有哪些核心需求？

```markdown
- 数据库虚拟化
- 数据库对业务透明，业务不需要知道数据库的真实 IP、主从、读写、高可用等
- 支持分库，且数据库的分库对业务透明

---

- 非跨库需求
 - partition key 的简单查询
 - partition key 上的 in 查询
 - 非 partition key 上的简单查询
 - 排序 + 分页
- 跨库 join
- 跨库事务
- 跨库子查询
```

---

数据库中间件、读写分离、分库分表


---

MySQL 有哪几种分表方法？MySQL 有哪几种路由规则？

:::tip

~~*List 是 Range 的延伸，Key 是 Hash 的延伸*~~

直接让`分库分表中间件`解决分表问题，业务和路由算法完全解耦，更灵活
:::


- `Range`（基于属于一个给定持续区间的列值，把多行分配给分区），优点是简单、容易拓展，缺点是负载不均衡，新表压力较大
- `List`（类似于按 range 分区，区别是 list 分区是基于列值，匹配一个离散值集合中的某个值来进行选择），优点是负载均衡，缺点是迁移比较麻烦
- `Hash`（基于用户定义的表达式的返回值来进行选择的分区）
- `Key`（类似于 hash 分区，区别是在于 Key 分区只支持计算一列或者多列，且 MySQL 服务器提供其自身的哈希函数，必须有一列或者多列包含整数值；）


```markdown
能否认为“List 是 Range 的延伸，Key 是 Hash 的延伸”？

---

不完全正确。在MySQL的分区表功能中，"List"和"Range"是两种不同的分区方式，而"Key"和"Hash"是另外两种不同的分区方式。它们并不是相互延伸的关系。

- "List"分区是基于某个列的值列表进行划分的方式，每个分区包含一个或多个特定值的范围。例如，可以根据地区将数据划分到不同的分区。

- "Range"分区是基于某个列的范围进行划分的方式，每个分区包含某个范围内的数据。例如，可以根据订单创建时间将数据划分到不同的分区。

- "Key"分区是根据某个列的哈希值进行划分的方式，它与"Hash"分区有相似的概念。每个分区根据哈希算法将数据均匀地分散到不同的分区中。

- "Hash"分区是根据某个列的哈希值进行划分的方式，它与"Key"分区类似。每个分区根据哈希算法将数据均匀地分散到不同的分区中。

虽然"List"和"Range"分区以及"Key"和"Hash"分区都涉及到按照某个列的特性进行划分，但它们的实现方式和划分策略是不同的。因此，不能简单地认为"List"是"Range"的延伸，"Key"是"Hash"的延伸。

```

```markdown
range, hash, list, key这种分表方法和水平分表、垂直分表这种分表方法，有啥区别？我有点晕

---

我明白这些术语可能会让人感到困惑。让我们来澄清一下这些概念之间的区别。

1. 分表方法：
 - 水平分表（Horizontal Sharding）：将同一个表的数据分散存储在多个表中，通常通过增加后缀或前缀来命名不同的表。例如，user_1、user_2等。
 - 垂直分表（Vertical Sharding）：将数据库按照功能或数据类型进行划分，不同的表存储在不同的数据库中。例如，将用户信息、订单信息等不同类型的数据存储在不同的表或数据库中。

2. 分区方法：
 - 范围分区（Range Partitioning）：根据某个列的范围将数据划分到不同的分区（分表）中。例如，按照订单创建时间将数据划分到不同的分区。
 - 哈希分区（Hash Partitioning）：根据某个列的哈希值将数据均匀地分散到不同的分区（分表）中。例如，使用哈希值将数据分散到不同的分区中。
 - 列表分区（List Partitioning）：根据某个列的值列表将数据划分到不同的分区（分表）中。例如，根据地区将数据划分到不同的分区。

分表方法是指将数据划分到不同的表中，而分区方法是指将数据划分到不同的分区（也可以是不同的表）中。分区方法可以应用于分表方法中，以进一步细分数据的存储和管理。

需要注意的是，分表和分区都是为了实现数据的水平扩展和性能优化。选择适合的分表方法和分区方法取决于具体的业务需求、数据特点和可扩展性要求。

```

```markdown
还是没懂mysql分区和分表有啥区别

---

很抱歉，让我更清晰地解释一下MySQL的分区和分表之间的区别。

分区（Partitioning）是指将一个表分割成多个逻辑分区，每个分区可以存储不同范围的数据。分区是在表级别进行的，它可以根据某个列的范围、哈希值、列表等方式进行划分。分区可以带来一些好处，如更好的查询性能、更容易管理大量数据以及更高的可用性等。

分表（Sharding）是将一个表的数据水平划分到多个物理表中，每个表可能存储不同的数据。分表是在表级别进行的，通常通过增加后缀或前缀来命名不同的表。分表的目的是将数据分散存储在多个表中，以实现更好的负载均衡和扩展性。

简而言之，分区是在逻辑上将一个表划分为多个部分，而分表是在物理上将一个表拆分为多个表。分区是根据某个列的特性进行划分，而分表是为了将数据分散存储在多个表中。

需要注意的是，分区和分表并不是相互排斥的概念，它们可以结合使用以实现更高级别的数据划分和扩展。在某些情况下，可以同时使用分区和分表来达到更好的性能和扩展性。

---

还有个mysql分库是吗？分库和分区有啥区别？是不是大部分公司都不使用分区，而是选择分库呢？为啥呢？

---

是的，MySQL中也存在分库的概念，即将数据拆分到多个数据库中。分库是在数据库级别进行的，每个数据库可以存储不同的数据。

区分分库和分区的主要区别如下：

1. 数据划分粒度：分区是在一个数据库内对表进行划分，将表的数据分散存储在不同的分区中。而分库是将数据划分到不同的数据库中，每个数据库可能包含多个表。

2. 管理和扩展：分区主要用于在单个数据库内管理和优化数据，可以提高查询性能和管理大量数据的能力。分库则更适合水平扩展，将数据分散到多个数据库实例中，每个数据库实例可以独立运行和扩展，从而提高整个系统的负载能力和可扩展性。

关于为什么大部分公司选择分库而不是分区，有以下几个主要原因：

1. 数据隔离和并发性：分库可以将数据隔离到不同的数据库中，每个数据库实例有自己的资源和连接池，可以提高并发性能，避免单一数据库成为瓶颈。

2. 可扩展性：分库可以更容易地实现水平扩展，通过增加数据库实例来分担负载。分库可以在不同的服务器上部署，甚至可以跨多个数据中心进行部署，以实现更高的可扩展性和容错性。

3. 简化管理：分库可以简化数据库管理，每个数据库实例可以独立进行备份、恢复、优化和维护。同时，分库可以提供更好的隔离性，出现故障或性能问题时，只会影响单个数据库实例，而不会影响整个系统。

尽管如此，选择分库还是分区取决于具体的业务需求、数据规模和负载情况。在某些场景下，分区可以提供足够的性能和管理便利，而无需引入分库的复杂性。因此，最佳的选择应该根据具体情况进行评估和决策。

```

```markdown
分区和分库是不是都是逻辑上对数据进行拆分呢？实际物理上并没有拆分数据。分表则是物理上直接拆分数据？

---
是的，你的理解是正确的。分区和分库都是在逻辑上对数据进行拆分，而实际上并没有对数据进行物理上的拆分。

在分区和分库的情况下，逻辑上的拆分是通过将数据划分到不同的分区或数据库中进行管理。这种逻辑上的拆分可以带来一些好处，如更好的查询性能、更容易管理大量数据和更高的可用性。但是，实际上，这些分区和分库中的数据仍然存储在同一个物理存储设备（如硬盘）上。

而分表则是在物理上直接拆分数据，将数据存储在不同的物理表中。每个表可以存储不同的数据，通过表名或其他标识来区分。分表需要在数据库中创建多个表，并将数据按照某种规则分散到这些表中。这意味着数据实际上分散存储在多个物理表中，而不是在同一个表中。

因此，分表是一种直接的物理数据拆分方式，而分区和分库是在逻辑上对数据进行拆分和管理的方式。这些概念的选择和实施应根据具体的需求、数据规模和负载情况进行评估和决策。

---

也就是其实这三点的目的都是类似的，都是为了降低大表问题，降低负载，是吗？只不过实现的方法不同，分库和分区是逻辑上拆分数据，分表则是物理上拆分数据。实际操作时通常是分表+分库，我理解的对吗？

---

是的，这三个概念的目的都是为了解决大表问题、降低负载和提高数据库性能。它们都是用于处理数据量增长和负载压力的情况。

分区、分库和分表的实现方法不同，但都是为了达到相同的目标。分区和分库是在逻辑上对数据进行拆分和管理，以提高查询性能、管理大量数据和实现可扩展性。而分表则是在物理上直接拆分数据，将数据存储在不同的物理表中，以减轻单个表的负载压力。

在实际操作中，通常会结合使用分表和分库。通过分表，将数据水平拆分到多个物理表中，以减轻单个表的负载和提高查询性能。同时，通过分库，将这些分表进一步拆分到多个数据库实例中，实现水平扩展和负载均衡。

这样的组合可以提供更好的性能、可扩展性和管理灵活性。但是，最佳的实现方式仍然取决于具体的需求、数据规模和负载情况。根据实际情况进行评估和决策，选择适合的方案进行实施。

```

其实这三点的目的都是类似的，都是为了降低大表问题，降低负载，是吗？只不过实现的方法不同，分库和分区是逻辑上拆分数据，分表则是物理上拆分数据。实际操作时通常是分表+分库。


---

```markdown

- 基本认知：什么是分区？分区有哪些缺点，为什么大部分互联网公司都不使用分区，而更多的选择分库分表来进行水平拆分呢？请简述一下分区和分表的各自优势和缺点？使用分库分表的先后顺序？
- MySQL 有哪几种分表方法？MySQL 有哪几种路由规则？
- 怎么实现 MySQL 分表？时间（按时间分区，大部分只查询最近的订单数据，那么大部分访问都集中在一个分区，比一个表小多了，数据库也可以更好地加缓存，从而提高性能）
- MySQL 有哪些分表方法？
- 分库分表带来的问题？


---

- 分区就是，所有数据，逻辑上还在一个表中，但物理上，可以根据一定的规则放在不同的文件中。业务代码无需改动。
- *不使用分区，主要是因为在高并发业务下，有很多问题*，主要是三点：如果 sql 不走分区键，很容易出现全表锁；分区表中使用关联查询，性能极差；使用分库分表，我们可以自己选择业务场景和访问模式，而分区则完全交给 MySQL，无法控制。

---

- 实现方式上，分表是真正的分表，利用 merge 引擎把一张大表分成多张小表。而一张大表分区之后，还是一张表，而不是多张表，但是它存放数据的区块变多了。
- 数据处理上，分表后，存取数据都是发生在一个个分表里。“select * FROM alluser id='12'”我们是对 alluser 里面的分表进行操作的。分区呢，分区只不过是把存放数据的文件分成了许多小块，分区后的表呢，还是一张表，数据处理还是由自己完成的。
- 性能提升上，分区分表后都能够突破磁盘的 I/O 瓶颈，但是分区和分表的侧重点不同，分表重点在于存取数据时如何提高 mysql 的并发能力上；而分区呢，如何突破磁盘的读写能力，从而达到提高 MySQL 性能的目的。
- 实现难度上，用 merge 方式分表是很简单的方法，并且对程序代码来说可以做到是透明的。分区实现是比较简单的，建立分区表，跟建立普通的表没有区别，并且对代码来说也是透明的。

---

- *应该先分表，再分库*，因为分表后可以解决单表的压力，但是数据库本身的压力没有下降，我们需要分库，真正隔离来优化服务。

```


---

分库分表带来的问题？

- 事务一致性问题。
- 跨节点关联查询 join 问题。
- 跨节点分页，排序，函数问题。
- 全局主键避重问题。
- 数据迁移、扩容问题。

[也许是东半球直接底气的分库分表实践了](https://mp.weixin.qq.com/s/aAfFjj3x2Fpk-Z728-UWDg)


---


vitess能解决所有mysql高可用方面的常见问题，比如什么主从复制、读写分离、分库分表、写库单点问题等等。


---

```markdown


### *什么是读写分离？怎么实现读写分离？*

- 简单来说就是，在主服务器上写，在从服务器上读，基本的原理就是让主数据库处理事务性查询，而从数据库处理查询，数据库复制被用来把事务性查询导致的改变同步到集群中的从数据库
- MySQL 主从复制是 MySQL 读写分离的基础，只有完成了主从复制，才能在其基础上去做读写分离
- 为什么需要读写分离？大部分应用都是读多写少，然而写请求优先于读请求，会阻塞读请求，所以我们需要把读写操作分开，优化体验

---

怎么实现读写分离？

- 用 `读写分离数据库中间件` 自建
- 直接使用阿里云 RDS 读写分离服务。开启读写分离服务后，所有的 `主实例`和`只读实例`都会有独立的连接地址，还会分配一个额外的`读写分离地址`，服务端数据库地址直接填写`读写分离地址`，RDS 会根据读写请求进行自动转发。读压力太大的情况下，直接水平拓展读库就可以了。存在的问题是*读库高可用，但是写库还是单点*

```


---

技术选型：有哪几种 MySQL 集群方案？为什么使用 Consul+MHA 实现 MySQL 高可用？Maxscale 是啥？有啥优缺点？

- MySQL Proxy
- MySQL Cluster
- MySQL+MHA(Master High Availability)
- MySQL+MMM

为什么使用 Consul+MHA 实现 MySQL 高可用？有什么优点？有哪些缺点？怎么解决？

- MHA 是目前中小公司使用的常见 MySQL 高可用架构，但有些云厂商`不支持虚拟 VIP`，或者`VIP 不是同网段的`，所以无法实现基于`MHA`或`Keepalived 漂移 VIP 形式`的高可用使用场景。于是针对这种情况，衍生出`Cousul 服务发现+MHA 这种架构`
- `consul+MHA`的缺点是成本略高，也不好定位问题，用`Maxscale`解决

---

Maxscale 是什么？怎么使用？有哪些缺点？

缺点是，*由于 GTID 实现方式不同，Maxscale 最新版不支持 mysql 的故障自动转移，只支持读写分离功能*

[完美替代 MHA，Maxscale 的高可用故障转移功能你大概还不知道](https://mp.weixin.qq.com/s?__biz=MzkwOTIxNDQ3OA==&mid=2247532343&idx=1&sn=2eff7e0e4e76870fb11924c11e18ee1e&source=41#wechat_redirect)

:::danger

这部分内容是废的，MHA或者Maxscale这些组件实际上主要提供故障转移，但是vitess本身就支持，所以不需要搭配使用。
:::



---









## [xxx] mysql


### optimize

:::tip

*首先，优化 MySQL 是一个系统工程，由`优化 MySQL 服务`+`优化数据库设计`+`SQL 语句`组成。优化 MySQL 服务又涉及到`MySQL 运维`和`高可用`方面，这里只说最基本的配置优化。*

木桶原理

编成顺口溜就是：

**分析执行计划、矫正行数、添加索引、避免回表、使用 ICP、优化字符串索引、控制 flush 时机、加快 innoDB 刷盘、避免对索引字段做函数操作。**

下面是具体内容

:::


:::danger

实际上这两个都挺扯淡的，我们通常使用RDS之类的云服务部署mysql，压根不可能对服务进行调优。

至于sql优化，大部分云服务厂商的RDS本身就提供了optimizer服务，会自动monitor并添加索引，并且会提供所有慢sql及其原因和建议。并不需要我们自己手动做优化。

:::



:::tip

- `explain`以及 explain 的 extended 拓展
- `explain analyze`
- ~~`query profile`(就是 profiling) `Query Profiler 工具`可以获取一条 sql 在整个执行过程中多种资源的消耗情况，以及性能瓶颈究竟是什么，是 cpu 还是 io，以及具体的 IPC、swap、页分裂等信息~~
- ~~`optimize 语句`~~
- `optimizer_trace 工具`

:::

- 开启`慢查询日志`来定位慢 sql（设置需要优化的 SQL 语句的执行时间，记录下超过该设置时间的语句，即为需要优化的语句）
- 用`show status`了解各种 SQL 的执行效率，定位执行效率低的 SQL 语句
- 用`explain`分析效率低的 SQL 语句
- 用`trace`分析优化器选择执行计划。查询 SQL 语句会执行多长时间，CPU 使用量，执行过程中 systemlock，table lock 花了多长时间。

```mysql
show status;


SHOW STATUS
    WHERE Variable_name IN (
        'Connections', -- 已经处理的连接数
        'Threads_running', -- 当前正在执行的线程数
        'Threads_connected', -- 当前打开的连接数
        'Threads_created', -- 创建的线程数
        'Queries', -- 已经执行的查询次数
        'Slow_queries', -- 慢查询的次数
        'Innodb_buffer_pool_read_requests', -- InnoDB缓冲池的读请求次数
        'Innodb_buffer_pool_reads', -- 从磁盘读取的InnoDB缓冲池页数
        'Innodb_rows_read', -- 从InnoDB表中读取的行数
        'Innodb_rows_inserted', -- 向InnoDB表中插入的行数
        'Innodb_rows_updated', -- 更新的InnoDB表中的行数
        'Innodb_rows_deleted', -- 从InnoDB表中删除的行数
        'Bytes_received', -- 从客户端接收的总字节数
        'Bytes_sent' -- 发送给客户端的总字节数
    );
```




```mysql

# Explain Analyze
# mysql8 提供的优化工具，他会做出查询计划，并且会实际执行，以测量出查询计划中各个关键点的实际指标，比如耗时、条数、循环次数

# - cost 里的是估算结果，也就是成本，mysql 会基于 cost 选择执行计划，忽略不看
# - actual 里的是实际执行结果
#  - time 有两部分，前面的是返回第一条记录的耗时，后面的是返回所有记录的耗时
#  - rows 是实际返回的总条数
#  - loops 是过滤迭代器执行的循环次数

EXPLAIN ANALYZE SELECT * FROM rss_feed;
# 虽然无法给出具体的绝对值范围，但是在一般情况下，cost 值通常可以在以下几个范围内进行大致的评估：

# 小于 10：通常表示执行成本很低，查询计划可能非常高效。
# 10 - 100：表示执行成本适中，查询计划相对较好，但仍有改进的空间。
# 100 - 1000：表示执行成本较高，可能存在一些不太高效的操作或者需要进行优化。
# 大于 1000：表示执行成本非常高，可能存在一些显著的性能问题，需要进行进一步的优化。

```

---

optimizer-trace 工具是什么？


- [Mysql 使用 optimizer_trace 查看执行流程，分析、验证优化思路](https://segmentfault.com/a/1190000018136007)
- [MySQL · 最佳实践 · 性能分析的大杀器—Optimizer trace](http://mysql.taobao.org/monthly/2019/11/03/)



```markdown
查询计划的解释是由优化器提供的，而执行详细信息的收集是由执行器提供的。
```

这点在mysql和postgres里是一样的。*也就是说几个mysql常用的优化命令，optimizer-trace是optimizer提供的，explain analyze 是 executor提供的，show status 则是一个数据汇总的命令，*

另外，profiles已经废弃了，使用 [MySQL :: MySQL 8.0 Reference Manual :: 27 MySQL Performance Schema](https://dev.mysql.com/doc/refman/8.0/en/performance-schema.html) 代替


---



- *[有哪些常见的数据库优化方法？ - 知乎](https://www.zhihu.com/question/36431635/answer/1276528192)*
- *[这 15 个 SQL 优化口诀，工作面试都够用了](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247495903&idx=1&sn=9ab0f1a49aedbce6a32aa4e7a6794d28)*

![v2-f05bd000f81085eba207c54090d2813e_r](https://cdn.wrss.top/docs/2023/01/v2f05bd000f81085eba207c54090d2813er.jpeg)

- 预发跑 sql explain
- 看一下行数对不对，不对可以用`analyze table <t>`矫正
- 添加索引，索引不一定是最优的，`force index`强制走索引，但是不建议使用
- 查看是否存在回表的情况
- 覆盖索引避免回表，不用*
- 合理安排联合索引的顺序
- MySQL5.6 之后使用 ICP 减少回表次数
- 给字符串加索引，用`前缀索引`、`倒序存储`、`hash`
- 数据库的 flush 时机
- innoDB 刷盘速度，脏页比例、redolog 写盘速度
- 索引字段不要做函数操作，会破坏索引值的有序性，优化器会放弃走树结构。如果触发隐式转换，也会走 cast 函数，会放弃走索引

---

MySQL 性能调优？

*MySQL 性能优化包括两方面，MySQL 所在宿主机的调优，以及 MySQL 配置的优化*

- MySQL 所在宿主机调优跟 redis 调优有点类似，都是`调整 Linux 默认的 IO 调度算法为 deadline`、`禁用 NUMA`、`修改 swappiness 设置`这三点，主要是防止 NUMA 之后频繁发生 swap，导致性能衰减。
- *MySQL 配置优化不赘述，取决于业务，负载或硬件，在慢内存和快磁盘、高并发和写密集型负载情况下，都需要特殊的调整。无非是连接池、缓冲池、最大连接数等方面的优化*
- `优化数据库连接池`，优化 initialSize、minIdle/maxIdle、maxActive、maxWait 等参数，不多说




### logs

- binlog
- undolog
- redolog
- 查询日志
- 慢查询日志


---

slowlog

```ini

; 怎么开启慢查询日志？有哪些关键配置项？怎么查看慢 sql？

;my.cnf
;这个参数设置为 ON，可以捕获执行时间超过一定数值的 SQL 语句。
slow_query_log = 1
;记录日志的文件名
slow_query_log_file = /path/to/slow-query.log
;当 SQL 语句执行时间超过此数值时，就会被记录到日志中，建议设置为 1 或者更短
long_query_time = 2
;这个参数设置为 ON，可以捕获到所有未使用索引的 SQL 语句，尽管这个 SQL 语句有可能执行得挺快。
log_queries_not_using_indexes = 1

```

---

binlog

```ini
# 设置二进制日志
log-bin=mysql-bin
# mixed, statement, row
# mix 是 statement 和 row 的混合。正常而言都是用 statement 来存，但是像主从这种没有逻辑的则用 row 格式来存
binlog-format=ROW
expire_logs_days=7
binlog_row_image=FULL
binlog_checksum=ON
binlog_cache_size=32M
max_binlog_size=100M

# 刷盘相关参数
# checkpoint
# 默认为0，不去强制要求，由系统自行判断何时写入磁盘。
# 1：每次 commit 的时候都要将 binlog 写入磁盘，最安全的设置
# N：每 N 个事务，才会将 binlog 写入磁盘
sync_binlog=1
# 对于使用 InnoDB 存储引擎的表，该参数指定事务提交时 binlog 和 redo log 是否需要刷盘。常见的取值包括：0, 1, 2
innodb_flush_log_at_trx_commit=1
# 该参数指定多长时间进行一次 binlog 和 redo log 的刷盘操作。
innodb_flush_log_at_timeout=1
```


---


```markdown

我们通常在mysql组合备份策略，用“全量 + 增量”，还是“全量 + 差量”？这两种组合备份策略有啥区别呢？分别的适用场景？

---

在MySQL中，常见的备份策略有"全量 + 增量"和"全量 + 差异"两种。这两种策略有一些区别和适用场景。

"全量 + 增量"备份策略是指先进行一次全量备份，然后根据全量备份之后的增量变化进行增量备份。全量备份包含了所有数据和表，而增量备份只包含了自上次备份以来发生的变化。这种备份策略可以节省备份时间和存储空间，适用于数据量较大的情况。

"全量 + 差异"备份策略也是先进行一次全量备份，然后根据每次备份之间的差异进行备份。差异备份包含了自上次全量备份以来的所有变化。与增量备份不同的是，差异备份包含了自上次备份以来的所有变化，而不仅仅是自上次备份之后的增量变化。这种备份策略可以提供更好的灾难恢复能力，适用于需要频繁恢复到某个备份点的情况。

选择备份策略应根据具体需求和业务场景来决定。如果对备份时间和存储空间有较高要求，可以选择"全量 + 增量"备份策略。如果对备份恢复能力有较高要求，可以选择"全量 + 差异"备份策略。

```

在生产环境，我们如果使用RDS的话，不考虑备份策略，直接在RDS后台设置就可以了。所以相关的配置和命令也不需要搞了。





### ***cpoe***



- server 层
	- `连接器(connector)` 权限验证；连接成功后，通过连接池管理连接
	- `解析器(parser)` 词法分析、语法分析
	- `查询优化器(optimizer)` 生成执行计划，选择索引
	- `执行器(executor)` 负责具体执行，先判断对某表是否有执行权限；根据该表的存储引擎调用对应接口
- `存储引擎` 负责数据的存储和提取操作

:::tip

cpoe

---

**最核心的是查询优化器和存储引擎。** 其他的什么连接器、解析器和执行器都没什么意思。

查询优化器的核心是各种查询优化方法

:::



<details>
<summary>MySQL 解析器</summary>

- MySQL 解析器的组成？首先执行 `词法分析`，然后进行`语法分析`
- 词法分析是什么？
- 这个阶段的任务是从左到右一个字符、一个字符地读入源输入，即对构成源程序的字符流进行扫描，然后根据构词规则识别单词（也称单词符号或符号）。词法分析程序实现这个任务。词法分析程序可以使用 lex 或 GNU 开源的 Flex 等工具自动生成。
- 语法分析是什么？
- 语法分析的任务是在词法分析的基础上将单词序列组合成各类语法短语，如“程序”，“语句”，“表达式”等。语法分析程序判断源程序在结构上是否正确。源程序的结构由上下文五官文法描述。语法分析常用 Bison 工具自动处理。


```markdown

mysql 的解析器和 golang 或者 php 之类的编程语言的编译器一样呢？



MySQL 的解析器和编程语言（如 Golang 或 PHP）的编译器在一些方面有相似之处，但也存在一些关键的区别。

解析器的作用是将 SQL 语句解析成内部数据结构，以便数据库可以理解和执行。MySQL 的解析器负责解析 SQL 语句，识别其中的关键字、表名、列名、运算符、函数等，并生成相应的语法树或执行计划。

编译器的作用是将高级语言代码（如 Golang 或 PHP）转换为可执行的机器代码。编译器通常包括词法分析、语法分析、语义分析、代码优化和代码生成等多个阶段。

相似之处在于解析器和编译器都需要对输入进行分析和处理。它们都需要进行词法分析（将输入拆分成标记）、语法分析（根据语法规则构建语法树）和语义分析（验证语法正确性和语义一致性）等步骤。

然而，MySQL 的解析器和编程语言的编译器也有一些关键的区别。主要区别在于目标和输入类型：

1. 目标：MySQL 的解析器的目标是将 SQL 语句转换为数据库内部能够执行的查询计划。而编程语言的编译器的目标是将高级语言代码转换为机器代码，以便计算机能够直接执行。

2. 输入类型：MySQL 的解析器接收的输入是 SQL 语句，而编程语言的编译器接收的输入是高级语言代码。

此外，编程语言的编译器还包括代码优化和代码生成等步骤，以提高执行效率。

总结起来，尽管 MySQL 的解析器和编程语言的编译器在某些方面有相似性，但它们的目标和输入类型等方面存在明显的区别。这些区别使得它们在实现和功能上有所不同。我希望这回答能够解决你的疑问！如果你还有其他问题，欢迎继续提问。我爱编码！


```

</details>




---


mysql 的查询语句的具体执行？比如 sql 语句有 select from where orderby，执行时的执行顺序？


```markdown

在 MySQL 中，查询语句的执行顺序如下：

1. FROM：首先，MySQL 解析查询语句的 FROM 子句，确定要查询的表以及它们的连接方式。这步中还包括子查询的处理。

2. WHERE：接下来，MySQL 会根据 WHERE 子句中的条件过滤出符合条件的记录。这一步会筛选出满足 WHERE 条件的行。

3. GROUP BY：如果查询中包含 GROUP BY 子句，MySQL 会按照指定的列对结果进行分组。

4. HAVING：如果查询中包含 HAVING 子句，MySQL 会根据 HAVING 条件过滤出满足条件的分组。

5. SELECT：此时，MySQL 会选择要返回的列，并计算任何表达式或聚合函数。

6. DISTINCT：如果查询中有 DISTINCT 关键字，MySQL 会去除重复的结果行。

7. ORDER BY：最后，MySQL 会按照 ORDER BY 子句中指定的列对结果进行排序。

需要注意的是，这只是一般情况下查询语句的执行顺序。MySQL 的查询优化器可能会对查询进行优化，如重新排序执行步骤、使用索引等，以提高查询性能。因此，实际执行顺序可能会有所不同。

如果在查询中使用了子查询，那么子查询会作为一个独立的步骤嵌套在主查询中，并按照相同的执行顺序进行处理。

了解查询语句的执行顺序可以帮助我们更好地理解和优化查询，以提高查询性能和效率。

```


FWG(H)SDO

```markdown

为什么mysql查询语句是按照FROM、WHERE、GROUP BY、HAVING、SELECT、DISTINCT、ORDER BY的顺序执行的？请从mysql optimizer的角度，从源码级别给我解释一下

---

MySQL查询语句按照特定顺序执行的原因涉及到MySQL优化器的工作原理。MySQL优化器负责解析查询语句，并根据数据统计信息、索引和规则来生成最优的执行计划。下面是从MySQL优化器的角度解释查询语句执行顺序的一般过程：

1. FROM子句：优化器首先处理FROM子句，确定查询涉及的表和它们的连接方式。这包括选择合适的索引、访问方法和连接顺序。优化器会评估每个表的成本，并根据成本模型选择最佳的连接方式。

2. WHERE子句：优化器考虑WHERE子句中的过滤条件，以确定可以使用的索引和访问方法。它会尽可能使用索引来快速定位匹配的行，减少需要扫描的数据量。

3. GROUP BY和HAVING子句：如果查询包含GROUP BY和HAVING子句，优化器会根据聚合操作和过滤条件来确定如何进行分组。它会选择适当的索引和算法来执行聚合操作，以便尽可能高效地生成结果。

4. SELECT子句：一旦确定了表连接、过滤条件和分组方式，优化器会处理SELECT子句，选择需要返回的列和计算表达式。它会考虑列的顺序以及访问方式，以便最大程度地减少访问和计算的成本。

5. DISTINCT：如果查询中包含DISTINCT关键字，优化器会确保返回的结果集中没有重复的行。它会使用合适的索引或排序算法来实现这一目标。

6. ORDER BY：最后，优化器处理ORDER BY子句，以确定如何对结果进行排序。它会选择合适的索引或排序算法，以最小化排序操作的成本。

需要注意的是，MySQL优化器是一个复杂的系统，其内部算法和决策可能会因版本而异。解释查询语句执行顺序需要深入研究MySQL优化器的源代码实现，以获得更详细和准确的解释。你可以查阅MySQL的源代码和优化器相关的文档来深入了解。

---

能否认为在mysql的connector, parser, optimizer, executor 中 optimizer是最重要的？或者说，至少比其他几个组件重要？如果不是，其他几个组件有什么核心作用呢？

---

...

---

按照我的理解，connector就不说了，比较简单。parser可以理解为mysql的compiler或者说interpretor. 那executor呢？我想知道executor是怎么与search engine交互，并且保证查询计划按照预期执行的

---

你的理解基本上是正确的。解析器可以看作是MySQL的编译器，负责将SQL查询语句解析为可执行的内部表示。现在我们来详细了解一下执行器（Executor）与存储引擎（Storage Engine）之间的交互，并确保查询计划按预期执行的过程。

...

---

"执行器从解析器获取查询计划" executor 直接从parser获取查询计划，然后直接在engine中查询吗？这个过程之间不是应该有optimizer对查询计划进行优化吗？

---

非常抱歉，我之前的回答可能有些混淆。你是正确的，在执行器（Executor）执行查询之前，查询计划（Execution Plan）确实需要经过优化器（Optimizer）的处理。

非常抱歉我的表述不够准确。执行器（Executor）不仅仅负责将查询计划传递给存储引擎（Storage Engine），还负责执行查询计划，并处理查询的各个阶段。下面是更详细的执行过程：

1. 解析器（Parser）将查询语句解析为语法树，并将其转换为内部数据结构，包括查询计划。

2. 优化器（Optimizer）接收解析器生成的查询计划，然后基于表的统计信息、索引信息、查询规则和系统参数等进行优化。优化器通过考虑不同的执行策略和访问路径来生成最优的执行计划。

3. 优化器生成的优化执行计划包含了具体的查询操作顺序、索引使用、连接方式等信息。

4. 执行器从优化器获取经过优化的查询计划，并将其传递给存储引擎。

5. 执行器根据查询计划的指令，逐步执行查询操作。这包括从存储引擎读取数据、进行过滤、排序、聚合等操作，以及处理事务的提交和回滚。

6. 执行器通过与存储引擎的交互，将返回的数据按照预期的格式组织成结果集，并最终返回给客户端。

所以，执行器不仅仅负责将查询计划传递给存储引擎，还负责执行查询计划的各个阶段，并确保查询的正确性和一致性。执行器在查询过程中与存储引擎紧密合作，协调数据的读取、写入和处理，以及事务的管理。

再次对之前的回答造成的困惑表示歉意，希望这次的解释更加明确。如果还有其他问题，请随时提问。

```



如果拿图书馆来类比mysql的话，就很好理解了。假设我们的需求是进入图书馆获取n本符合我们需要的书。connector就相当于门卫，只有预约（相当于auth）过才能进入，我们可以通过调整连接数（就是预约人数）来动态调整图书馆的负载。parser就相当于是把汉语转化成该书的ISBD号等MACS专用信息（将查询语句转换为内部数据结构，相当于compiler），并且提供这些书的位置和路线（提供查询计划）。optimizer就相当于优化我们去找到这本书的路线（找到最优路线，提高查询效率）。executor则相当于执行优化后的查询计划，从图书馆书架（存储引擎）里查找所有需要的数据，这也解释了查询操作关键字的执行顺序，当然要先确定这些书籍的大概区域（也就是FROM），如果需要把这些书按序排列的话，就最后再执行Order这种已经拿到所有书籍之后无关紧要的操作。那中间肯定就是来获取查找这些书了，也就是各种条件（where和groupby/having和select），当然书肯定不需要重复的（也就是Distinct去重操作）。我的理解对吗？如果不够完善的话，请帮我补充




```markdown
好，如果我们把存储引擎比做图书馆的所有书架的话，表、页、行分别类比成什么比较合适？表可能类比成图书馆的某个区域？页就是该区域的某个书架，行就是某一排书？

---

是的，您可以将存储引擎比作图书馆的所有书架。表可以类比成图书馆的某个区域，每个区域存放着特定类型的书籍。页可以看作是该区域的某个书架，每个书架上放着一定数量的书籍。行可以类比成某一排书，每一排上放着一本书。这个比喻可以帮助我们理解存储引擎中表、页和行的关系。

---

好的，进一步的，我们可以用这些继续类比myisam和innodb，myisam就是每个分类（比如工业技术、交通运输、历史地理等等，具体查看《中国图书馆分类法》）都会有一个单独的目录，并且不允许很多人同时查找（不支持并发查找，也就是不支持事务），进行查找时直接锁表，相应的，我们可以直接通过这个单独的MYI索引文件查找对应的图书，非常快。

InnoDB就灵活的多了，他是以书架为单位进行查找和存储的，所以他的目录（索引）是和某排图书在一起的（相当于每排书一个索引（主键索引），索引id都贴在书架该层的最前面，我们根据索引id来看需要的书是不是在这排（再多说一句，这也是为什么主键id最好单调递增的原因））。他是支持多人同时查找的。并且在读写操作时只锁定某排书（也就是行级锁定），粒度更细，这样就更能频繁地执行读操作和写操作。

需要注意的是mysql还支持同时使用多种存储引擎，也就是说在图书馆里如果有一些冷门分类，很少有新书入库的，那就用myisam这种类型的管理方式，如果非常热门的分类，每天都有很多用户来买书，每天书店也需要频繁补货的，就应该用innodb。当然，如果我们把mysql看作是图书馆的话，不同图书馆的特性（规矩、规章制度）也不同，比如说oracle或者sql server这种的就比较死板，图书馆开店营业之前就定好了所有书架的管理模式（也就是存储引擎），之后再也不能修改，更不存在说不同分类使用不同的管理模式一说了。

我理解的对吗？

---

您的理解是正确的。MyISAM和InnoDB是MySQL中两种常见的存储引擎。MyISAM以每个分类为单位进行查找和存储，每个分类有一个单独的目录，并且不支持并发查找和事务。在查找时，它会直接锁定整个表，因此查询速度��常快。而InnoDB以书架为单位进行查找和存储，每排书有一个索引，索引id贴在书架该层的最前面。它支持多人同时查找，并且在读写操作时只锁定某排书，粒度更细，因此更适合频繁执行读操作和写操作。

需要注意的是，MySQL还支持同时使用多种存储引擎。对于冷门分类很少有新书入库的情况，可以选择使用MyISAM这种管理方式。而对于非常热门的分类，每天都有很多用户来买书，每天书店也需要频繁补货的情况，就应该选择使用InnoDB。当然，不同的数据库管理系统可能有不同的特性和规则，比如Oracle或SQL Server可能更加死板，一旦确定了存储引擎就不能修改，也不存在不同分类使用不同管理模式的情况。

您的理解非常准确！

```


:::tip
应该说，之前还对我这种“”的方法有所疑虑，但是事实证明这个就是效率最高的方法

***把这些抽象概念具像化+直接看源码，就是最好的。通过具像化的类比构建一个非常易于理解的东西，画个图。再通过直接看源码看看是怎么实现的，加深理解。比之前看各种二手屎的作者本身也不知所云的各种抽象概念高到不知道哪里去了***。而不是看各种技术文章，各种二手屎。非常蠢。

因为各种技术文章往往是静态的、片面的，并且很有可能写文章的人自己也并不是真的懂（我看的blog太多了，实际上大部分人都并不懂，就天天写blog，纯有病）

:::



---


MySQL 查询优化器有哪些优化方法？

:::tip
按照 join，数据读取方式，索引等因素，估算出开销最小的执行计划，来优化 sql 查询语句的执行。

本质来说都是为了减少 IO 开销，具体方法有，直接从索引读取数据，或者访问索引时过滤掉不符合查询条件的行等等。

:::

- `ICP索引条件下推(Index Condition Pushdown)` 用索引筛选的 where 条件在存储引擎一侧进行筛选，而不是将所有 index access 的结果都放在 server 端进行 where 筛选
- `MRR索引多范围查找(Multi-Range Read)` 优化器将随机 io 转化为顺序 io，以降低查询过程中 io 开销的一种手段
- `BKA`，Batched Key Access，在表连接过程中为了提升 join 性能而使用的 join buffer，其作用是在读取被 join 表的记录时，使用顺序 io(BKA 被使用的标识是执行计划的 extra 信息中会有 BKA 信息)
- `BNL`

---

```markdown

emmm 我指的是 mysql 查询优化器的底层技术，比如 ICP、MRR、BKA、BNL、index dive 这种，除了这些还有哪些呢？


非常抱歉之前的回答可能没有理解你的问题。你提到的 ICP（索引条件下推）、MRR（多范围读取）、BKA（块嵌套循环连接）、BNL（基于块的嵌套循环连接）和索引深入搜索（Index Dive）是 MySQL 查询优化器底层技术中的一些重要方法。

除了这些，MySQL 查询优化器还使用了其他一些底层技术来优化查询性能。以下是一些常见的 MySQL 查询优化器底层技术：

1. 基于成本的优化（CBO）：MySQL 查询优化器通过评估不同执行计划的成本来选择最优的执行计划。它会考虑索引的选择、连接顺序、连接类型等因素，并尽量选择成本最低的执行计划。

2. 基于规则的优化（RBO）：MySQL 查询优化器使用一系列预定义的规则来进行查询优化，例如消除冗余操作、优化 WHERE 条件、转换连接类型等。

3. 排序缓存：MySQL 查询优化器会根据查询的结果集进行排序，并将排序结果缓存在内存中，以便后续的查询可以直接访问排序结果，而无需再次进行排序操作。

4. 优化器提示（Optimizer Hints）：MySQL 提供了一些特殊的注释语法，可以在查询中指定优化器的提示，以干预优化器的决策。这可以用于调整查询执行计划，以适应特定的场景和需求。

这些底层技术在 MySQL 查询优化器中起着关键的作用，帮助优化查询性能并选择最优的执行计划。MySQL 查询优化器的具体实现和算法是复杂的，并且可能会随着 MySQL 版本的更新而有所改变。

希望这个回答能够解决你的疑问！如果你还有其他问题，请随时提问。我爱编码！


```

---


ICP 索引条件下推

- ICP 的原理？有什么好处？
- 使用 ICP 的注意事项？



```markdown

当执行 MySQL 查询时，索引条件下推是一种优化技术，它允许 MySQL 在访问索引时过滤掉不符合查询条件的行，减少了不必要的 IO 操作，从而提高查询性能。

索引条件下推的原理很简单。当 MySQL 执行查询语句时，它会根据查询条件选择合适的索引来访问数据。在传统的执行方式中，MySQL 首先通过索引找到满足条件的记录的主键，然后再根据主键值从数据表中获取记录。而索引条件下推则在索引访问阶段就进行条件过滤，只返回满足查询条件的记录的主键，避免了不必要的主键查找操作。

这样做的好处是减少了磁盘 IO 和网络传输，提高了查询效率。特别是对于那些返回记录较多但满足查询条件的记录较少的查询，索引条件下推可以大幅提升性能。

要启用索引条件下推，首先需要确保你的 MySQL 版本是 5.6 或以上，并且查询语句中使用了适当的索引。MySQL 在执行查询时会自动判断是否可以使用索引条件下推进行优化。

希望这个解释对你有所帮助！如果你还有其他关于 MySQL 或其他编程问题的疑问，都可以随时提问，我会尽力帮助你！我爱编码！


```


```markdown


使用 ICP 的注意事项

- ICP 只能用于二级索引，不能用于主索引。
- 不是全部 where 都能用 ICP 筛选，如果 where 条件的字段不在索引中，当然还是要读取整条记录做筛选，在这种情况下，仍然要到 server 端做 where 筛选。
- ICP 的加速效果取决于在存储引擎内通过 ICP 筛选掉的数据的比例。

```


[MySQL：好好的索引，为什么要下推？](https://mp.weixin.qq.com/s?__biz=MzAwNTc3OTE5Mg==&mid=2657444539&idx=1&sn=f2211d7ed33b073ba91f1ccaa50c8e93)


---


Index dive 索引深入搜索

- 什么是`index dive`？
- 优化器在哪些情况下会跳过`index dive`？


```markdown


通过少量访问`B+树索引`来分析需要扫描的记录数量

通俗来说就是，在查询过程中，直接在查询引擎层的 API 获取数据时，实现“非直接索引”过滤条件的筛选，而不是查询引擎层查询出来之后在 server 层筛选

换句话说就是，ICP 在获取数据的同时实现了 where 的次选条件中无法直接使用索引的情况下的筛选，避免没有 ICP 优化的时候分两个步骤的实现

```


```markdown

索引深入搜索（Index Dive）是另一种优化技术，它允许 MySQL 在索引中进行更深层次的搜索，以避免从磁盘读取不必要的数据块。当满足查询条件的数据在索引的连续块中时，索引深入搜索可以直接从索引中读取数据，而无需访问数据表。这种方式可以显著减少 IO 操作，提高查询性能。

索引条件下推和索引深入搜索可以结合使用，以进一步提高查询性能。当 MySQL 执行查询时，首先会利用索引条件下推过滤掉不满足查询条件的记录，然后再利用索引深入搜索从索引中读取满足查询条件的数据。这样可以最大程度地减少 IO 操作，提高查询效率。


需要注意的是，索引条件下推和索引深入搜索都是 MySQL 内部的优化技术，对于开发人员而言，只需要合理设计和使用合适的索引，MySQL 会自动根据查询条件和索引来选择合适的优化策略。


```



```markdown

好的，那我们来继续聊聊optimizer的细节，如果我们把mysql比做图书馆的话，ICP, MRR, BKA, BNL 以及 index dive 这些分别可以类比成什么？

---

当将MySQL比作图书馆时，可以将以下优化器技术类比为不同的操作：

1. ICP（Index Condition Pushdown）：ICP在优化器中是一项重要的优化技术，它类似于图书馆的索引目录。在图书馆中，索引目录帮助读者快速找到所需书籍的位置。类比到MySQL中，ICP会尽可能将查询条件下推至存储引擎层级，以减少不必要的数据读取，提高查询效率。

2. MRR（Multi-Range Read）：MRR是一种批量读取技术，类似于在图书馆中一次性获取多本书。MRR允许MySQL在存储引擎层级批量读取满足查询条件的多个数据块，以减少磁盘I/O操作，提高查询性能。

3. BKA（Batch Key Access）：BKA是一种批量键访问技术，类似于在图书馆中通过预定书架号快速获取多本书。在MySQL中，BKA允许优化器批量访问索引，以减少索引访问的次数，提高查询速度。

4. BNL（Block Nested Loop）：BNL是一种块嵌套循环技术，类似于在图书馆中通过遍历多个书架来查找所需书籍。在MySQL中，BNL用于处理连接操作，它会逐行读取两个表的数据，并执行循环匹配操作，以获取符合连接条件的结果。

5. Index Dive：Index Dive类似于在图书馆中通过索引快速定位到需要的书籍的过程。在MySQL中，Index Dive是一种优化技术，它允许优化器通过索引的跳跃访问，直接定位到满足查询条件的数据，而无需完全扫描索引。

这些优化器技术都旨在提高查询性能，减少不必要的磁盘I/O和数据扫描。通过将MySQL的优化器技术与图书馆的操作进行类比，可以更好地理解它们的功能和作用。希望这个回答对你有帮助！如果你有进一步的问题，请随时提问。

---

“ICP会尽可能将查询条件下推至存储引擎层级，以减少不必要的数据读取，提高查询效率。”

为什么把查询条件放到存储引擎，能提高查询效率？

---

将查询条件下推至存储引擎层级可以提高查询效率的原因是减少了不必要的数据读取。

当查询语句中包含了条件限制时，传统的方式是将所有数据读入MySQL服务器，然后再进行条件过滤。这样会导致大量的数据传输和处理，尤其是在数据量较大时。

而通过将查询条件下推至存储引擎层级，MySQL可以在存储引擎中进行条件过滤，只将满足条件的数据传输到MySQL服务器。这样可以大大减少数据传输和处理的工作量，提高查询效率。

另外，存储引擎层级通常会有索引等数据结构支持，可以更高效地执行条件过滤操作。因此，将查询条件下推至存储引擎可以充分利用存储引擎的优势，减少不必要的数据读取，从而提高查询性能。

总结起来，通过将查询条件下推至存储引擎层级，可以减少数据传输和处理，利用存储引擎的优势进行条件过滤，最终提高查询效率。这就是ICP技术的作用。

---

BKA和BNL是不是都是在join操作时才会使用的优化技术？

---

是的，BKA（Batch Key Access）和BNL（Block Nested Loop）都是在连接操作（join）中使用的优化技术。

1. BKA（Batch Key Access）：BKA优化技术在连接操作中使用，特别是在执行连接操作时，如果一个表上的索引已经排序，而另一个表上的连接列也是有序的，那么MySQL可以使用BKA来批量访问这两个表。它允许优化器批量访问索引，减少索引访问的次数，从而提高连接操作的性能。

2. BNL（Block Nested Loop）：BNL优化技术也是在连接操作中使用的。当连接操作无法使用更高级的连接算法（如索引连接或哈希连接）时，MySQL会使用BNL。BNL通过逐行读取两个表的数据，并执行循环匹配操作，以获取满足连接条件的结果。虽然BNL可能会导致性能较低，但在某些情况下，它仍然是执行连接操作的一种有效方法。

需要注意的是，BKA和BNL是在特定的情况下被MySQL优化器选择使用的。MySQL的优化器会根据表的大小、索引的可用性、连接条件等因素来决定使用哪种连接算法。根据查询的具体情况，优化器会选择最佳的连接方式来提高查询性能。

因此，虽然BKA和BNL是在连接操作中使用的优化技术，但并不是所有连接操作都会使用它们。MySQL的优化器会根据具体情况选择最合适的连接算法。

```



### MySQL 版本 CHANGELOG


```markdown


> MySQL5.6

- `GTID`全局事务标识，用来取代传统的`binlog文件偏移量复制`方式
- 支持`crash-slave`，保证无论在 master 还是 slave 发生异常 crash 拉起后，整个复制结构是支持 ACID 特性的 (没有一致性问题)，也意味着仅考虑支持事务的存储引擎

---

> MySQL5.7

- `虚拟列`Virtual Columns
- `支持JSON格式数据`，提供了`创建json`、`查询json`、`修改json`、`返回json`等方法

---

> MySQL8

- `火山模型执行器`
- `文档存储`
- `查询优化工具`，我们常用的`explain工具`给出的结果，不是实际执行的情况，所以不太准确；而`explain analyze`会实际执行，以测量出查询计划中各个关键点的实际指标，例如耗时、条数，最后详细的打印出来
- 增加了“隐藏索引”，索引被设置为隐藏后，优化器会忽略该索引，便于性能调试
- `降序索引`
- 也有一些优化项，比如优化了 mysql 的 GIS，更好的优化器消费模型，默认使用 utf8mb4 编码，移除了没用的查询缓存

为什么 MySQL8 移除了`查询缓存`？

很简单，使用查询缓存利大于弊，MySQL 团队打算把查询缓存做到客户端，也就是类似`redis6客户端缓存`的功能




```







- 有哪些实现 MySQL 高可用的方案？
- MySQL 高可用，有哪些核心需求？

<details>
<summary>有哪些实现 MySQL 高可用的方案？</summary>

- 有很多方案，但是都不靠谱
- 基于 MySQL 复制的方案是主流，也非常成熟，引入中间件和引入 zookeeper 虽然能将系统的可用性做的更好，可支撑的规模更大，但也对研发和运维提出了更高的要求；因此，在选择方案时，要根据业务场景和运维规模做选择

</details>

<details>
<summary>MySQL 高可用，有哪些核心需求？</summary>

- 客户端切换，如何“自动故障转移”
- 多个 MySQL 节点之间如何做数据同步

</details>

## 主从复制

- 什么是主从复制？主从复制解决了什么问题？主从复制的工作原理？GTID 的工作原理？
- 有哪些导致主从同步延迟的原因？为什么要优化主从同步的延迟问题？如何解决主从复制的延迟问题？
- ~~怎么部署 MySQL 主从复制？怎么用 docker 部署 MySQL 主从复制？~~


### 主从复制

- 什么是主从复制？主从复制解决了什么问题？
- 主从复制的工作原理？主从复制过程中，主从服务器分别使用了哪些线程？
- 什么是主从复制的复制过滤？
- 主从复制过程中，主从服务器分别使用了哪些线程？
- GTID 是什么？
- GTID 的工作原理？GTID 和 binlog 偏移量的区别？
- 使用 GTID 有哪些好处？
- 怎么使用 GTID 进行 MySQL 复制？怎么配置？



<details>
<summary>什么是主从复制？主从复制解决了什么问题？</summary>

- 主从是一种用于数据库容错和灾备的高可用解决方案，而不是一种处理高并发压力的解决方案
- 如果主服务器出现问题，可以快速切换到从服务器提供的服务 (主写从读)
- 可以在从服务器上执行备份，以避免备份期间影响主服务器的服务
- 主从复制后，也可以在从服务器上查询，以降低主服务器的访问压力；但是，只有更新不频繁的数据或者对实时性要求不高的数据可以通过从服务器查询，实时性要求高的数据仍需要从主服务器查询


</details>


<details>
<summary>主从复制的工作原理？主从复制过程中，主从服务器分别使用了哪些线程？</summary>

- `写入` 主机使用`dump 线程`，把`写操作` 写入到 binlog 中
- `复制` 从机使用`IO 线程`，将主机的 binlog 复制到自己的`中继日志 relaylog`里
- `重放` 从机使用`sql 线程`重放 relaylog，实现主从同步

</details>


<details>
<summary>GTID</summary>

GTID 就是`Global Transaction ID(全局唯一 id)`，*GTID = server_uuid : transaction_id*，其中 `server_uuid` 是 MySQL 本身提供的，该集群某台 MySQL 的唯一标识，而 `transaction_id` 则是事务 id，默认递增，保证在某个集群下 GTID 唯一

---

- `写入`，先写`binlog event`，再写 `binlog`
- `复制`，binlog event 和 binlog 传给从库
- `重放`，从库用同样的 GTID 写 binlog

</details>






### 主从复制延迟问题


为什么要优化主从同步的延迟问题？延迟问题的原因？

- 在数据量较大、并发量较大的场景下，延迟会比较严重
- *主从同步的延迟问题无法解决，只能改善，因为既然是复制，那么必然在一段时间内数据是不一致的*
- mysql 主从延迟的主要原因是*从库使用单线程重放 relaylog*
  有哪些使用读写分离后，主从复制延迟导致的坑？

*写操作还没同步到读库，就直接去读库里读取相应数据，导致数据不一致*

---


如何解决主从复制的延迟问题？

优化主从复制延迟的思路？**如何解决主从复制的延迟问题？**(存疑)

主从复制的流程就三步，写入/复制/重放;写操作完成后会实时写入 binlog，没有优化点;所以优化点在于后面两步;复制和重放都可以通过多线程并行

- SQL 线程忙不过来（可能需要应用数据量较大，可能和从库本身的一些操作有锁和资源的冲突；主库可以并发写，SQL 线程不可以；主要原因）
- 网络抖动导致 IO 线程复制延迟（次要原因）
- `优化重放`: MySQL5.7 引入了单数据库的并行复制 (MySQL5.6 引入单实例多库的并行复制，用处不大)，修改`slave-parallel-workers`参数即可，具体配置搜索`Enhanced Multi-threaded Slaves`
- `优化复制`: 优化数据库集群内部网络;
- 我们使用`数据库中间件`来解决延迟问题：所有读写都走数据库中间件，记录所有路由到写库到 key，在主从同步时间窗口内，如果有读请求访问中间件，就把该请求转发到主库 (而非从库);同步完成后，读请求继续走从库;




### 主主复制（互为主从）

- 技术选型：主主复制是啥？为啥要用主主复制？和主从复制有啥区别？*为了保证`主库高可用`，`主主复制`和`shadow-master`这两套方案，哪套比较好？*
- ~~**使用主主复制时 ID 冲突，怎么办？**~~

:::tip
技术选型：怎么保证主库高可用？主主复制是啥？为啥要用主主复制？和主从复制有啥区别？
:::

- 主主复制是什么？为什么要用主主复制？
	- *主主复制的目的就是为了冗余写库* 读写分离 (主从复制) 后无限水平拓展读库，只能保证读库的高可用，但是写库仍然是单点，所以，我们为了保证“写库”的高可用，可以设置两个主库，并且设置双向同步
- 主主复制和主从复制有什么区别？主主复制和主从复制的侧重点不同。*主从复制侧重于冗余，从库用来查询，负担了一部分负载。而主主复制主要侧重于负载，两台主机一起负担“写压力”*

<details>
<summary>为了保证 `主库高可用`，`主主复制` 和 `shadow-master` 这两套方案，哪套比较好？</summary>

这两套方案的优缺点都很明显，*双主互备可以水平拓展写库，提高性能，但是需要解决两台主库之间的读写延迟，以及读写冲突的问题；`shadow-master` 则正好相反。*

- `双主互备` 的方式实现写操作高可用。
- `shadow-master`。虽是双主，但只有一个主提供服务（读 + 写），另一个主是“shadow-master”，只用来保证高可用，平时不提供服务。master 挂了，shadow-master 顶上（vip 漂移，对业务层透明，不需要人工介入）

</details>

<details>
<summary>使用主主复制时 ID 冲突，怎么办？</summary>

- 如果双主复制，修改 `my.cnf`，A 机插入奇数 ID，B 机插入偶数 ID
- 如果多主复制，取消 mysql 自增 id 配置后，用 uuid

</details>




### 为什么不要用`select *`？

- 使用`*`会查出所有字段，从而影响 sql 语句
- *如果表中有 LOB 字段，用`select *`就会查出 LOB 字段，会慢很多*
- 大宽表直接使用*进行查询
- use_merge 这种表连接方式情况下，排序操作的内存消耗有较大的差距，这种差距会在有索引情况下，且指定查询列也能命中索引走索引快速全扫描时被大幅放大
- 如果表中数据很多，查询字段也很多的情况下（不能全部都走索引），使用`*`也会增加不需要的列在数据库返回数据到应用时网络层的消耗。并且，如果机器是`EXADATA`，用`smart scan`就会出现使用`*`和指定字段查询有明显的性能差异


### count(*)、count(1) 和 count(column) 的区别？

- *`count(1)`和`count(*)`是完全相同的，使用相同的优化*。至于，count(1) 的 1 可以理解为“伪列”，也可以理解为`1=1`这样的 true 的情况，只是一个占位符，这两种情况，在 mysql 优化器的角度出发是完全相同的
- 至于 count(column) 和 count(*) 的区别，则是 count(column) 的列如果是一个可空列，那么只会统计该列不为空的条数，所以可能会和总条数不同

[MySQL 表太大，count(*) 都能 502，怎么优化？](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247496626&idx=1&sn=2dd9b16a788f1c8bf7fc0124188d043b)


### MySQL 分页排序时的数据重复问题？

[MySQL Paging Sorting with Data Duplication Problem (MySQL Priority Queue) - SoByte](https://www.sobyte.net/post/2021-09/mysql-paging-sorting-data-duplicates/)

问题原因？根本原因是*MySQL5.6 的优化器在遇到`order by x limit m,n`时使用`priority queue`进行优化，而`priority queue`使用堆排序这个不稳定的排序算法，所以有可能出现“相同的值可能排序出来的结果和读出来的数据顺序不一致”*


解决方法？直接原因是*分页重复数据是否出现与排序字段数据唯一性有关，与排序字段是否有序无关*。所以*如果需要把某个“重复字段”进行排序，只要在`order by`中结合某个“唯一字段”进行排序即可*，把原本不唯一的排序条件变成组合唯一的排序条件，因此可以解决分页数据重复的问题。

[mysql orderby limit 翻页数据重复的问题_唐霜的博客](https://www.tangshuang.net/1827.html)


---


"mysql8 order by priority queue, heapsort"

[Sorting — The Unofficial MySQL 8.0 Optimizer Guide 1.0.1 documentation](http://www.unofficialmysqlguide.com/sorting.html)

```markdown

MySQL has four ways to return results in sorted order, which may be required as part of an ORDER BY or GROUP BY (without ORDER BY NULL). EXPLAIN will show if the data requires a sort operation, but it will not list which sort algorithm is used. This information is available in OPTIMIZER_TRACE. The four ways to return results sorted are as follows:


Via an Index. B+tree indexes are maintained in sorted order, so some ORDER BY queries do not require sorting at all.

Via a Priority Queue. An ORDER BY with a small limit may be able to store the complete result set in a temporary buffer. As an example, consider the query:

Via the Alternative Sort Algorithm. This algorithm is used if no TEXT or BLOB columns are present. It is defined in the MySQL manual [1] as:

Via the original sort algorithm. This algorithm is used when TEXT or BLOB columns are present. It is defined in the MySQL manual [1] as:

```


[Priority Queue and Heap Sort. Priority Queue | by lukeleeai | lukeleeai | Medium](https://medium.com/lukeleeai/priority-queue-and-heap-sort-48768db1dd5e)

[Strange behavior in mySQL 8 with order by, limit and parentheses - Stack Overflow](https://stackoverflow.com/questions/59202878/strange-behavior-in-mysql-8-with-order-by-limit-and-parentheses)


so, refer to these blogpost, mysql8 still has this problem.








### [doc] CatKang 的博客 [2023/11/23]


[Welcome | CatKang 的博客](https://catkang.github.io/) 主要是 zeppelin 和 MySQL 相关的源码分析




---


- [数据库事务隔离发展历史 | CatKang 的博客](https://catkang.github.io/2018/08/31/isolation-level.html)
- [浅析数据库并发控制机制 | CatKang 的博客](https://catkang.github.io/2018/09/19/concurrency-control.html)
- [数据库故障恢复机制的前世今生 | CatKang 的博客](https://catkang.github.io/2019/01/16/crash-recovery.html)
- [庖丁解 InnoDB 之 REDO LOG | CatKang 的博客](https://catkang.github.io/2020/02/27/mysql-redo.html)
- [庖丁解 InnoDB 之 Undo LOG | CatKang 的博客](https://catkang.github.io/2021/10/30/mysql-undo.html)
- [B+ 树数据库加锁历史 | CatKang 的博客](https://catkang.github.io/2022/01/27/btree-lock.html)
- [B+ 树数据库故障恢复概述 | CatKang 的博客](https://catkang.github.io/2022/10/05/btree-crash-recovery.html)
- [庖丁解 InnoDB 之 Buffer Pool | CatKang 的博客](https://catkang.github.io/2023/08/08/mysql-buffer-pool.html)


---

[NewSQL 数据库概述 | CatKang 的博客](https://catkang.github.io/2020/12/01/newsql.html)





---


[浅谈分布式存储系统数据分布方法 | CatKang 的博客](https://catkang.github.io/2017/12/17/data-placement.html)



