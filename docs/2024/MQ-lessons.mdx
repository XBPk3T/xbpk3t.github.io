---
title: MQ相关课程读书笔记
slug: /2024/MQ-lessons
date: 2024-10-13
unlisted: true
---




## MQ



- q: "MQ能够解决哪些问题？***有哪些核心需求（或者说特点）？***"
  x: 通常认为MQ的作用是“削峰填谷、消息分发、异步通信、架构解耦”，按照我的理解，最核心的是“解耦和异步处理”，用来在高并发场景下平滑短时间内大量的服务请求，不使用消息队列的系统，根据木桶效应，性能取决于系统中性能最慢的组件，但是消息队列可以将组件解耦，各组件异步执行。如果没有 MQ，只能在服务里耦合限流服务，那么不管是上游限流，还是下游限流，都会引入业务的复杂性。所以，我们可以把限流通过 MQ 解决，也起到了解耦的作用。


### compares

[17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ 四个分布式消息队列](https://mp.weixin.qq.com/s?__biz=MzkyMzcxODg0MQ==&mid=2247522161&idx=1&sn=6689f4e75ba7fc00e283dae872592f97)

arch, perf(throughput, latency), scalability, durability(fault tolerance, failover), msg delivery semantics, msg ordering, network model, storage model, feats(retry, delay queue) and use cases


- 开发语言
- 支持协议
- 消息存储
- 消息事务
- 负载均衡
- 集群方式
- 管理界面
- 可用性
- 消息重复
- 吞吐量 TPS
- 订阅方式和消息分发
- 顺序消息
- 消息回溯
- 消息重试
- 并发度



:::danger

```yaml
- MQ有哪些通用的相关基础概念（比如说调度算法、消息模式）？



```

:::



### MQ的消息模式是啥意思？


四种

- P2P
- Pub/Sub
- Request-Reply
- Broadcast

本质来说被多少consumer接收和消费（比如说P2P就是只有1个consumer，而Pub/Sub和Broadcast则都有n个consumer接收，但是二者的区别是Broadcast只能被1个consumer消费掉。之于Request-Reply则不限制consumer数量）。

最常用的就是点到点模型和推拉模型

- 点对点模式
- pub/sub模式（推拉模型）
  - 推模式：生产者将消息发送给消息队列，消息队列把消息推给消费者
  - 拉模式：消费者请求消息队列，接收消息。生产者从消息队列中拉取消息




```markdown
消息队列的消息模式是啥意思？kafka、NATS、NSQ这些都有什么消息模式？

---

消息队列的消息模式指的是消息在队列中传递和处理的方式，它决定了消息的交互方式和消费者的行为。不同的消息队列系统可以支持不同的消息模式，下面是一些常见的消息模式示例：

1. 点对点模式（Point-to-Point）：在此模式下，消息生产者将消息发送到特定的队列，然后一个或多个消费者从队列中接收和处理消息。每个消息只能被一个消费者接收，类似于点对点通信。Kafka 和 NATS 都支持点对点模式。

2. 发布-订阅模式（Publish-Subscribe）：在此模式下，消息生产者将消息发送到一个主题（Topic），然后多个消费者订阅该主题并同时接收消息。每个消息可以被多个消费者接收，类似于广播。Kafka 和 NATS 都支持发布-订阅模式。

3. 请求-应答模式（Request-Reply）：在此模式下，消息生产者发送请求消息到一个特定的队列或主题，然后等待一个或多个消费者返回相应的应答消息。这种模式常用于需要请求和响应交互的场景。Kafka 和 NATS 都支持请求-应答模式。

4. 广播模式（Broadcast）：在此模式下，消息生产者将消息发送到一个主题（Topic），然后所有订阅该主题的消费者都会接收到该消息。不同于发布-订阅模式，广播模式下每个消息只会被消费者组中的一个消费者接收。NSQ 支持广播模式。

需要注意的是，虽然 Kafka 和 NATS 都支持点对点模式和发布-订阅模式，但它们的实现和细节可能有所不同。每个消息队列系统都有自己独特的特性和使用方式，因此在选择消息队列时，需要根据具体的需求和使用场景来决定哪种消息模式最适合。


```



:::danger

```yaml
- kafka、NATS、NSQ这些都有什么消息模式？



```

:::



### 常见的 MQ 中间件协议？

Transport(lw? perf? reliable?), use cases(low-bandwidth? IoT? real-time? advanced feats?)

- `AMPQ 协议`，高级消息队列协议，*AMPQ 不是一个具体的消息队列实现，而是一个标准化的消息中间件协议*。目标是让不同语言，不同系统的应用互相通信，并提供一个简单统一的模型和编程接口
- `MQTT 协议`
- `STOMP 协议`
- `XMPP 协议`




:::danger

```yaml
- Compare (AMPQ, MQTT, STOMP, XMPP, DDS, CoAP)?


```

:::



## 《消息队列高手课》


[消息队列高手课](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%AB%98%E6%89%8B%E8%AF%BE)





## kafka



- `Broker`消息服务器，作为 server 提供消息核心服务
- `Producer`消息发布者，业务的发起方，负责生产消息传输给 broker，
- `Consumer`消息订阅者，业务的处理方，负责从 broker 获取消息并进行业务逻辑处理
- `Topic`主题，发布订阅模式下的消息统一汇集地，不同发布者发布不同的主题，由消息服务器分发到不同的订阅者，实现消息的广播
- `Queue`队列，某个发布者向指定 queue 发送消息，订阅者订阅特定的 queue 完成消息的点对点接收
- `Message`消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输





```markdown
Kafka的存储系统设计是为了满足高并发、高可用和高性能的需求。它主要处理实时产生的海量数据流，需要高效地存储和检索数据。Kafka的存储系统基于顺序追加写日志的方式，并通过稀疏索引来快速定位消息。它的存储架构包括主题（Topic）、分区（Partition）、副本（Replica）、分段（Segment）和索引（Index）。每个分区的日志被分为多个日志分段，每个分段包含日志文件和索引文件，以便高效地进行消息的查找、维护和清理。

```




---


可以把 kafka 想像成高速路，而京广高速可以想像成一个 topic(主题路由)

京广高速上有很多车道进行分流，每个车道上的车都通往相同目的地 (同一个 topic)，这里的车道就是 partition(分区路由)

```markdown

谈到 Kafka 的存储设计，了解不多的同学，可能会有这样的疑惑：为什么 Kafka 会采用 Logging（日志文件）这种很原始的方式来存储消息，而没考虑用数据库或者 KV 来做存储？
而对 Kafka 有所了解的同学，应该能快速说出一些 知识点：比如 Append Only、Linear Scans、磁盘顺序写、页缓存、零拷贝、稀疏索引、二分查找等等。

从上图可以看出来，Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构：

- kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的，即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。
- Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话，对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈，故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。
- Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset,  因此 kafka 只能保证每个分区内部有序性，并不能保证全局有序性。
- 然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段 (LogSegment) 的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。
- Log 日志在物理上只是以文件夹的形式存储，而每个 LogSegement 对应磁盘上的一个日志文件和两个索引文件，以及可能的其他文件 (比如以".snapshot"为后缀的快照索引文件等)

```



---


Kafka选择基于日志存储的原因是其设计目标是为了处理高并发写入的场景，而关系型数据库的B+树索引结构在大量写操作时会因为索引维护而降低效率。B+树索引结构还需要额外的空间来存储索引，并可能出现数据页分裂等问题，这些都不适合Kafka的高并发系统需求。相反，日志存储可以通过顺序追加写的方式来提高写入速度，并且可以通过稀疏索引来高效地查询数据。

```markdown
稀疏索引

如何提高读性能，大家很容易想到的是：索引。Kafka 所面临的查询场景其实很简单：能按照 offset 或者 timestamp 查到消息即可。
如果采用 B Tree 类的索引结构来实现，每次数据写入时都需要维护索引（属于随机 IO 操作），而且还会引来「页分裂」这种比较耗时的操作。而这些代价对于仅需要实现简单查询要求的 Kafka 来说，显得非常重。所以，B Tree 类的索引并不适用于 Kafka。
相反，哈希索引看起来却非常合适。为了加快读操作，如果只需要在内存中维护一个「从 offset 到日志文件偏移量」的映射关系即可，每次根据 offset 查找消息时，从哈希表中得到偏移量，再去读文件即可。（根据 timestamp 查消息也可以采用同样的思路）
但是哈希索引常驻内存，显然没法处理数据量很大的情况，Kafka 每秒可能会有高达几百万的消息写入，一定会将内存撑爆。
可我们发现消息的 offset 完全可以设计成有序的（实际上是一个单调递增 long 类型的字段），这样消息在日志文件中本身就是有序存放的了，我们便没必要为每个消息建 hash 索引了，完全可以将消息划分成若干个 block，只索引每个 block 第一条消息的 offset 即可，先根据大小关系找到 block，然后在 block 中顺序搜索，这便是 Kafka“稀疏索引”的设计思想。


采用“稀疏索引”，可以认为是在磁盘空间、内存空间、查找性能等多方面的一个折中。有了稀疏索引，当给定一个 offset 时，Kafka 采用的是二分查找来高效定位不大于 offset 的物理位移，然后找到目标消息。
```

***append 追加写日志 + 稀疏的哈希索引，也就是`LSM Tree`***


---


kafka 的运维和监控

- 主题管理
- 动态配置
- 消费者组的位移管理
- KafkaAdminClient
- 认证机制
- MirrorMaker
- 监控框架
- 授权管理
- kafka 调优
- 流处理应用搭建实例

高级 kafka 应用

- kafka streams
- kafka DSL 开发

kafka 客户端的生产者

- 分区机制
- 压缩算法
- 无消息丢失配置
- 高级功能
- TCP 连接管理
- 幂等性生产者和事务

kafka 客户端的消费者

- 消费者组
- 位移主题
- rebalance
- 位移提交
- 异常处理
- 多线程开发实例
- TCP 连接管理
- group 监控



---



[Kafka is dead, long live Kafka. by Richard Artoul | by WarpStream Labs | Medium](https://medium.com/@warpstream/kafka-is-dead-long-live-kafka-4ef4fdce03e2)

[mq 选型 - V2EX](https://www.v2ex.com/t/765626)





```yaml
    # [Kafka体系架构详细分解 - luozhiyun`s Blog](https://www.luozhiyun.com/archives/260)
    # [深入理解Kafka必知必会（1） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/67)
    # [深入理解Kafka必知必会（2） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/64)
    # [深入理解Kafka必知必会（3） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/58)

```


[32 道常见的 Kafka 面试题你都会吗？附答案](https://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650719847&amp;idx=1&amp;sn=5cbc20ae39756e39552a9a056c133a80&poc_token=HLWE7maj-HqqXBeWYdmqAdNYhfIYxmsPgrQjiNK3) 看这些 kafka 面试题，然后再重新整理

[Kafka Architecture & Internal. This talks about the Apache Kafka… | by Narayan Kumar | Medium](https://mail-narayank.medium.com/kafka-architecture-internal-d0b3334d1df)







## 《Kafka核心技术与实战》

[Kafka核心技术与实战](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98)

---








## 《Kafka核心源码解读》

[Kafka核心源码解读](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB)

---









## 《RocketMQ 实战与进阶》


[RocketMQ 实战与进阶（完）](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/RocketMQ%20%E5%AE%9E%E6%88%98%E4%B8%8E%E8%BF%9B%E9%98%B6%EF%BC%88%E5%AE%8C%EF%BC%89)

---







