---
title: MQ相关课程读书笔记
slug: /2024/MQ-lessons
date: 2024-10-13
unlisted: true
---




## MQ



- q: "MQ能够解决哪些问题？***有哪些核心需求（或者说特点）？***"
  x: 通常认为MQ的作用是“削峰填谷、消息分发、异步通信、架构解耦”，按照我的理解，最核心的是“解耦和异步处理”，用来在高并发场景下平滑短时间内大量的服务请求，不使用消息队列的系统，根据木桶效应，性能取决于系统中性能最慢的组件，但是消息队列可以将组件解耦，各组件异步执行。如果没有 MQ，只能在服务里耦合限流服务，那么不管是上游限流，还是下游限流，都会引入业务的复杂性。所以，我们可以把限流通过 MQ 解决，也起到了解耦的作用。


### compares

[17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ 四个分布式消息队列](https://mp.weixin.qq.com/s?__biz=MzkyMzcxODg0MQ==&mid=2247522161&idx=1&sn=6689f4e75ba7fc00e283dae872592f97)

arch, perf(throughput, latency), scalability, durability(fault tolerance, failover), msg delivery semantics, msg ordering, network model, storage model, feats(retry, delay queue) and use cases


- 开发语言
- 支持协议
- 消息存储
- 消息事务
- 负载均衡
- 集群方式
- 管理界面
- 可用性
- 消息重复
- 吞吐量 TPS
- 订阅方式和消息分发
- 顺序消息
- 消息回溯
- 消息重试
- 并发度



:::danger

```yaml
- MQ有哪些通用的相关基础概念（比如说调度算法、消息模式）？



```

:::



### MQ的消息模式是啥意思？


四种

- P2P
- Pub/Sub
- Request-Reply
- Broadcast

本质来说被多少consumer接收和消费（比如说P2P就是只有1个consumer，而Pub/Sub和Broadcast则都有n个consumer接收，但是二者的区别是Broadcast只能被1个consumer消费掉。之于Request-Reply则不限制consumer数量）。

最常用的就是点到点模型和推拉模型

- 点对点模式
- pub/sub模式（推拉模型）
  - 推模式：生产者将消息发送给消息队列，消息队列把消息推给消费者
  - 拉模式：消费者请求消息队列，接收消息。生产者从消息队列中拉取消息




```markdown
消息队列的消息模式是啥意思？kafka、NATS、NSQ这些都有什么消息模式？

---

消息队列的消息模式指的是消息在队列中传递和处理的方式，它决定了消息的交互方式和消费者的行为。不同的消息队列系统可以支持不同的消息模式，下面是一些常见的消息模式示例：

1. 点对点模式（Point-to-Point）：在此模式下，消息生产者将消息发送到特定的队列，然后一个或多个消费者从队列中接收和处理消息。每个消息只能被一个消费者接收，类似于点对点通信。Kafka 和 NATS 都支持点对点模式。

2. 发布-订阅模式（Publish-Subscribe）：在此模式下，消息生产者将消息发送到一个主题（Topic），然后多个消费者订阅该主题并同时接收消息。每个消息可以被多个消费者接收，类似于广播。Kafka 和 NATS 都支持发布-订阅模式。

3. 请求-应答模式（Request-Reply）：在此模式下，消息生产者发送请求消息到一个特定的队列或主题，然后等待一个或多个消费者返回相应的应答消息。这种模式常用于需要请求和响应交互的场景。Kafka 和 NATS 都支持请求-应答模式。

4. 广播模式（Broadcast）：在此模式下，消息生产者将消息发送到一个主题（Topic），然后所有订阅该主题的消费者都会接收到该消息。不同于发布-订阅模式，广播模式下每个消息只会被消费者组中的一个消费者接收。NSQ 支持广播模式。

需要注意的是，虽然 Kafka 和 NATS 都支持点对点模式和发布-订阅模式，但它们的实现和细节可能有所不同。每个消息队列系统都有自己独特的特性和使用方式，因此在选择消息队列时，需要根据具体的需求和使用场景来决定哪种消息模式最适合。


```



:::danger

```yaml
- kafka、NATS、NSQ这些都有什么消息模式？



```

:::



### 常见的 MQ 中间件协议？

Transport(lw? perf? reliable?), use cases(low-bandwidth? IoT? real-time? advanced feats?)

- `AMPQ 协议`，高级消息队列协议，*AMPQ 不是一个具体的消息队列实现，而是一个标准化的消息中间件协议*。目标是让不同语言，不同系统的应用互相通信，并提供一个简单统一的模型和编程接口
- `MQTT 协议`
- `STOMP 协议`
- `XMPP 协议`




:::danger

```yaml
- Compare (AMPQ, MQTT, STOMP, XMPP, DDS, CoAP)?


```

:::



## 《消息队列高手课》


[消息队列高手课](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%AB%98%E6%89%8B%E8%AF%BE)





## kafka



- `Broker`消息服务器，作为 server 提供消息核心服务
- `Producer`消息发布者，业务的发起方，负责生产消息传输给 broker，
- `Consumer`消息订阅者，业务的处理方，负责从 broker 获取消息并进行业务逻辑处理
- `Topic`主题，发布订阅模式下的消息统一汇集地，不同发布者发布不同的主题，由消息服务器分发到不同的订阅者，实现消息的广播
- `Queue`队列，某个发布者向指定 queue 发送消息，订阅者订阅特定的 queue 完成消息的点对点接收
- `Message`消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输





```markdown
Kafka的存储系统设计是为了满足高并发、高可用和高性能的需求。它主要处理实时产生的海量数据流，需要高效地存储和检索数据。Kafka的存储系统基于顺序追加写日志的方式，并通过稀疏索引来快速定位消息。它的存储架构包括主题（Topic）、分区（Partition）、副本（Replica）、分段（Segment）和索引（Index）。每个分区的日志被分为多个日志分段，每个分段包含日志文件和索引文件，以便高效地进行消息的查找、维护和清理。

```




---


可以把 kafka 想像成高速路，而京广高速可以想像成一个 topic(主题路由)

京广高速上有很多车道进行分流，每个车道上的车都通往相同目的地 (同一个 topic)，这里的车道就是 partition(分区路由)

```markdown

谈到 Kafka 的存储设计，了解不多的同学，可能会有这样的疑惑：为什么 Kafka 会采用 Logging（日志文件）这种很原始的方式来存储消息，而没考虑用数据库或者 KV 来做存储？
而对 Kafka 有所了解的同学，应该能快速说出一些 知识点：比如 Append Only、Linear Scans、磁盘顺序写、页缓存、零拷贝、稀疏索引、二分查找等等。

从上图可以看出来，Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构：

- kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的，即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。
- Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话，对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈，故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。
- Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset,  因此 kafka 只能保证每个分区内部有序性，并不能保证全局有序性。
- 然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段 (LogSegment) 的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。
- Log 日志在物理上只是以文件夹的形式存储，而每个 LogSegement 对应磁盘上的一个日志文件和两个索引文件，以及可能的其他文件 (比如以".snapshot"为后缀的快照索引文件等)

```



---


Kafka选择基于日志存储的原因是其设计目标是为了处理高并发写入的场景，而关系型数据库的B+树索引结构在大量写操作时会因为索引维护而降低效率。B+树索引结构还需要额外的空间来存储索引，并可能出现数据页分裂等问题，这些都不适合Kafka的高并发系统需求。相反，日志存储可以通过顺序追加写的方式来提高写入速度，并且可以通过稀疏索引来高效地查询数据。

```markdown
稀疏索引

如何提高读性能，大家很容易想到的是：索引。Kafka 所面临的查询场景其实很简单：能按照 offset 或者 timestamp 查到消息即可。
如果采用 B Tree 类的索引结构来实现，每次数据写入时都需要维护索引（属于随机 IO 操作），而且还会引来「页分裂」这种比较耗时的操作。而这些代价对于仅需要实现简单查询要求的 Kafka 来说，显得非常重。所以，B Tree 类的索引并不适用于 Kafka。
相反，哈希索引看起来却非常合适。为了加快读操作，如果只需要在内存中维护一个「从 offset 到日志文件偏移量」的映射关系即可，每次根据 offset 查找消息时，从哈希表中得到偏移量，再去读文件即可。（根据 timestamp 查消息也可以采用同样的思路）
但是哈希索引常驻内存，显然没法处理数据量很大的情况，Kafka 每秒可能会有高达几百万的消息写入，一定会将内存撑爆。
可我们发现消息的 offset 完全可以设计成有序的（实际上是一个单调递增 long 类型的字段），这样消息在日志文件中本身就是有序存放的了，我们便没必要为每个消息建 hash 索引了，完全可以将消息划分成若干个 block，只索引每个 block 第一条消息的 offset 即可，先根据大小关系找到 block，然后在 block 中顺序搜索，这便是 Kafka“稀疏索引”的设计思想。


采用“稀疏索引”，可以认为是在磁盘空间、内存空间、查找性能等多方面的一个折中。有了稀疏索引，当给定一个 offset 时，Kafka 采用的是二分查找来高效定位不大于 offset 的物理位移，然后找到目标消息。
```

***append 追加写日志 + 稀疏的哈希索引，也就是`LSM Tree`***


---


kafka 的运维和监控

- 主题管理
- 动态配置
- 消费者组的位移管理
- KafkaAdminClient
- 认证机制
- MirrorMaker
- 监控框架
- 授权管理
- kafka 调优
- 流处理应用搭建实例

高级 kafka 应用

- kafka streams
- kafka DSL 开发

kafka 客户端的生产者

- 分区机制
- 压缩算法
- 无消息丢失配置
- 高级功能
- TCP 连接管理
- 幂等性生产者和事务

kafka 客户端的消费者

- 消费者组
- 位移主题
- rebalance
- 位移提交
- 异常处理
- 多线程开发实例
- TCP 连接管理
- group 监控



---



[Kafka is dead, long live Kafka. by Richard Artoul | by WarpStream Labs | Medium](https://medium.com/@warpstream/kafka-is-dead-long-live-kafka-4ef4fdce03e2)

[mq 选型 - V2EX](https://www.v2ex.com/t/765626)





```yaml
    # [Kafka体系架构详细分解 - luozhiyun`s Blog](https://www.luozhiyun.com/archives/260)
    # [深入理解Kafka必知必会（1） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/67)
    # [深入理解Kafka必知必会（2） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/64)
    # [深入理解Kafka必知必会（3） - luozhiyun`s Blog](https://www.luozhiyun.com/archives/58)

```


[32 道常见的 Kafka 面试题你都会吗？附答案](https://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650719847&amp;idx=1&amp;sn=5cbc20ae39756e39552a9a056c133a80&poc_token=HLWE7maj-HqqXBeWYdmqAdNYhfIYxmsPgrQjiNK3) 看这些 kafka 面试题，然后再重新整理

[Kafka Architecture & Internal. This talks about the Apache Kafka… | by Narayan Kumar | Medium](https://mail-narayank.medium.com/kafka-architecture-internal-d0b3334d1df)







## 《Kafka核心技术与实战》

[Kafka核心技术与实战](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98)

---








## 《Kafka核心源码解读》

[Kafka核心源码解读](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB)

---









## 《RocketMQ 实战与进阶》


[RocketMQ 实战与进阶（完）](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/RocketMQ%20%E5%AE%9E%E6%88%98%E4%B8%8E%E8%BF%9B%E9%98%B6%EF%BC%88%E5%AE%8C%EF%BC%89)

---











## [archive] kafka


### 基础概念/核心需求


*总结一下，解耦和异步处理，以及在高并发场景下平滑短时间内大量的服务请求，不使用消息队列的系统，根据木桶效应，性能取决于系统中性能最慢的组件，但是消息队列可以将组件解耦，各组件异步执行*

- `系统中组件解耦`
- `流量削峰`，如果没有 MQ，只能在服务里耦合限流服务，那么不管是上游限流，还是下游限流，都会引入业务的复杂性。所以，我们可以把限流通过 MQ 解决，也起到了解耦的作用
- `消息分发`
- `异步通信`

[消息队列的精髓与灵魂](https://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&mid=2247549135&idx=1&sn=3970331bf3e4870e403414448492dd46)


```markdown
kafka 其实是一个轻量级 MQ 服务，只支持 MQ 的基本功能，但是不支持延迟队列/重试机制等高级功能

Kafka 最开始其实是 Linkedin 内部孵化的项目，在设计之初是被当做「数据管道」，用于处理以下两种场景：

- 运营活动场景：记录用户的浏览、搜索、点击、活跃度等行为。
- 系统运维场景：监控服务器的 CPU、内存、请求耗时等性能指标。

可以看到这两种数据都属于日志范畴，特点是：数据实时生产，而且数据量很大

所以从一开始，Kafka 就是为实时日志流而生的。了解了这个背景，就不难理解 Kafka 与流数据的关系了，以及 Kafka 为什么在大数据领域有如此广泛的应用？也是因为它最初就是为解决大数据的管道问题而诞生的。


```

```markdown
kafka 有哪些特点？

- `高吞吐量`、`低延迟`：kafka 每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个 topic 可以分多个`partition`,`consumer group`对 partition 进行 consume 操作
- `可扩展性`：kafka 集群支持热扩展
- `持久性`、`可靠性`：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- `容错性`：允许集群中节点失败（若副本数量为 n，则允许 n-1 个节点失败）
- `高并发`：支持数千个客户端同时读写

```

---


*消息队列有哪些核心需求？*

```markdown
- 基本需求
  - 重试和错误处理机制
  - 异步执行
  - 支持高并发
- 架构需求
  - 宕机 failover，无需人工介入
  - 根据不同业务场景提供不同 QoS
  - 完善的监控告警体系，系统监控、业务监控、业务告警
  - 消息系统本身具有 trace 能力，可以快速定位问题
  - 提供消息限流和降级能力
```


*选择方案，有哪些核心需求？怎么设计一个延时队列的实现方案？*

- 重试和失败处理机制
- 多线程执行，或者异步执行。(生产和消费，任务执行不互相影响)
- 支持高并发，出堆入堆的性能要好，否则就会压堆压爆

消息系统有哪些核心需求？

- `性能好`，消息投递和消息消费要性能很好，一般通过增加分片数获取并行处理能力。
- `消息要可靠`，生产端、消费端、MQ 端都不能丢消息。一般通过增加副本，强制刷盘来解决。数据库也要通过主从来做备份。
- `拓展性要好`，增加节点集群增大后，不能降低性能
- `社区活跃`，生态成熟。



---

区别

- 开发语言
- 支持协议
- 消息存储
- 消息事务
- 负载均衡
- 集群方式
- 管理界面
- 可用性
- 消息重复
- 吞吐量 TPS
- 订阅方式和消息分发
- 顺序消息
- 消息回溯
- 消息重试
- 并发度

**[17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ 四个分布式消息队列](https://mp.weixin.qq.com/s?__biz=MzkyNTI5NTQ1NQ==&mid=2247500561&idx=1&sn=931cf980b218db76225c8d12899adf09&source=41#wechat_redirect)**

- NSQ: *大部分消息队列中间件都支持实时消息这个功能；而 NSQ 是只支持实时消息功能的分布式系统*



### 常见的坑/怎么解决？




[我用 kafka 踩过的一些非比寻常的坑](https://mp.weixin.qq.com/s?__biz=MzA4MTc4NTUxNQ==&mid=2650523481&idx=1&sn=e9c16db68b94a859dfc2679e3547ca96)


```markdown
- *顺序问题*
  - 为什么要保证消息的顺序？
  - 怎么保证消息顺序？
  - 出现意外
- *消息积压*
  - 消息体过大
  - 路由规则不合理
  - 批量操作引起的连锁反应
  - 表过大
- 主键冲突
- 数据库主从延迟
- 重复消费
- 多环境消费问题
```


丢数据

[谁能告诉我，Kafka 到底会不会丢数据？](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247496169&idx=1&sn=fdee310f83f62a690c179fd379b15b47)





---


网络模型

[图解 Kafka 超高并发网络架构演进过程](https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247489709&idx=2&sn=959fb1009b0e4ea87e9009b1bca1db87)

可以看到 kafka的 network model 还是一个经典的 CPT+reactor



---

```markdown

### kafka 的吞吐率为什么那么高？

*写入数据时顺序写入+MMAP；读取数据时零拷贝 + 批量压缩*

- 顺序写入：消息有序性
- MMAP
- 基于 sendfile 实现的零拷贝，kafka 把所有消息都存放在文件中，消费者需要数据的时候 kafka 直接把文件发送给消费者，配合 mmap 作为文件读写方式，直接把他传给 sendfile
- 批量压缩，消息服务的瓶颈是网络 io，所以通过对多个消息批量压缩，来有效降低网络 io




### kafka 是怎么做到`消息有序性`的？

kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。
kafka 的数据一致性原理？


```

---

kafka 为什么发生背压 (消息堆压) 的问题？

kafka 如何避免背压现象？

*背压就是消费者消费不动，导致生产者阻塞的现象*

```markdown

- `消费者消费速率问题`
 - 消费者过少生产者消费速率过快，或者说消费者组里其中一个消费者宕机也会导致
 - 增加消费者数量 (注意 rebalance)，以及加快消费者消费的速率
- `分区的消息分布不均匀`
 - 如果要保证生产者消息有序的话，就要指定 key，如果某个范围的 key 都路由到了某个分区，就会导致消费者组消费分区时，某个分区的消息就特别多，从而导致消费速率不均衡
 - 解决方法：为每个 key 增加随机后缀，均匀路由到每个分区


- 监控队列，动态调用消费者，适时增加消费者
- 做好降级方案，达到预设阈值，出队后暂不处理，直接先持久化再说
- 消费者投递异步任务，不要阻塞出队列

```

---



```markdown

#### 生产消息

批量发送消息

Kafka 作为一个消息队列，很显然是一个 IO 密集型应用，它所面临的挑战除了磁盘 IO（Broker 端需要对消息持久化），还有网络 IO（Producer 到 Broker，Broker 到 Consumer，都需要通过网络进行消息传输）。
在上一篇文章已经指出过：磁盘顺序 IO 的速度其实非常快，不亚于内存随机读写。这样网络 IO 便成为了 Kafka 的性能瓶颈所在。
基于这个背景，Kafka 采用了批量发送消息的方式，通过将多条消息按照分区进行分组，然后每次发送一个消息集合，从而大大减少了网络传输的 overhead。
老许注：overhead 在这里意味着开销的意思

看似很平常的一个手段，其实它大大提升了 Kafka 的吞吐量，而且它的精妙之处远非如此，下面几条优化手段都和它息息相关。

消息压缩

消息压缩的目的是为了进一步减少网络传输带宽。而对于压缩算法来说，通常是：数据量越大，压缩效果才会越好。
因为有了批量发送这个前提，从而使得 Kafka 的消息压缩机制能真正发挥出它的威力（压缩的本质取决于多消息的重复性）。对比压缩单条消息，同时对多条消息进行压缩，能大幅减少数据量，从而更大程度提高网络传输率。
有文章对 Kafka 支持的三种压缩算法：gzip、snappy、lz4 进行了性能对比，测试 2 万条消息，效果如下：

整体来看，gzip 压缩效果最好，但是生成耗时更长，综合对比 lz4 性能最佳。

其实压缩消息不仅仅减少了网络 IO，它还大大降低了磁盘 IO。因为批量消息在持久化到 Broker 中的磁盘时，仍然保持的是压缩状态，最终是在 Consumer 端做了解压缩操作。

这种端到端的压缩设计，其实非常巧妙，它又大大提高了写磁盘的效率。

3、高效序列化
Kafka 消息中的 Key 和 Value，都支持自定义类型，只需要提供相应的序列化和反序列化器即可。因此，用户可以根据实际情况选用快速且紧凑的序列化方式（比如 ProtoBuf、Avro）来减少实际的网络传输量以及磁盘存储量，进一步提高吞吐量。

4、内存池复用
前面说过 Producer 发送消息是批量的，因此消息都会先写入 Producer 的内存中进行缓冲，直到多条消息组成了一个 Batch，才会通过网络把 Batch 发给 Broker。
当这个 Batch 发送完毕后，显然这部分数据还会在 Producer 端的 JVM 内存中，由于不存在引用了，它是可以被 JVM 回收掉的。
但是大家都知道，JVM GC 时一定会存在 Stop The World 的过程，即使采用最先进的垃圾回收器，也势必会导致工作线程的短暂停顿，这对于 Kafka 这种高并发场景肯定会带来性能上的影响。
有了这个背景，便引出了 Kafka 非常优秀的内存池机制，它和连接池、线程池的本质一样，都是为了提高复用，减少频繁的创建和释放。
具体是如何实现的呢？其实很简单：Producer 一上来就会占用一个固定大小的内存块，比如 64MB，然后将 64 MB 划分成 M 个小内存块（比如一个小内存块大小是 16KB）。
当需要创建一个新的 Batch 时，直接从内存池中取出一个 16 KB 的内存块即可，然后往里面不断写入消息，但最大写入量就是 16 KB，接着将 Batch 发送给 Broker，此时该内存块就可以还回到缓冲池中继续复用了，根本不涉及垃圾回收。最终整个流程如下图所示：

了解了 Producer 端上面 4 条高性能设计后，大家一定会有一个疑问：传统的数据库或者消息中间件都是想办法让 Client 端更轻量，将 Server 设计成重量级，仅让 Client 充当应用程序和 Server 之间的接口。

但是 Kafka 却反其道而行之，采取了独具一格的设计思路，在将消息发送给 Broker 之前，需要先在 Client 端完成大量的工作，例如：消息的分区路由、校验和的计算、压缩消息等。这样便很好地分摊 Broker 的计算压力。
可见，没有最好的设计，只有最合适的设计，这就是架构的本源。

---

#### 存储消息

##### IO 多路复用

对于 Kafka Broker 来说，要做到高性能，首先要考虑的是：设计出一个高效的网络通信模型，用来处理它和 Producer 以及 Consumer 之间的消息传递问题。

Kafka 采用的是：很典型的 Reactor 网络通信模型，完整的网络通信层框架图如下所示：


通俗点记忆就是 1 + N + M：

1：表示 1 个 Acceptor 线程，负责监听新的连接，然后将新连接交给 Processor 线程处理。

N：表示 N 个 Processor 线程，每个 Processor 都有自己的 selector，负责从 socket 中读写数据。

M：表示 M 个 KafkaRequestHandler 业务处理线程，它通过调用 KafkaApis 进行业务处理，然后生成 response，再交由给 Processor 线程。

对于 IO 有所研究的同学，应该清楚：Reactor 模式正是采用了很经典的 IO 多路复用技术，它可以复用一个线程去处理大量的 Socket 连接，从而保证高性能。Netty 和 Redis 为什么能做到十万甚至百万并发？它们其实都采用了 Reactor 网络通信模型。

##### 磁盘顺序写

通过 IO 多路复用搞定网络通信后，Broker 下一步要考虑的是：如何将消息快速地存储起来？
在 Kafka 存储选型的奥秘一文中提到了：Kafka 选用的是「日志文件」来存储消息，那这种写磁盘文件的方式，又究竟是如何做到高性能的呢？
这一切得益于磁盘顺序写，怎么理解呢？
Kafka 作为消息队列，本质上就是一个队列，是先进先出的，而且消息一旦生产了就不可变。这种有序性和不可变性使得 Kafka 完全可以「顺序写」日志文件，也就是说，仅仅将消息追加到文件末尾即可。
有了顺序写的前提，我们再来看一个对比实验，从下图中可以看到：磁盘顺序写的性能远远高于磁盘随机写，甚至高于内存随机写。

原因很简单：对于普通的机械磁盘，如果是随机写入，性能确实极差，也就是随便找到文件的某个位置来写数据。但如果是顺序写入，因为可大大节省磁盘寻道和盘片旋转的时间，因此性能提升了 3 个数量级。

##### Page Cache

磁盘顺序写已经很快了，但是对比内存顺序写仍然慢了几个数量级，那有没有可能继续优化呢？答案是肯定的。
这里 Kafka 用到了 Page Cache 技术，简单理解就是：利用了操作系统本身的缓存技术，在读写磁盘日志文件时，其实操作的都是内存，然后由操作系统决定什么时候将 Page Cache 里的数据真正刷入磁盘。
通过下面这个示例图便一目了然。


那 Page Cache 究竟什么时候会发挥最大的威力呢？这又不得不提 Page Cache 所用到的两个经典原理。
Page Cache 缓存的是最近会被使用的磁盘数据，利用的是「时间局部性」原理，依据是：最近访问的数据很可能接下来再访问到。而预读到 Page Cache 中的磁盘数据，又利用了「空间局部性」原理，依据是：数据往往是连续访问的。
而 Kafka 作为消息队列，消息先是顺序写入，而且立马又会被消费者读取到，无疑非常契合上述两条局部性原理。因此，页缓存可以说是 Kafka 做到高吞吐的重要因素之一。
除此之外，页缓存还有一个巨大的优势。用过 Java 的人都知道：如果不用页缓存，而是用 JVM 进程中的缓存，对象的内存开销非常大（通常是真实数据大小的几倍甚至更多），此外还需要进行垃圾回收，GC 所带来的 Stop The World 问题也会带来性能问题。可见，页缓存确实优势明显，而且极大地简化了 Kafka 的代码实现。

##### 分区分段结构

磁盘顺序写加上页缓存很好地解决了日志文件的高性能读写问题。但是如果一个 Topic 只对应一个日志文件，显然只能存放在一台 Broker 机器上。
当面对海量消息时，单机的存储容量和读写性能肯定有限，这样又引出了又一个精妙的存储设计：对数据进行分区存储。
我在 Kafka 架构设计的任督二脉一文中详细解释了分区（Partition）的概念和作用，它是 Kafka 并发处理的最小粒度，很好地解决了存储的扩展性问题。随着分区数的增加，Kafka 的吞吐量得以进一步提升。
其实在 Kafka 的存储底层，在分区之下还有一层：那便是「分段」。简单理解：分区对应的其实是文件夹，分段对应的才是真正的日志文件。


每个 Partition 又被分成了多个 Segment，那为什么有了 Partition 之后，还需要 Segment 呢？
如果不引入 Segment，一个 Partition 只对应一个文件，那这个文件会一直增大，势必造成单个 Partition 文件过大，查找和维护不方便。
此外，在做历史消息删除时，必然需要将文件前面的内容删除，只有一个文件显然不符合 Kafka 顺序写的思路。而在引入 Segment 后，则只需将旧的 Segment 文件删除即可，保证了每个 Segment 的顺序写。

```

---




```markdown

#### 消费消息

##### 稀疏索引

如何提高读性能，大家很容易想到的是：索引。Kafka 所面临的查询场景其实很简单：能按照 offset 或者 timestamp 查到消息即可。
如果采用 B Tree 类的索引结构来实现，每次数据写入时都需要维护索引（属于随机 IO 操作），而且还会引来「页分裂」这种比较耗时的操作。而这些代价对于仅需要实现简单查询要求的 Kafka 来说，显得非常重。所以，B Tree 类的索引并不适用于 Kafka。
相反，哈希索引看起来却非常合适。为了加快读操作，如果只需要在内存中维护一个「从 offset 到日志文件偏移量」的映射关系即可，每次根据 offset 查找消息时，从哈希表中得到偏移量，再去读文件即可。（根据 timestamp 查消息也可以采用同样的思路）
但是哈希索引常驻内存，显然没法处理数据量很大的情况，Kafka 每秒可能会有高达几百万的消息写入，一定会将内存撑爆。
可我们发现消息的 offset 完全可以设计成有序的（实际上是一个单调递增 long 类型的字段），这样消息在日志文件中本身就是有序存放的了，我们便没必要为每个消息建 hash 索引了，完全可以将消息划分成若干个 block，只索引每个 block 第一条消息的 offset 即可，先根据大小关系找到 block，然后在 block 中顺序搜索，这便是 Kafka“稀疏索引”的设计思想。


采用“稀疏索引”，可以认为是在磁盘空间、内存空间、查找性能等多方面的一个折中。有了稀疏索引，当给定一个 offset 时，Kafka 采用的是二分查找来高效定位不大于 offset 的物理位移，然后找到目标消息。

##### mmap

利用稀疏索引，已经基本解决了高效查询的问题，但是这个过程中仍然有进一步的优化空间，那便是通过 mmap（memory mapped files）读写上面提到的稀疏索引文件，进一步提高查询消息的速度。

注意：mmap 和 page cache 是两个概念，网上很多资料把它们混淆在一起。此外，还有资料谈到 Kafka 在读 log 文件时也用到了 mmap，通过对 2.8.0 版本的源码分析，这个信息也是错误的，其实只有索引文件的读写才用到了 mmap.

究竟如何理解 mmap？前面提到，常规的文件操作为了提高读写性能，使用了 Page Cache 机制，但是由于页缓存处在内核空间中，不能被用户进程直接寻址，所以读文件时还需要通过系统调用，将页缓存中的数据再次拷贝到用户空间中。
而采用 mmap 后，它将磁盘文件与进程虚拟地址做了映射，并不会招致系统调用，以及额外的内存 copy 开销，从而提高了文件读取效率。

关于 mmap，好友小风哥写过一篇很通俗的文章：mmap 可以让程序员解锁哪些骚操作？大家可以参考。
具体到 Kafka 的源码层面，就是基于 JDK nio 包下的 MappedByteBuffer 的 map 函数，将磁盘文件映射到内存中。
至于为什么 log 文件不采用 mmap？其实是一个特别好的问题，这个问题社区并没有给出官方答案，网上的答案只能揣测作者的意图。个人比较认同 stackoverflow 上的这个答案：
mmap 有多少字节可以映射到内存中与地址空间有关，32 位的体系结构只能处理 4GB 甚至更小的文件。Kafka 日志通常足够大，可能一次只能映射部分，因此读取它们将变得非常复杂。然而，索引文件是稀疏的，它们相对较小。将它们映射到内存中可以加快查找过程，这是内存映射文件提供的主要好处。

老许注：mmap 也是一种零拷贝技术

##### 零拷贝

消息借助稀疏索引被查询到后，下一步便是：将消息从磁盘文件中读出来，然后通过网卡发给消费者，那这一步又可以怎么优化呢？
Kafka 用到了零拷贝（Zero-Copy）技术来提升性能。所谓的零拷贝是指数据直接从磁盘文件复制到网卡设备，而无需经过应用程序，减少了内核和用户模式之间的上下文切换。
下面这个过程是不采用零拷贝技术时，从磁盘中读取文件然后通过网卡发送出去的流程，可以看到：经历了 4 次拷贝，4 次上下文切换。


如果采用零拷贝技术（底层通过 sendfile 方法实现），流程将变成下面这样。可以看到：只需 3 次拷贝以及 2 次上下文切换，显然性能更高。


##### 批量拉取

和生产者批量发送消息类似，消息者也是批量拉取消息的，每次拉取一个消息集合，从而大大减少了网络传输的 overhead。
另外，在 Kafka 精妙的高性能设计（上篇）中介绍过，生产者其实在 Client 端对批量消息进行了压缩，这批消息持久化到 Broker 时，仍然保持的是压缩状态，最终在 Consumer 端再做解压缩操作。

```


---


```markdown

### 存储设计

- 功能性需求：存的是什么数据？量级如何？需要存多久？CRUD 的场景都有哪些？
- 非功能性需求：性能和稳定性的要求是什么样的？是否要考虑扩展性？

---

- 存的数据主要是消息流：消息可以是最简单的文本字符串，也可以是自定义的复杂格式。但是对于 Broker 来说，它只需处理好消息的投递即可，无需关注消息内容本身。
- 数据量级非常大：因为 Kafka 作为 Linkedin 的孵化项目诞生，用作实时日志流处理（运营活动中的埋点、运维监控指标等），按 Linkedin 当初的业务规模来看，每天要处理的消息量预计在千亿级规模。
- CRUD 场景足够简单：因为消息队列最核心的功能就是数据管道，它仅提供转储能力，因此 CRUD 操作确实很简单。

非功能性需求：

- 性能要求：之前的文章交代过，Linkedin 最初尝试过用 ActiveMQ 来解决数据传输问题，但是性能无法满足要求，然后才决定自研 Kafka。ActiveMQ 的单机吞吐量大约是万级 TPS，Kafka 显然要比 ActiveMQ 的性能高一个量级才行。
- 稳定性要求：消息的持久化（确保机器重启后历史数据不丢失）、单台 Broker 宕机后如何快速故障转移继续对外提供服务，这两个能力也是 Kafka 必须要考虑的。
- 扩展性要求：Kafka 面对的是海量数据的存储问题，必然要考虑存储的扩展性。

再简单总结下，Kafka 的存储需求如下：

- 功能性需求：其实足够简单，追加写、无需 update、能根据消费位移和时间戳查询消息、能定期删除过期的消息。
- 非功能性需求：是难点所在，因为 Kafka 本身就是一个高并发系统，必然会遇到典型的高性能、高可用和高扩展这三方面的挑战。

### kafka 存储场景剖析

### kafka 存储选型

### kafka 存储架构设计

*append 追加写日志 + 稀疏的哈希索引，也就是`LSM Tree`*

谈到 Kafka 的存储设计，了解不多的同学，可能会有这样的疑惑：为什么 Kafka 会采用 Logging（日志文件）这种很原始的方式来存储消息，而没考虑用数据库或者 KV 来做存储？
而对 Kafka 有所了解的同学，应该能快速说出一些 知识点：比如 Append Only、Linear Scans、磁盘顺序写、页缓存、零拷贝、稀疏索引、二分查找等等。




从上图可以看出来，Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构：

- kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的，即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。
- Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话，对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈，故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。
- Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset,  因此 kafka 只能保证每个分区内部有序性，并不能保证全局有序性。
- 然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段 (LogSegment) 的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。
- Log 日志在物理上只是以文件夹的形式存储，而每个 LogSegement 对应磁盘上的一个日志文件和两个索引文件，以及可能的其他文件 (比如以".snapshot"为后缀的快照索引文件等)

### kafka 日志系统架构设计

```

[搞透 Kafka 的存储架构，看这篇就够了](https://mp.weixin.qq.com/s?__biz=MzU3NzEwNjI5OA==&mid=2247484749&idx=1&sn=9f8a82c1896c999bac39419a5acf9d7d)






```markdown
- 日志收集：一个公司可以用 Kafka 可以收集各种服务的 log，通过 kafka 以统一接口服务的方式开放给各种 consumer，例如 hadoop、HBase、Solr 等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka 经常被用来记录 web 用户或者 app 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 kafka 的 topic 中，然后订阅者通过订阅这些 topic 来做实时的监控分析，或者装载到 hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka 也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
- 流式处理：比如 spark streaming 和 Flink

kafka 的运维和监控

- 主题管理
- 动态配置
- 消费者组的位移管理
- KafkaAdminClient
- 认证机制
- MirrorMaker
- 监控框架
- 授权管理
- kafka 调优
- 流处理应用搭建实例

高级 kafka 应用

- kafka streams
- kafka DSL 开发

kafka 客户端的生产者

- 分区机制
- 压缩算法
- 无消息丢失配置
- 高级功能
- TCP 连接管理
- 幂等性生产者和事务

kafka 客户端的消费者

- 消费者组
- 位移主题
- rebalance
- 位移提交
- 异常处理
- 多线程开发实例
- TCP 连接管理
- group 监控

```





### kafka 面试题

[32 道常见的 Kafka 面试题你都会吗？附答案](https://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650719847&amp;idx=1&amp;sn=5cbc20ae39756e39552a9a056c133a80)



```markdown
14、数据传输的事务有几种？
数据传输的事务定义通常有以下三种级别：
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输

（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.

（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被

```


```markdown
- kafka 里怎么保证 exactly once？
- kafka 怎么保证信息不丢失？

可以把 kafka 想像成高速路，而京广高速可以想像成一个 topic(主题路由)

京广高速上有很多车道进行分流，每个车道上的车都通往相同目的地 (同一个 topic)，这里的车道就是 partition(分区路由)

```




ISR、OSR、AR 是什么？

- *ISR 是由 leader 维护，follower 从 leader 同步数据有一些延迟，超过相应的阈值会把 follower 剔除出 ISR, 存入 OSR（Out-of-Sync Replicas）列表，新加入的 follower 也会先存放在 OSR 中。AR=ISR+OSR*
- `ISR`In-Sync Replicas 副本同步队列
- `OSR`Out-of-Sync Replicas
- `AR`Assigned Replicas 所有副本

LEO、HW、LSO、LW 等分别代表什么？

- `LEO`
- `HW`
- `LSO`
- `LW`

kafka 包括哪些组件？

- `broker 服务代理`，kafka 集群中的实例被称为 broker
- `producer`生产者
- `topic 消息主题`，是一个消息记录发布后的逻辑名称，一个 topic 被分为若干个分区，用于消息的发布
- `consumer`和`consumer group`订阅一个或一组 topic，从 broker 拉数据，进行消费

Kafka 架构分为以下几个部分

```markdown
Producer ：消息生产者，就是向 kafka broker 发消息的客户端。

Consumer ：消息消费者，向 kafka broker 取消息的客户端。

Topic ：可以理解为一个队列，一个 Topic 又分为一个或多个分区，

Consumer Group：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。

Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。

Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。

Offset：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是 00000000000.kafka。
```




### [archive]




```markdown
## RabbitMQ



- **RabbitMQ 是什么？**
- RabbitMQ 的 ACK 机制是什么？
- RabbitMQ 的交换器、路由、绑定？
- RabbitMQ 的 RPC 机制？
- RabbitMQ 的延迟队列？
- RabbitMQ 的单节点故障恢复？
- **golang 怎么使用 RabbitMQ？**




### RabbitMQ 是什么？


- direct: 交换机和一个队列绑定起来，并指定一个路由键
- fanout: 交换机寻找匹配的路由键的绑定，并将消息路由给对应的队列


### golang 怎么使用 RabbitMQ？

- **[streadway/amqp: Go client for AMQP 0.9.1](https://github.com/streadway/amqp)** RabbitMQ
- 使用 [streadway/amqp: Go client for AMQP 0.9.1](https://github.com/streadway/amqp) 操作 rabbitMQ 服务
- 使用 [rabbitmq/rabbitmq-delayed-message-exchange](https://github.com/rabbitmq/rabbitmq-delayed-message-exchange) 插件，实现延迟队列。
- [RabbitMQ Go 教程 2——工作队列](https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651446336&idx=3&sn=c875b288597ffd4d11bba5e5922c6bc4)
- [duolabmeng6/go-rabbitmq-easy: 容易使用的 rabbitmq](https://github.com/duolabmeng6/go-rabbitmq-easy)

---

- [go web+RabbitMQ 实战速学篇 - 程序员在囧途 - jtthink.com](https://www.jtthink.com/course/110)


```

