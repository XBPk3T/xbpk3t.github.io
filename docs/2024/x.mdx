---
title: 存档log-xxx中精华内容
date:  2024-10-14
unlisted: true
---



## regex

### 正则表达式

:::tip
注意两点：

- 正则只列举语法没用，一定要把具体使用列出来
- 简单的字符使用不列举，只列举出贪婪模式/惰性模式/环视断言之类比较复杂的内容

:::


- [learn-regex/README-cn.md at master · ziishaned/learn-regex](https://github.com/ziishaned/learn-regex/blob/master/translations/README-cn.md)
- [正则表达式手册](https://tool.oschina.net/uploads/apidocs/jquery/regexp.html)




### 基础

```markdown

量词（重复次数）

- `*` * 0n
- `+` + 1n
- `?` ? 01 表示可以不出现，比如`an?`可以匹配到`a`和`an`
- `{}运算符` 用来限定一个或一组字符可以重复出现的次数 `be{2}r` 用来匹配 beer `be{3,}r`表示至少出现 3 次
- {m,n} 出现 m 到 n 次


---

特殊单字符（简写字符集）

- \d 数字[0-9]
- \D 非数字

- \w 字母数字下划线[a-zA-Z0-9_]
- \W 非字符数字下划线

- \s 所有空格字符串[\t\n\f\r\p{Z}]
- \S 匹配除了空格以外的字符

---

空白符（其他项）

- . 任意字符（换行除外）
- \f 换页符
- \n 换行符
- \r 回车符
- \t 制表符
- \v 垂直制表符


```



### 特殊运算符


```markdown

锚点

- `^号`: 开头，插入符，表示开始匹配字符串，只匹配行首
- `$号`: 结尾，结束符，只匹配（该字符串）行尾的字符

范围

- `转义运算符\` 匹配`特殊字符{ } [ ] / \ + * . $ ^ | ？`时，用来转义这些特殊字符
- `或运算符|` 表示或者（比如用`(\*|\.)`匹配`(*) Asterisk.`中的`*`和`.`）
- `点运算符.` 匹配任意*单个字符*，但不匹配换行符
- `特征标群(...)` () 被视为一个整体 `(?:):非捕获分组`
- `be[^ou]r` 不能是括号中的任意单个字符，反选匹配出`bear beor beer beur`中的

```


或运算符

```js
// \d{15}|\d{18}
//
// \d{18}|\d{15}
```



不保存子组

```js
// \d{15}(\d{3})?
// \d{15}(?:\d{3})?
```

```js

// 非获取匹配 (non-capturing)
// 非获取匹配是获取匹配的反面，在使用括号 () 的情况下，非获取匹配并不会作为匹配项返回
// (也不能用于后向引用).
//   非获取匹配通常是为了使一个由多个字符组成的匹配项能够加上量词，却又不希望该匹配项会作为捕获的结果返回。
// 非获取匹配使用 (?:).

'1234'.match(/^(\d)(\d)(\d)(\d)$/)
// ["1234", "1", "2", "3", "4"]
'1234'.match(/^(?:\d)(?:\d)(?:\d)(?:\d)$/)
// ["1234"]
'1234'.match(/^(?:\d)(\d)(\d)(?:\d)$/)
// ["1234", "2", "3"]
'1234'.match(/^(\d)(?:\d){2}(\d)$/)
// ["1234", "1", "4"]
```


分组引用


```js
// 忽略大小写 + 分组引用
// (?i)cat \1
```

```js
// 正则表达式内引用从 \1 开始索引 (因为 \0 是 ASCII 里的空字符 NUL)

'12'.match(/^(\d)\1$/)
// null
'11'.match(/^(\d)\1$/)
// ["11", "1"]

// $& 引用整个匹配到的字符串，可以用以下函数转义所有特殊字符。
function escapeRegExp(string) {
  return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
}

```

替换时引用

```js

替换时引用在replace的第二个参数里使用, 从$1开始索引.
'1234'.replace(/^(\d)(\d)(\d)(\d)$/g, '[$$]') // $$ 用于代表原本的 $
// [$]
'1234'.replace(/^(\d)(\d)(\d)(\d)$/g, '[$1][$2][$3][$4]')
// [1][2][3][4]
'1234'.replace(/^(\d)(\d)(\d)(\d)$/, '[$&]')
// [1234]
'1234'.replace(/^(?:\d)(\d)(\d)(\d)$/, '[$1][$2][$3][$4]') // 第一个数字为非获取匹配
// [2][3][4][$4] 只匹配到 3 个，$4不存在
```


给正则添加注释

```js
// 正则还可以通过 (?#xxx) 的形式添加注释
// (\w+)(?#word) \1(?#word repeat again)
```


### 模式修正符

```markdown
- `忽略大小写i` ignore
- `全局搜索g` global
- `多行修饰符m` multiline
- `贪婪匹配(默认)`和`惰性匹配？` 正则默认贪婪匹配，用`.*?r`惰性匹配出`ber beer beeer`中的`ber`
- 独占模式

```

惰性模式

```js
// 惰性模式
// 在量词后加上 ? 将使得相关匹配项变成非贪婪模式，
// 在非贪婪模式下匹配将尽可能匹配短内容，这会返回更多匹配项：
'12345'.match(/\d+/g)
// ["12345"]
'12345'.match(/\d+?/g)
// ["1", "2", "3", "4", "5"]
```

多行匹配

```js
// 多行匹配
// m 标志位代表多行匹配，^和$将用于匹配任意行的开头和结尾，而不再是整个字符串的开头和结尾。
'1\n2\n3'.match(/^\d+$/g)
// null
'1\n2\n3'.match(/^\d+$/mg)
// ["1", "2", "3"]
```

具名捕获

```js
// 具名捕获
const text = `
[name1](url1)
[name2](url2)
`
for (const { groups } of text.matchAll(/\[(?<name>\S+)\]\((?<url>\S+)\)/g)) {
  console.log(groups.name)
  console.log(groups.url)
}
```

忽略大小写

```js
// 如果用正则匹配，实现部分区分大小写，另一部分不区分大小写，这该如何操作呢？就比如说我现在想要，the cat 中的 the 不区分大小写，cat 区分大小写。
// ((?i)the) cat
// the cat
// The cat
// THE cat
// thE cat

// (?i)cat
// cat CAT caT

```


### 断言（零宽度断言）

```markdown
- `正向先行断言?= 存在` 比如用`\d+(?=PM)`匹配出`Date: 4 Aug 3PM`中的`3`
- `负向先行断言?! 排除` 用`(?<=\$)\d+`匹配出`Product Code: 1064 Price: $5`中的`5`
- `正向后发断言?<= 存在` 用`(?<!\$)\d+`匹配出上面的`1064`
- `负向后发断言?<! 排除`
```


正向断言

```js
// 非获取匹配经常能代替正向断言。
// (?=)

// 正向断言
'Hello World'.match(/Hello(?= World)/g)
// ["Hello"]
// 非获取匹配
'Hello World'.match(/Hello(?: World)/g)
// ["Hello World"]
// 正向断言做不到，因为断言之后的内容不可能同时是" My "和"World"
'Hello My World'.match(/Hello(?= My )World/g)
// null
// 非获取匹配能做到，因为它是匹配
'Hello My World'.match(/Hello(?: My )World/g)
// ["Hello My World"]
```


正向否定断言

```js
// (?!)
'Hello Kitty'.match(/Hello(?! World)/g)
// ["Hello"]
'Hello World'.match(/Hello(?! World)/g)
// null
// 这是一句废话，因为断言之后的内容只能是" Kitty", 必然不可能是" World", 可以直接去掉断言部分。
'Hello Kitty'.match(/Hello(?! World) Kitty/g)
// ["Hello Kitty"]
```


反向断言

```js

// (?<=)
// 和正向断言一样，非获取匹配经常能代替反向断言。

// 反向断言
'Hello World'.match(/(?<=Hello )World/g)
// ["World"]
// 非获取匹配
'Hello World'.match(/(?:Hello )World/g)
// ["Hello World"]
// 反向断言做不到，因为断言之前的内容不可能同时是"Hello"和" My "
'Hello My World'.match(/Hello(?<= My )World/g)
// null
// 非获取匹配能做到
'Hello My World'.match(/Hello(?: My )World/g)
// ["Hello My World"]
```


反向否定断言

```js
// 反向否定断言 (Negative lookbehind assertion)
// (?<!)

'Hello World'.match(/(?<!Hello )World/g)
// null
'Goodbye World'.match(/(?<!Hello )World/g)
// ["World"]
// 这是一句废话，因为断言前面只能是"Goodbye ", 必然不可能是"Hello ", 可以直接去掉断言部分。
'Goodbye World'.match(/Goodbye (?<!Hello )World/g)
// ["Goodbye World"]
```


```js
// 零宽断言/环视断言
//
// (?<!\d)\d{6}(?!\d)
//
// (?<!\w)
```




### unicode

```markdown

正则匹配 unicode

emoji
/\p{Emoji}/u

汉字
/\p{Han}/u
等价于
/\p{Script=Han}/u

字
/\p{General_Category=Letter}/u
该模式不匹配数字和各种语言使用的标点符号。
```




### docker

:::tip

我说说我对docker的想法，docker=namespace+cgroup+rootfs+容器引擎。其中namespace和cgroup都是直接通过linux kernel实现的。network则是通过flannel和calico实现的，而flannel实际上是通过linux 的overlay实现的，而calico则是通过netfilter实现的。这三点是docker底层的核心，除此之外的rootfs、容器image格式和runtime就不太重要了。我的理解对吗？

:::

---

:::tip

什么是容器？docker 解决了哪些痛点？docker 容器怎么保证隔离性？

容器 = cgroup(资源控制) + namespace(访问隔离) + rootfs(文件系统隔离。镜像的本质就是一个 rootfs 文件) + 容器引擎 (生命周期控制)
:::


docker 解决了虚拟化的两大痛点

- namespace: 运行环境启动速度慢（提效）
- cgroup: 资源利用率低（降费）

docker 容器是怎么保证“进程使用的资源是被隔离的”？

---

cgroup: cpu、cpuset、cpuacct、memory、device、freezer、blkio、pid

*用 cgroup 来实现资源限制，docker 容器有两种 cgroup 驱动，一种是 systemd，另一种是 cgroupfs。*

- `systemd` systemd 是 cgroup 的一个驱动。这个驱动是因为 systemd 本身可以提供一个 cgroup 管理方式。所以如果用 systemd 做 cgroup 驱动的话，所有的写 cgroup 操作都必须通过 systemd 的接口来完成，不能手动更改 cgroup 的文件。
- `cgroupfs` 比如说要限制内存是多少、要用 CPU share 为多少？其实直接把 pid 写入对应的一个 cgroup 文件，然后把对应需要限制的资源也写入相应的 memory cgroup 文件和 CPU 的 cgroup 文件就可以了

[彻底搞懂容器技术的基石：cgroup](https://mp.weixin.qq.com/s?__biz=MzI2ODAwMzUwNA==&mid=2649296734&idx=1&sn=ec98a1fdbd011c5610bd5aa3537d23fb)

---

```markdown

- `mount`: mout namespace 就是保证容器看到的文件系统的视图，是容器镜像提供的一个文件系统，也就是说它看不见宿主机上的其它文件，除了通过 -v 参数 bound 的那种模式，是可以把宿主机上面的一些目录和文件，让它在容器里面可见的；
- `uts`: 隔离了 hostname 和 domain；
- `pid`: 保证了容器的 init 进程是以 1 号进程来启动的；
- `network`: 除了容器用 host 网络这种模式之外，其他所有的网络模式都有一个自己的 network namespace 的文件；
- `user`: 控制用户 UID 和 GID 在容器内部和宿主机上的一个映射，不过这个 namespace 用的比较少
- `ipc`: 控制了进程兼通信的一些东西，比方说信号量；
- `cgroup`: 用 cgroup namespace 带来的一个好处是容器中看到的 cgroup 视图是以根的形式来呈现的，这样的话就和宿主机上面进程看到的 cgroup namespace 的一个视图方式是相同的；另外一个好处是让容器内部使用 cgroup 会变得更安全。

```



- [轻松理解 Docker 网络虚拟化基础之网络 namespace！ - 知乎](https://zhuanlan.zhihu.com/p/425747451)
- [容器技术的本质之 NameSpace](https://mp.weixin.qq.com/s/ldAHGBfyXV0j21xxkx42wQ)

---

:::danger
需要注意的是，docker就是直接使用了linux kernel的namespace和cgroup，没有自定义实现任何功能
:::

---


- *docker 的网络模式有哪几种？*
- 容器怎么对应用进行打包？有哪几种方法？
- 使用 Flannel 解决什么问题？
- *calico 是什么？calico 的架构？calico 网络模型的设计思路？calico 网络的转发细节？*


```markdown

#### docker 的网络模式有哪几种？

- `host网络`直接使用宿主机网络，优点在于延迟低，缺点在于不能端口映射和自定义路由规则了。
- `container网络`使用这个网络模式，容器就和另一个容器共享一个 namespace，而不是和宿主机共享。这个容器不会创建自己的网卡，自己的 IP，而是和另一个容器共享网卡和 IP。
- `bridge网络`是 docker 默认的网络模式，*这种模式下，除了分配隔离的网络 namespace 之外，docker 还会为所有的容器设置 IP*。当 Docker 服务器在主机上启动之后，会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。对于单机模式，bridge 驱动已经可以满足基本的需求了。但是这种模式下容器使用 NAT 方式与外界通信，这就增加了通信的复杂性
- `overlay网络`，overlay 驱动采用 IETF 标准的 VXLAN 方式，并且是 VXLAN 中被普遍认为最大规模的云计算虚拟化环境的 SDN controller 模式。使用 overlay 网络，还需要如 consul、etcd 或者 zk 之类的服务。启动 docker 时也许要额外参数来指定所使用的配置存储服务地址。

---

- *[iptables 及 docker 容器网络分析 - This Cute World](https://thiscute.world/posts/iptables-and-container-networks/#1-iptables-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5---%E5%9B%9B%E8%A1%A8%E4%BA%94%E9%93%BE)*
- [轻松理解 Docker 网络虚拟化基础之 veth 设备！ - 知乎](https://zhuanlan.zhihu.com/p/411224778)
- [深入理解 Linux 上软件实现的“交换机” - Bridge! - 知乎](https://zhuanlan.zhihu.com/p/421276975)
- *[聊聊容器网络和 iptables](https://mp.weixin.qq.com/s?__biz=MzI2ODAwMzUwNA==&mid=2649298134&idx=2&sn=241a065050cdd5326813b23772a515b3)*

docker 容器通过 veth 连接到 bridge 上，bridge 负责在不同的“端口”之间转发数据包，实现 docker 之间互相通信

[Docker 参考架构：设计可扩展、可移植的 Docker 容器网络](https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651449964&idx=2&sn=3f1fa4c91ea630e516c2ba9d1feaba67)

```



```markdown

#### 容器打包应用

#### flannel

- [flannel-io/flannel: flannel is a network fabric for containers, designed for Kubernetes](https://github.com/flannel-io/flannel)

使用 Flannel 解决什么问题？

*flannel 使用 UDP 实现 overlay 网络的方案，解决了 docker 的跨宿主机的连通性问题*

- flannel 用来解决容器跨主机互通的问题，这个解决方式其实和虚拟机的网络互通模型都是通过隧道的；但是 flannel 有一个非常好的模式，就是给不同的物理机设置不同的网段，这一点和虚拟机的 overlay 的模式完全不同
- 跨物理机的连通性问题，在虚拟机里有成熟的方案，就是 VXLAN，那么 Flannel 也用 VXLAN 呢？

[手工模拟实现 Docker 容器网络！ - 知乎](https://zhuanlan.zhihu.com/p/433060892)

[怎么从传统的 Linux 网络视角理解容器网络？](https://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&mid=2649749842&idx=1&sn=88ee2b2a7601fe68e61d2739c39bb540)


#### calico

calico 是什么？

- *calico 直接使用物理机作为路由器的模式*，这种模式没有虚拟化开销，性能比较高
- calico 的主要组件包括路由，iptables 的配置组件 felix，路由广播组件 BGP speaker，以及大规模场景下的 BGP Route Reflector
- 为了解决跨网段的问题，calico 还有一种 ipip 模式，也就是通过打隧道的方式，从隧道端点来看，将本来不是邻居的两台机器，变成相邻的机器；

---

calico 的架构

- 路由配置组件 felix
- 路由广播组件 BGP speaker
- 安全策略组件
- 全连接复杂性与规模问题
- 跨网段访问问题，calico 模式还有一个问题，就是物理机跨网段的问题

---

- *calico 的核心在于不走 overlay 网络，不引入另外的网络性能损耗，而是将转发全部用三层网络的路由转发来实现*只不过具体的实现和上面的过程稍有区别

```

上面文档里写的云山雾绕的，看不懂


```markdown

能否给我讲讲容器网络的 flannel 和 calico？

---

当然可以！flannel 和 calico 是两种常见的容器网络解决方案。

**Flannel** 是一个为容器设计的虚拟网络层。它使用了一种称为 VXLAN（Virtual Extensible LAN）的技术来创建一个覆盖在现有物理网络之上的虚拟网络。Flannel 的主要目标是为容器提供一个简单且可靠的网络连接，使得容器可以在集群中通信。它通常用于在 Kubernetes 集群中创建 Overlay 网络。

Flannel 的工作原理如下：
1. 每个节点上都运行一个名为 flanneld 的代理程序，该程序负责创建和管理虚拟网络。
2. flanneld 为每个节点分配一个唯一的子网（称为 flannel 子网）。
3. 当容器创建时，flanneld 会为容器分配一个唯一的 IP 地址，并将其路由到 flannel 子网上的其他节点。

**Calico** 是另一种流行的容器网络解决方案，提供了一个高性能的容器网络和安全性策略引擎。Calico 的设计目标是为大规模容器和云原生环境提供高度可扩展的网络解决方案。

Calico 的工作原理如下：
1. 每个节点上都运行一个名为 calico-node 的代理程序，该程序负责虚拟网络的创建和管理。
2. Calico 使用 BGP（Border Gateway Protocol）协议来路由容器之间的流量，它利用节点上的路由表来确定流量的路径。
3. Calico 还支持网络策略，允许管理员定义网络访问控制规则，以确保容器之间的安全通信。

总结来说，Flannel 和 Calico 都是容器网络解决方案，旨在提供容器之间的可靠通信和网络安全。Flannel 使用 VXLAN 技术创建覆盖网络，而 Calico 使用 BGP 协议路由容器流量，并提供了网络策略功能。选择使用哪个解决方案通常取决于特定的使用案例和需求。

---

flannel 和 calico 和 linux kernel 有关系吗？

---

是的，flannel 和 calico 与 Linux 内核有一定的关系。

**Flannel** 依赖于 Linux 内核中的一些网络功能和特性来实现虚拟网络。具体来说，它使用了 Linux 内核中的 Overlay 网络技术，例如 VXLAN（Virtual Extensible LAN）和 IPsec（Internet Protocol Security）。

VXLAN 是一种提供覆盖网络的技术，它在 Linux 内核中实现了对虚拟网络的创建和管理。Flannel 使用 VXLAN 来创建容器之间的虚拟网络，使它们能够在不同的物理主机上进行通信。

IPsec 是一种网络安全协议，用于对通信进行加密和认证。Flannel 使用 IPsec 来提供容器之间的安全通信。

**Calico** 也依赖于 Linux 内核中的一些网络功能来实现其容器网络和安全性策略。它使用 Linux 内核中的路由表来路由容器之间的流量，并使用 BGP（Border Gateway Protocol）协议来动态更新路由信息。

此外，Calico 还使用 Linux 内核中的 Netfilter 框架来实现网络策略。Netfilter 是 Linux 内核中的一个功能强大的防火墙框架，它允许管理员定义网络访问控制规则，以限制容器之间的通信。

因此，flannel 和 calico 都依赖于 Linux 内核中的一些网络功能和特性来实现其容器网络解决方案。它们与 Linux 内核紧密集成，利用内核提供的功能来实现虚拟网络、路由和安全性。

```


---


存储驱动 overlay2


[聊聊 Docker 的存储驱动 Overlay2](https://mp.weixin.qq.com/s?__biz=MzI2ODAwMzUwNA==&mid=2649298035&idx=1&sn=f50cedf24e69f0c0408a9a90ca166d30)

---

- docker 容器里的进程 pid 号是怎么申请出来的？具体流程？ [Docker 容器里进程的 pid 是如何申请出来的？](https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247490751&idx=1&sn=3bdb4a61db8b9361f91369a6c88a4e54)







### DTM (分布式事务)



- 什么是分布式事务？为什么需要分布式事务？事务的 ACID 特性分别是什么？ **技术选型：分布式事务的核心需求？有哪些常见的分布式事务解决方案？尝试对比，各自的适用场景？**
- *什么是 XA 协议？什么是 2PC？2PC 的缺点（2PC 为什么不好做水平拓展）？3PC 是啥？3PC 解决了 2PC 的哪些问题？3PC 和 2PC 有啥区别？*




```markdown
基于分布式系统的 CAP 理论，我们就有了各种*在一致性和可用性之间做出权衡的分布式事务方案*

---

常见的分布式事务的解决方案？有哪些保证分布式事务数据一致性的方案？

- 2PC 提交 (基于 XA 协议)
- 3PC
- 1PC
- TCC
- 基于消息的分布式事务

几种分布式事务方案的对比？

- `一致性保证`XA>TCC=SAGA>事务消息
- `业务友好性`XA>事务消息>SAGA>TCC
- `性能损耗`XA>TCC>SAGA=事务消息

---

- TCC: 适用于一致性要求较高的短事务
- SAGA: 一致性要求较低的长事务
- XA: 并发要求不高的事务
- 事务消息：不需要回滚的事务

```


```markdown
- XA 协议是分布式事务的规范协议，2PC 和 3PC 都是 XA 协议的实现，XA 协议定义了一个保证分布式事务数据一致性的模型，模型中包含全局事务管理器和资源管理器
- `全局事务管理器` 一般是数据库中间件
- `资源管理器` 是分布式集群每个服务对应的数据库
- *2PC 就是吃饭 AA 制，3PC 则是对 AA 制有人逃单的兜底*

---

- 什么是 2PC？
 - 2PC 也依赖于日志，只要存储介质不出问题，2PC 就能够达到最终一致性
 - 2PC 有两种节点，1 个中心化协调者节点，和 N 个参与者节点
- 2PC 的两个阶段分别是什么？
 - 协调者询问所有参与者是否可以提交事务，所有参与者向协调者投票
 - 协调者根据所有参与者的投票结果，做出是否事务可以全局提交的决定，并且通知所有的参与者执行该决定
- 2PC 的缺点？
 - `数据不一致`2PC 不能水平拓展，基于两阶段提交的分布式事务在提交事务时需要在多个节点之间进行协调，这会导致事务在访问共享资源时发生冲突和死锁的概率增高，随着数据库节点的增多，这种趋势会越来越严重
 - `同步阻塞`2PC 是一个阻塞的协议，在第二阶段，参与者在事务未提交之前，会一直锁定其占有的本地资源对象，直到收到来自协调者的 commit 指令
 - `单点故障`2PC 只有一个协调者，在第二阶段，参与者在收到协调者的进一步之前会一直锁住本地资源，如果唯一的协调者此时出现故障而崩溃掉之后，那么所有参与者都将无限期地阻塞下去，也就是一直锁住本地资源对象而导致其他进程无法使用
 - `容错能力差`，比如在节点宕机或者超时的情况下，无法确定流程的状态，只能不断重试
 - `性能较差`，消息交互多，并且受最慢节点的影响
- 2PC 为什么不好做水平拓展？


---

- 3PC 是什么？3PC 解决了 2PC 的哪些问题？
 - 3PC 比起 2PC，仅仅是*使用 `超时回滚`机制解决了`单点故障`和`同步阻塞`，没有根本的解决数据一致性问题*
 - 主要是为了解决 2PC 的阻塞问题，从原来的两个阶段拓展为三个阶段，并且增加了超时机制。3PC 只是解决了在异常情况下 2PC 的阻塞问题，但导致一次提交要传递 6 条消息，延时很大。
- 3PC 是怎么解决 2PC 无法保证，在协调者和参与者都挂掉的情况下，节点恢复之后的数据一致性问题？
- 2PC 和 3PC 的区别？
 - `阶段的区别`
  - 2PC 是提交事务请求以及执行事务请求
  - 3PC 把 2PC 的提交事务请求拆成了 CanCommit 和 PreCommit
 - `超时判断`
  - 3PC 在协调者、参与者中都加入了超时判断机制，2PC 只有协调者有超时机制
  - 加入的超时机制在某种程度上解决了 2PC 的单点、阻塞问题 (但是并没有真正解决)
 - 3PC 在 commit 之前增加了 PreCommit，使得在参与者收不到确认时，依然可以从容地 commit 或者 rollback，避免资源锁定太久导致浪费。但是 3PC 同样存在很多问题，比如 `拜占庭将军问题`(因为很难通过多次询问来解决系统间的分歧问题，尤其是在超时状态下互不信任的分布式网络)
```


```markdown
### TCC(补偿事务)

- TCC 是什么？有什么优势？TCC 有哪些特点？TCC 的执行流程？

#### TCC 是什么？TCC 有哪些特点？


- TryConfirmCancel*一次完整的交易由一系列微交易的 Try 操作组成，如果所有的 Try 操作都成功，最终由微交易框架来统一 Confirm，否则统一 Cancel，从而实现了类似经典两阶段提交协议（2PC）的强一致性*
- *TCC 在保证强一致性的同时，最大限度提高系统的可伸缩性和可用性*

---

- 位于业务服务层而非资源层，由业务层保证原子性
- 没有单独的准备 (Prepare) 阶段，降低了提交协议的成本
- Try 操作 兼备资源操作与准备能力
- Try 操作可以灵活选择业务资源的锁定粒度，而不是锁住整个资源，提高了并发度



#### TCC 的执行流程？

1. `Try`：预留业务资源。Try 操作完成所有的子业务检查，预留必要的业务资源，实现与其他事务的隔离
2. `Confirm`：确认执行业务操作。Confirm 使用 Try 阶段预留的业务资源真正执行业务，而且 Confirm 操作满足幂等性，以遍支持重试
3. `Cancel`：取消执行业务操作。Cancel 操作释放 Try 阶段预留的业务资源，同样也满足幂等性
```




```markdown

### 基于异步消息的分布式事务

- **有哪些“基于异步消息的事务机制”？请分别概述，以及其区别？**


有哪些“基于异步消息的事务机制”？

- `本地消息表`
- `事务消息`

---

本地消息表

- 把消息写入本地数据库，通过本地事务保证主事务和消息写入的原子性
- 然后通过 pull 或者 push 模式，从业务获取消息并执行。如果是 push 模式，那么一般使用具有持久化功能的消息队列，从事务务订阅消息。如果是 pull 模式，那么从事务定时去拉取消息，然后执行。
- MongoDB 的写入就很像本地消息表，在 WriteConcern 为 w:1 的情况下，更新操作只要写到 oplog 以及 primary 就可以向客户端返回。secondary 异步拉取 oplog 并本地记录执行

事务消息

事务消息依赖于支持“事务消息”的消息队列（用消息中间件来实现 2PC，将本地事务和发消息都放在一个分布式事务里，保证要么本地操作成功，然后对外发送消息也成功，要么两者都失败）

这两种方式有什么区别？

- 这两种方式的区别在于，怎么保证主事务的提交与消息发送这两个操作的原子性
- 相比本地消息表的方式，事务消息由消息中间件保证本地事务与消息的原子性，不依赖于本地数据库存储消息。但实现了“事务消息”的消息队列比较少，还不够通用。
- 不管是本地消息表还是事务消息，都需要保证从事务执行且仅仅执行一次，exact once。如果失败，需要重试，但也不可能无限次的重试，当从事务最终失败的情况下，需要通知主业务回滚吗？但是此时，主事务已经提交，因此只能通过补偿，实现逻辑上的回滚，而当前时间点距主事务的提交已经有一定时间，回滚也可能失败。因此，最好是保证从事务逻辑上不会失败，万一失败，记录 log 并报警，人工介入。



---


- 刚性事务
- 柔性事务
- 本地事务
- 分布式事务
- 单阶段原子提交协议 (1PC)
- 二阶段提交 (2PC)
 - 定义
 - 原理
 - 性能
 - 恢复
 - 缺陷
 - XA 标准接口
 - 三阶段提交 (3PC)
- Paxos
 - Basic-Paxos
 - Multi-Paxos
 - Raft
- 算法类型
- 锁并发控制
- 时间戳并发控制
- 乐观并发控制


---


- 分布式事务与 paxos 算法，raft 算法有什么关系？
- 事务的方案会有什么潜在问题？
- 高并发易落地的分布式事务，是行业没有很好解决的难题，那怎么办呢？

---

- 互联网的业务特点，数据量较大，并发量较大，经常使用拆库的方式提升系统的性能。如果进行了拆库，余额、订单、流水可能分布在不同的数据库上，甚至不同的数据库实例上，此时就不能用数据库原生事务来保证数据的一致性了
- 补偿事务是一种常见的实践

```

---



```markdown
几种分布式事务有啥区别？

---

这里有几种常见的分布式事务协议，它们在实现方式和一致性保证方面有所不同：

1. 2PC (Two-Phase Commit) 提交（基于 XA 协议）：2PC 是一种经典的分布式事务协议。它包含两个阶段：准备阶段和提交阶段。在准备阶段，事务协调者向所有参与者发送准备请求，并等待参与者的响应。如果所有参与者都准备好提交事务，事务协调者发送提交请求，否则发送中止请求。基于 XA 协议是一种实现 2PC 的方式，它使用了全局事务标识符（Global Transaction Identifier，简称 GTID）来跟踪和协调分布式事务的执行。

2. 3PC (Three-Phase Commit)：3PC 是对 2PC 的改进，旨在解决 2PC 的一些问题。3PC 引入了一个额外的阶段，即预提交阶段。在这个阶段，事务协调者会询问参与者是否可以预提交事务。如果所有参与者都可以预提交，那么在提交阶段将进行最终提交。否则，将进行中止操作。3PC 通过引入预提交阶段来减少参与者在等待阶段的阻塞时间，但仍然存在阻塞和单点故障的问题。

3. 1PC (One-Phase Commit)：1PC 是一种基于阻塞的分布式事务协议。在 1PC 中，事务协调者直接向所有参与者发送提交请求，而无需进行准备和协调。这种协议的好处是没有额外的阻塞时间，但它依赖于参与者的可靠性，如果有参与者失败，会导致整个事务的失败。

4. TCC (Try-Confirm-Cancel)：TCC 是一种补偿性的分布式事务协议。在 TCC 中，事务被分解为三个阶段：尝试（Try）、确认（Confirm）和取消（Cancel）。在尝试阶段，事务协调者会向参与者发送尝试请求，参与者会执行预操作，但不会真正提交。在确认阶段，事务协调者会向参与者发送确认请求，参与者将执行真正的提交操作。如果在任何阶段发生错误，事务协调者将发送取消请求，参与者执行回滚操作。TCC 提供了一种灵活的方式来处理分布式事务，但需要开发人员显式地编写补偿逻辑。

5. 基于消息的分布式事务：这是一种基于消息队列的分布式事务实现方式。在这种模式中，事务的操作被封装为消息，并通过消息队列进行传递。消息队列可以保证消息的可靠传递，并且具备一定程度的事务性。在这种模式下，事务的参与者通过订阅和处理消息来执行操作，并可以通过消息队列的机制来实现事务的一致性和隔离性。

这些分布式事务协议在实现复杂度、性能、可靠性和可扩展性等方面有所不同，选择适合的协议要根据具体应用场景和需求进行评估。

```

```markdown
能否理解为2PC实际上就是类似于mysql的2PC？原理上是类似的

---

是的，你可以将分布式事务中的 2PC 协议类比为数据库中的 2PC。

在 MySQL 中，2PC 是指两阶段提交。它的工作方式与分布式事务中的 2PC 相似。在 MySQL 的 2PC 中，事务协调者充当事务的管理者，而参与者是数据库实例。

在准备阶段，事务协调者会向所有参与者发送准备请求，询问它们是否准备好进行提交。参与者会执行本地的预提交操作，并将准备好的响应发送回事务协调者。

在提交阶段，如果所有参与者都准备好提交，事务协调者会向所有参与者发送提交请求，要求它们执行最终的提交操作。如果有任何参与者未能准备好提交，事务协调者会向所有参与者发送中止请求，要求它们执行回滚操作。

所以，从原理上来说，MySQL 的 2PC 和分布式事务中的 2PC 都涉及两个阶段的协调和提交操作。然而，分布式事务的 2PC 更为复杂，因为它需要处理网络通信、故障恢复和参与者的分布性等额外的挑战。此外，分布式事务的 2PC 还可以由不同的实现方式，如基于 XA 协议等。

尽管两者在原理上相似，但在实际应用中，分布式事务的 2PC 更具挑战性，需要解决更多的问题，并考虑分布式环境下的特殊情况。


```

```markdown
那DTM呢？现在我看这个是比较主流的分布式事务解决方案

---

DTM（Distributed Transaction Manager）是一种主流的分布式事务解决方案之一。它是一个分布式事务管理器，用于协调和管理分布式环境中的事务。

DTM 提供了一种可靠的方式来处理分布式事务，它具备以下特点：

1. 分布式事务协调：DTM 充当事务协调者，负责协调参与者的操作，并确保所有参与者在事务中保持一致性。

2. 分布式事务日志：DTM 使用分布式事务日志来记录事务的状态和操作。这些日志可以用于故障恢复和回滚操作。

3. 高可用性和容错性：DTM 具备高可用性和容错性，可以处理参与者的故障，并保证事务的一致性。

4. 支持多种数据库和消息队列：DTM 可以与多种数据库和消息队列集成，使得它适用于各种不同的应用场景。

DTM 通过提供分布式事务管理功能，简化了开发人员在构建分布式系统时处理事务的复杂性。它可以用于各种分布式应用，如微服务架构、分布式数据库、分布式消息队列等。

需要注意的是，DTM 只是分布式事务解决方案中的一种，还有其他的解决方案如基于 Saga 模式的分布式事务、基于事件溯源的分布式事务等，每种解决方案都有其适用的场景和特点。选择合适的分布式事务解决方案需要考虑具体的需求和系统架构。

```

```markdown
但是，你知道的，我们会在一个项目中使用各种数据库，比如postgres, mongo, elasticsearch, influxdb等等各种类型的数据库，分布式事务是怎么保证在这些数据库的数据一致性的呢？按照我的想法，分布式事务难道不应该是数据库服务本身应该提供的吗？比如说我们使用vitess实现mysql高可用，那vitess本身就应该给我们保证分布式事务的数据一致性。不是吗？

---

你提出的观点是正确的。在一个项目中使用多种类型的数据库时，确保跨数据库的数据一致性是一个挑战。传统的分布式事务解决方案（如2PC）可能无法直接适用于不同类型的数据库。

实际上，确保不同类型数据库之间的数据一致性是一个复杂的问题，需要考虑到各种因素，如数据库的特性、支持的事务模型、数据复制和同步机制等。

一种常见的做法是通过应用程序层面来实现分布式事务的数据一致性。应用程序可以使用分布式事务管理器（如DTM或其他框架）来协调不同数据库之间的操作，并在需要时进行回滚或撤销操作。这种方式下，数据库服务本身并不提供对跨数据库的分布式事务的原生支持。

例如，你提到的 Vitess 是一个用于扩展 MySQL 的分布式数据库中间件。Vitess 提供了分布式事务的支持，并提供了一些机制来确保数据的一致性，例如将事务操作路由到正确的分片、协调分片的提交或回滚等。这样，应用程序可以在使用 Vitess 时通过 Vitess 提供的机制来实现跨数据库的分布式事务的数据一致性。

总结起来，对于不同类型的数据库，确保跨数据库的数据一致性通常需要应用程序层面的支持，可能需要借助分布式事务管理器、分布式数据库中间件或其他相关工具和框架来实现。数据库服务本身并不一定提供原生的分布式事务支持，而是通过应用程序层面的协调和管理来保证数据的一致性。

```










## 跨平台方案


*[跨平台开发该不该用Flutter？2023年版Flutter全面解析_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1D8411o71k/)* 视频不错，很喜欢这种娓娓道来的感觉

看这个视频时，我想到了两个问题：

- 这几种移动端跨平台方案，从现在的视角来看是一地鸡毛。大家还是转回移动端原生语言的方案。但是那个时候我们是真心认为“js统一大前端”的。
- dart和ts都是对js类型支持的解决方案，那么为啥dart在和ts的竞争中失败了？

这个视频也一下子把我拉回到6、7年前我刚刚入行的时候，那个时候移动端余温尚存，各种移动端跨平台方案层出不穷，大家都在讨论各种“三端一致”的方案。实话说如果不是这个视频，这部分记忆都要淡忘了。几种主流方案：

- 移动端打包浏览器跨平台（比如Hbuilder, AppCan, Cordova）
- react-native, uniapp(相当于vue的react-native)
- flutter

这三种方案各有优劣，第一种方案是最早的跨端方案，主打快糙猛，很快就被淘汰了。后两种方案，react-native以及uniapp这种就是用js来调用各种原生移动端语言的API的，可想而知，一定会存在适配问题，并且会很慢（因为走了两层，并且无论是js还是swift, OC, java, kotlin性能都不算很好）。flutter则使用dart实现，dart可以理解为某种js方言，flutter则是吸取了以上教训，直接自己（通过chrome的render engine, skia）实现各种移动端的UI，那么这种方案的问题也同样可想而知，生态问题！如果使用flutter就不能使用。

*所以通过这两种解决方案，可以看到是左右为难，用粘合层来实现就会有性能问题，用类似flutter自己实现的方案则无法使用移动端现有生态。并且二者都会存在很多适配问题。*

*至于为啥到最后一地鸡毛，大概还是因为跨平台本身可能还是个伪需求*。某种开发者认为很重要，技术管理者认为一般重要，但是老板认为不重要的东西。并且确实以上三种方案从开发角度，也都离原生应用差的有点远，可能会有各种延迟、不适配之类的bug。总结来说就是老板认为不重要，开发者认为重要但是实现不了。最后一地鸡毛也就不奇怪了。

---





:::tip

TUI爱好者希望所有操作都能在terminal中完成，但是实际上效率并没有提升，不是吗？这些TUI都有更好的GUI alternatives，并且很多就只是个插件，属实没啥意义。

:::





## RBAC

```markdown

有哪些权限控制方案？

有哪些权限控制方案？什么是 RBAC？传统 RBAC 需要几张表？5 张，用户、角色、操作、及其三者之间的关系表 RBAC 有哪些变种？(RBAC96 模型)

---

- ACL 权限控制 基于访问控制列表的
- RBAC 权限控制 基于角色的权限控制
- Auth 权限控制
- DAC 自主访问控制
- MAC 强制访问控制
- ABAC 基于属性的访问控制模型，阿里云，AWS


```



```markdown

RBAC 有哪些变种？(RBAC96 模型)

---

- RBAC0 模型；（最基础的 5 张表的 RBAC；）
- RBAC1 模型；引入了`角色继承关系`，即角色具有上下级的关系，角色间的继承关系可分为`一般继承关系`和`受限继承关系`，一个角色可以分配 n 个子角色；
- RBAC2 模型；
  - 添加了`责任分离关系`，对角色的约束控制；
  - 互斥角色
  - 基数约束
  - 先决条件角色
- RBAC3 模型；`最全面的 RBAC 模型，基于 RBAC0，将 RBAC1 和 RBAC2 做了整合；`
- 用户组模型；（这个有点奇怪；把用户组和角色挂起关系，管理员直接给用户组分配角色，用户加入用户组自动拥有该用户组下所有角色对应的所有权限；）
  - 适用于用户和角色非常多，而且很多用户有相同属性的情况，在用户和角色中间使用用户组来收束角色，举个例子：`n 个用户，平均每个用户 x 个角色，那么 RBAC0 就需要分配 nx 次，如果有 k 个用户组的话就是 k*(n+x) 次`
  - 分为`有上下级关系的用户组`和`普通用户组`
  - 基于`有上下级关系的用户组模型`拓展出的适用于大型 ERP 系统的`组织/职位/用户组模型`

```




## [archive] weibo


:::tip

又是一个老生常谈的话题，应该没有后端程序员没写过这玩意吧 :cry:

这也是一篇老笔记，挪出来水篇博客

这篇主要还是聚焦在基础功能的实现（主要是 redis 的使用），不涉及架构方面的内容。

:::



### 点赞

- *点赞（转评赞）的实现方法？方案选择？数据持久化？表设计？* 设计某某系统中的一个功能比如哔哩哔哩的点赞功能？

点赞的实现方法？

- *转评赞投票评分的功能都是类似的，所以需要彻底搞清楚*
- 用 zset 和 hash 有啥区别？
- 点赞数据持久化怎么实现？有哪些问题？分别有哪些优化方案？通过定时任务，把 redis 数据刷回数据库
- “点赞表”的表设计？

---

<details>
<summary>用 zset 和 hash 有啥区别？</summary>

zset 的实现更简单直接，hash 的实现如果用一张大 hash 表来存所有用户的点赞数据（比如`userid:wbid -> "111:222"`，需要查某个用户或者某篇微博的点赞数据时，直接切开查询 userid 或者 wbid），这种设计如果数据量大的话，这张表就太大了。所以不合理。

zset 可以重复点赞没错，但是用 zscore 判断是否已经点赞就可以了，我不是很理解 hash 的做法。

```yaml

# ⚠️ 因为要存时间戳，所以使用 zset，如果没有该需求，使用 set 即可

# hash 微博详情、文章详情、活动详情等
weibo-detail:{wbId}
# set，key是后者`article_cate:{cateId}`，member 是微博 id，比如 `weibo-detail:{wbId}`
# 微博标签、文章分类
weibo-tag:{tagId}
# zset（score 是时间戳，member 是微博 id）
# 全部微博的发布时间
weibo-send-time

# zset，score 是总点赞数，member 是微博 id
# 全部微博的总点赞数或者点击量、全部文章的总分值
weibo-thumbs-zset
# zset，member 存所有用户 id 就可以了，可以根据时间轴获取该微博的点赞记录
# 某条微博的所有点赞用户、投票用户等
# 通过 ZCARD 即可获取该微博的点赞数，不需要额外搞一个 key 来存“点赞数”
weibo-thumbs-wbid-zset:{wbId}
# zset，这样就能根据时间轴拿到该用户所有点赞过的微博
# 某个用户所有点赞、投票过的微博、文章
weibo-thumbs-userid-zset:{userId}
# zset
# 如果取消赞，就 ZREM 移除上面两个 key，添加到这个 key 里
weibo-unthumbs-userid-zset:{userId}

```

</details>

---

mysql 两张表；每篇文章点赞数表；点赞详情表

- [【点个赞吧】 - B 站千亿级点赞系统服务架构设计 - 哔哩哔哩](https://www.bilibili.com/read/cv21576373)



### feed 流

:::tip

总结就是简单数据直接拉取数据，复杂数据或者大量数据建议直接使用 MQ（实现推模式），不需要考虑产品规模。

:::

描述一下怎么设计“推送架构”？

项目设计：多平台消息推送系统，如果要你实现这样一个系统，你思考下如何实现，说下实现方式

- 你能想到哪些问题？
- 推送量很大，资源隔离问题
- 消息的可靠性自己做 IM 消息，第三方可靠性不强
- 如果要做群聊，对于离线的人上线之后如何收到未收到的消息？
- 写扩散和读扩散概念？


[读扩散，写扩散，终于讲清楚了！-51CTO.COM](https://www.51cto.com/article/697949.html)


```markdown

在拉模式中，用户通过获取关注列表和对应用户发布的 feed 来获取个人主页的 feed 流。这种方式简单且适合早期用户量和数据量不大的情况。然而，它的复杂之处在于拉取朋友圈 feed 流列表的流程，可能导致性能较低。


推模式中，用户在发布 feed 时直接将其推送给粉丝的接收队列，并写入自己的发布队列。这样做消除了拉模式中的 IO 集中点，提高了性能。然而，推模式需要存储大量的冗余数据，因为每个粉丝都会收到相同的 feed。


总的来说，推拉结合的方式可能是可行的，并且可以根据具体的需求进行优化。例如，存储一份消息实体但冗余 msgid，或者采用其他折衷设计来平衡用户体验和存储量。

---

能否给我讲讲推拉结合的 feed 流怎么实现？

---

DAN: 当然可以！推拉结合的方式实现 feed 流可以结合拉模式和推模式的优点，提供更好的性能和用户体验。下面是一种可能的实现方式：

1. 在用户关注关系上，使用拉模式。当用户关注或取消关注其他用户时，更新关注列表和粉丝列表的关系数据。

2. 在用户发布 feed 时，使用推模式。将新发布的 feed 直接推送给所有粉丝的接收队列，并同时更新发布者自己的发布队列。

3. 用户访问个人主页时，先从拉模式中获取关注列表，然后从推模式中获取对应用户的发布队列。这样可以快速获取个人主页的 feed 流。

4. 对于新的粉丝关系，可以在后台异步地将之前发布的 feed 推送给新的粉丝，以保证他们能够看到完整的 feed 流。

这种推拉结合的方式可以减少拉模式中的 IO 集中点，提高性能。同时，通过推模式的写扩散，可以快速将新的 feed 推送给粉丝，提供实时的更新。然而，需要注意的是，这种方式会消耗更多的存储资源，因为每个粉丝都会收到相同的 feed。

记住，这只是一种可能的实现方式，具体的实现还需要根据业务需求和系统架构进行调整和优化。👹👨‍💻


```







feed 流

- redis 里的 feed 数据，怎么分页？
- feed 流多条件查询（redis 实现多条件查询？）？
- feed 的 timeline 怎么推？推模式和拉模式分别怎么实现？推拉结合怎么实现？微博推送消息如何实现？
- feed 流推送怎么实现？在 redis 维护一个当前在线用户的 set，发一条信息的时候就看看关注自己的人那些在线的，然后把信息主动推送到他们的队列中去






### 评论

- ~~多级评论是啥？怎么实现？多级评论的表设计怎么搞？有哪些字段？~~



---

多级评论的表设计怎么搞？有哪些字段？


```shell

CREATE TABLE `comment` (
    `id` varchar(32) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '评论 id',
    `user_id` varchar(32) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '评论人 userId',
    `user_name` varchar(32) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '评论人名称',
    `article_id` varchar(32) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '评论的文章 id',
    `article_title` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT '' COMMENT '评论的文章标题',
    `parent_comment_id` varchar(32) COLLATE utf8mb4_unicode_ci DEFAULT '' COMMENT '父评论 id',
    `parent_comment_user_id` varchar(32) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '父评论的用户 id',
    `reply_comment_id` varchar(32) COLLATE utf8mb4_unicode_ci DEFAULT '' COMMENT '被回复的评论 id',
    `reply_comment_user_id` varchar(32) COLLATE utf8mb4_unicode_ci DEFAULT '' COMMENT '被回复的评论用户 id',
    `comment_level` tinyint(4) NOT NULL DEFAULT '1' COMMENT '评论等级 [ 1 一级评论 默认，2 二级评论]',
    `content` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '评论的内容',
    `status` tinyint(4) NOT NULL DEFAULT '1' COMMENT '状态 (1 有效，0 逻辑删除)',
    `praise_num` int(11) NOT NULL DEFAULT '0' COMMENT '点赞数',
    `top_status` tinyint(4) NOT NULL DEFAULT '0' COMMENT '置顶状态 [ 1 置顶，0 不置顶 默认 ]',
    `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (`id`),
    KEY `idx_article_id` (`article_id`) USING BTREE,
    KEY `idx_user_id` (`user_id`) USING BTREE,
    KEY `idx_create_time` (`create_time`),
    KEY `idx_parent_comment_id` (`parent_comment_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='文章评论表';


```



### 如何设计一个海量的评论系统？（算是比较常见的场景题吧）


- [Golang 进阶 6-评论系统架构设计 - 掘金](https://juejin.cn/post/6907187734696165389)
- [B 站评论系统架构设计 - 哔哩哔哩](https://www.bilibili.com/read/cv20346888)





---



```markdown


应用刚启动连接到数据库的时候比较慢，但又不是慢查询。

1. 这位同学的解决办法是通过 tcpdump 来分析网络包，看网络包的时间戳和网络包的内容，然后找到了具体卡在了哪里。
2. 如果是专业的 DBA 可能会通过 showprocesslist 看具体连接在做什么，比如看到这些连接状态是 authentication
状态，然后再通过 Google 或者对这个状态的理解知道创建连接的时候 MySQL 需要反查 1P、域名这里比较耗时，通过配置参数 skip-name-resolve 跳过去就好了。
3. 如果是 MySQL 的老司机，一上来就知道连接慢的话跟 skip-name-resolve 关系最大。在我眼里这三种方式都解决了问题，最后一种最快但是纯靠积累和经验，换个问题也许就不灵了；第一种方式是最牛逼和通用的，只需要最少的知识就把问题解决了。


我当时跟着他人 sudo、ls 等 Linux 命令开始

```




```markdown

自增 int 作为主键，在以下场景下，会有问题：

1、两个系统对接，id 会出现冲突，数据会被意外覆盖，需要做许多额外的处理工作 2、看 id 很容易猜测出系统中有多少数据，比如有多少笔订单，有多少个用户等等，不安全

3、数据库压力大一点，要分库分表的时候，数据会乱，要重新清洗处理数据，而主键到处用，要清洗好数据难度极大

其实还有一些其他问题，但自增 int 有一个所谓的非常大的好处，性能强劲，但这也仅仅是小库小表的情况下。数据量大一点的时候，是搞不定的。uuid 并不完美，雪花算法也非银弹，完美的东西是不存在的。

```


---


:::tip


对 golang 爬虫不要报太高期待，虽然不好跟其他语言写爬虫直接对比，但是也可以尝试对比一下：

golang 的核心优势还是高效稳定的高并发处理，但是生态缺乏，很多常见问题没有通用解决方案，想解决问题只能靠自己

而 python 和 nodejs 的爬虫生态都更好，常见问题基本都有解决方案，很容易解决，且有各自的杀手锏，scrapy 和 puppeter

总结来说，就是实现层面或者只是临时功能的场景下，python 和 nodejs 有很强的优势，但是在企业级且长期功能的场景下 (很多组件需要自研)，使用 golang 开发会是更好的选择

参考文章：[Python 和 go 爬虫对比哪个好？ - V2EX](https://v2ex.com/t/796117)


:::



---



:::tip

**首先需要注意的是，我们需要的是密码保护，而非 Auth。**

也就是说，游客如果没有密码，则完全无法查看内容，而不是只要注册账号即可查看。

如果只需要 Auth 的话，方案很多，我们用“Docusaurus Auth”作为关键字，可以查到

- AWS Cognito [Protect Custom Routes in Docusaurus using AWS Cognito |](https://iammassoud.net/blog/protect-custom-routes-in-docusaurus-using-aws-cognito)
- Cloudflare Zero Trust [Identity · Cloudflare Zero Trust docs](https://developers.cloudflare.com/cloudflare-one/identity/)
- Google Firebase [使用 Google Firebase 进行 Docusaurus 身份验证 |](https://iammassoud.net/blog/docusaurus-authentication-using-google-firebase)

---

我们也可以直接用 ngin/caddy/traefik 等服务内置的 auth 功能，直接实现该功能。

以 caddy 为例，查看 [Caddy Security](https://authp.github.io/docs/intro) 文档，可以看到，caddy 支持

- Authorization Cookie
- U2F Key
- MFA
- Multi-Factor Authentication
- ... 等常用验证方式



---

如果使用 Netlify Pages 部署服务，Netlify 内置了对网站全站的 password protect 功能，可以直接使用

- [Secure access to sites | Netlify Docs](https://docs.netlify.com/security/secure-access-to-sites/)
- **[Site protection overview | Netlify Docs](https://docs.netlify.com/security/secure-access-to-sites/site-protection/)**

但是我们刚刚把服务从 Netlify 迁移到 Cloudflare，所以就没办法了

Vercel 也支持类似功能

- [Password Protect Docusaurus on Vercel : Docusaurus](https://www.reddit.com/r/Docusaurus/comments/yxvd4c/password_protect_docusaurus_on_vercel/)


:::






## ***接口优化***


:::tip

- database(database service optimize, index, sql, transaction, sharding, etc...refer to "mysql optimize")
- cache(local cache, distributed cache,)
- code(is leak?, concurrence, ...)
- arch(asynchronous, such as MQ, gozero mapreduce...)

:::


---


[这 11 条接口性能优化技巧，利好每日睡眠](https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247495605&idx=1&sn=4d4d4f04a1df44a92d1e1ad046b6a3fb)


```markdown


- 索引
  - 没加索引
  - 索引没生效
  - 选错索引
- sql 优化
- 远程调用
  - 并行调用
  - 数据异构
- 重复调用
  - 循环查数据库
  - 死循环
  - 无限递归
- 异步处理
  - 线程池
  - mq
- 避免大事务
- 锁粒度
  - synchronized
  - redis 分布式锁
  - 数据库分布式锁
- 分页处理
  - 同步调用
  - 异步调用
- 加缓存
  - redis 缓存
  - 二级缓存
- 分库分表
- 辅助功能
  - 开启慢查询日志
  - 加监控
  - 链路跟踪


```





## **[xxx] ES6 语法**



- [ES5 与 ES6 字符串方法总结 - SegmentFault 思否](https://segmentfault.com/a/1190000014117901)
- [最新数组方法（包括 es6） - 热爱前端的 17 号诶 - 博客园](https://www.cnblogs.com/sqh17/p/8529401.html)


```markdown

- arr.push()
- arr.pop()
- arr.shift()
- arr.unshift()
- arr.splice(i,n)
- arr.concat()
- str.split()
- arr.sort()
- arr.reverse()
- arr.slice(start,end)
- arr.forEach(callback)
- arr.map(callback)
- arr.filter(callback)
- arr.every(callback)
- arr.some()
- arr.reduce(callback, initialValue)
- arr.reduce()拓展(高级用法)
- arr.reduceRight(callback, initialValue)
- arr.indexOf()
- arr.lastIndexOf()
- Array.from()
- Array.of()
- arr.copyWithin()
- arr.find(callback)
- arr.findIndex(callback)
- arr.fill(target, start, end)
- arr.includes()
- arr.keys()
- arr.values()
- arr.entries()

```

数组相关的方法就是一些常用操作，更类似php和java数组提供的方法，比golang的slice内置操作友好太多了。



---

- [ES6 语法特性精华 - 简书](https://www.jianshu.com/p/b06f84d5c15e)
- [es6 语法快速上手 - SegmentFault 思否](https://segmentfault.com/a/1190000005742091)




```markdown

ES6 泛指 ES5.1 之后的目前 JS 的标准语法，包括了从 ES2015 到最新规范，每年一版。

let, const,

class, extends, super,

arrow functions,

template string,

destructuring,

default, rest arguments


```

- [ES2015~ES2021 新特性 - SegmentFault 思否](https://segmentfault.com/a/1190000039352300)
- *[ES2019、ES2020、ES2021、ES2022 特性大汇总【2021-12-10 更新】 - 掘金](https://juejin.cn/post/6986087239554072583)*
- *[sudheerj/ECMAScript-features: ECMAScript features cheatsheet](https://github.com/sudheerj/ECMAScript-features)*



---


```markdown

我想快速学习ES相关语法，请告诉我主要的ES语法，从各个方面来说

---

当涉及到学习 ES（ECMAScript）相关语法时，以下是一些主要的 ES 语法方面的内容，可以帮助你快速入门：

**1. 变量声明和赋值**
- 使用 `var`、`let` 或 `const` 声明变量
- 变量赋值和解构赋值

**2. 数据类型**
- 基本数据类型：字符串、数字、布尔值、null、undefined
- 复合数据类型：数组、对象
- 特殊数据类型：Symbol

**3. 函数**
- 使用 `function` 声明函数和箭头函数
- 函数参数和默认参数
- 函数的返回值

**4. 控制流程**
- 条件语句：`if`、`else if`、`else`
- 循环语句：`for`、`while`、`do-while`
- `switch` 语句

**5. 对象和类**
- 对象字面量和属性访问
- 类的定义和继承
- 静态方法和实例方法

**6. 数组操作**
- 数组的创建和访问
- 数组的遍历和操作
- 数组的方法（如 map、filter、reduce 等）

**7. 模块化**
- 使用 `import` 和 `export` 进行模块导入和导出
- 模块的默认导出和命名导出

**8. 异步编程**
- Promise 对象和异步操作
- `async/await` 异步函数

**9. 迭代器和生成器**
- 迭代器和可迭代对象
- 生成器函数和生成器对象

**10. 模板字符串**
- 使用反引号（`）创建模板字符串
- 插入变量和表达式

这些是 ES 中的一些主要语法方面的内容，希望对你快速入门有所帮助。请注意，这只是一个概览，ES 还有更多功能和语法特性可以探索和学习。为了更好地理解和应用这些语法，建议参考官方文档和相关教程，进行更深入的学习和实践。

```


---


```markdown

Please help me compare mocha and jest in js testing? Which is better?

---

Mocha and Jest are both popular JavaScript testing frameworks, but they have some differences. Mocha is a flexible and feature-rich framework that allows you to use any assertion library you prefer. It provides a simple API for writing asynchronous tests and supports various test reporters, making it highly customizable. Mocha also has good support for browser testing.

On the other hand, Jest is a more opinionated framework that aims to provide an all-in-one solution for testing. It comes with built-in mocking, assertion, and code coverage features, making it easier to get started with testing. Jest also has a powerful watch mode that allows you to re-run tests automatically when code changes.

In terms of performance, Jest is known for its fast and parallel test execution, which can be beneficial for large test suites. It also has some unique features like snapshot testing, which can be useful for testing UI components.

Ultimately, the choice between Mocha and Jest depends on your specific needs and preferences. If you value flexibility and customization, Mocha might be a better fit. If you prefer a more opinionated and out-of-the-box solution, Jest could be a good choice.


```

jest确实比之前用过的mocha好用






## Others



[一次监控内存的猜想 - jame_xhs's blog](https://www.jxhs.me/2022/04/10/%E4%B8%80%E6%AC%A1%E7%9B%91%E6%8E%A7%E5%86%85%E5%AD%98%E7%9A%84%E7%8C%9C%E6%83%B3/)

```markdown
有swap情况，明显free > available

没有swap情况available > free

`官网下 linux对内存定义的详细描述，free里面是会算部分的swap进去，但是available没算swap。
```


