---
title: 《MySQL 45讲》读书笔记
slug: /2024/mysql-45-lessons
date: 2024-09-30
---



```markdown
00 开篇词 这一次，让我们一起来搞懂MySQL.md
01 基础架构：一条SQL查询语句是如何执行的？.md
02 日志系统：一条SQL更新语句是如何执行的？.md
03 事务隔离：为什么你改了我还看不见？.md
04 深入浅出索引（上）.md
05 深入浅出索引（下）.md
06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？.md
07 行锁功过：怎么减少行锁对性能的影响？.md
08 事务到底是隔离的还是不隔离的？.md
09 普通索引和唯一索引，应该怎么选择？.md
10 MySQL为什么有时候会选错索引？.md
11 怎么给字符串字段加索引？.md
12 为什么我的MySQL会“抖”一下？.md
13 为什么表数据删掉一半，表文件大小不变？.md

14 count()这么慢，我该怎么办？.md
15 答疑文章（一）：日志和索引相关问题.md
16 “order by”是怎么工作的？.md
17 如何正确地显示随机消息？.md
18 为什么这些SQL语句逻辑相同，性能却差异巨大？.md

19 为什么我只查一行的语句，也执行这么慢？.md
20 幻读是什么，幻读有什么问题？.md
21 为什么我只改一行的语句，锁这么多？.md


22 MySQL有哪些“饮鸩止渴”提高性能的方法？.md
23 MySQL是怎么保证数据不丢的？.md

24 MySQL是怎么保证主备一致的？.md
25 MySQL是怎么保证高可用的？.md
26 备库为什么会延迟好几个小时？.md
27 主库出问题了，从库怎么办？.md
28 读写分离有哪些坑？.md

29 如何判断一个数据库是不是出问题了？.md
30 答疑文章（二）：用动态的观点看加锁.md
31 误删数据后除了跑路，还能怎么办？.md
32 为什么还有kill不掉的语句？.md
33 我查这么多数据，会不会把数据库内存打爆？.md
34 到底可不可以使用join？.md
35 join语句怎么优化？.md
36 为什么临时表可以重名？.md
37 什么时候会使用内部临时表？.md
38 都说InnoDB好，那还要不要使用Memory引擎？.md
39 自增主键为什么不是连续的？.md
40 insert语句的锁为什么这么多？.md
41 怎么最快地复制一张表？.md
42 grant之后要跟着flush privileges吗？.md
43 要不要使用分区表？.md
44 答疑文章（三）：说一说这些好问题.md
45 自增id用完怎么办？.md
我的MySQL心路历程.md
结束语 点线网面，一起构建MySQL知识网络.md
```




## 01 基础架构：一条SQL查询语句是如何执行的？

[01 基础架构：一条SQL查询语句是如何执行的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/01%20%20%e5%9f%ba%e7%a1%80%e6%9e%b6%e6%9e%84%ef%bc%9a%e4%b8%80%e6%9d%a1SQL%e6%9f%a5%e8%af%a2%e8%af%ad%e5%8f%a5%e6%98%af%e5%a6%82%e4%bd%95%e6%89%a7%e8%a1%8c%e7%9a%84%ef%bc%9f.md)

:::tip

从 sql查询语句的执行，引申出 mysql arch（也就是cpoe）

:::



---

如果拿图书馆来类比mysql的话，就很好理解了。假设我们的需求是进入图书馆获取n本符合我们需要的书。

- connector就相当于门卫，只有预约（相当于auth）过才能进入，我们可以通过调整连接数（就是预约人数）来动态调整图书馆的负载。
- parser就相当于图书馆的前台，是把汉语转化成该书的ISBD号等MACS专用信息（将查询语句转换为内部数据结构，相当于compiler），并且提供这些书的位置和路线（提供查询计划）。mysql的parser其实就是compiler，词法分析、语法分析啥的。
- optimizer就相当于优化我们去找到这本书的路线（找到最优路线，提高查询效率）。
- executor则相当于“图书馆操作员”，负责执行优化后的查询计划（也就是带着我们），从图书馆书架（存储引擎）里查找所有需要的数据，这也解释了查询操作关键字的执行顺序，当然要先确定这些书籍的大概区域（也就是FROM），如果需要把这些书按序排列的话，就最后再执行Order这种已经拿到所有书籍之后无关紧要的操作。那中间肯定就是来获取查找这些书了，也就是各种条件（where和groupby/having和select），当然书肯定不需要重复的（也就是Distinct去重操作）。

***如果我们把存储引擎比做图书馆的所有书架的话，表、页、行分别类比成什么呢？*** 表可以类比成图书馆的某个区域，每个区域存放着特定类型的书籍。页可以看作是该区域的某个书架，每个书架上放着一定数量的书籍。行可以类比成某一排书，每一排上放着一本书。

进一步的，我们可以用这些继续类比myisam和innodb，myisam就是每个分类（比如工业技术、交通运输、历史地理等等，具体查看《中国图书馆分类法》）都会有一个单独的目录，并且不允许很多人同时查找（不支持并发查找，也就是不支持事务），进行查找时直接锁表，相应的，我们可以直接通过这个单独的MYI索引文件查找对应的图书，非常快。

InnoDB就灵活的多了，他是以书架为单位进行查找和存储的，所以他的目录（索引）是和某排图书在一起的（相当于每排书一个索引（主键索引），索引id都贴在书架该层的最前面，这时就存在两种情况，一种就是直接查目录（索引）就可以获得数据，不需要再查数据表，这个就是“索引覆盖”（或者说Index Dive，都是类似意思）。如果目录中查不到我们需要的数据，就需要“回表”了，那么我们根据索引id来看需要的书是不是在这排（再多说一句，这也是为什么主键id最好单调递增的原因））。他是支持多人同时查找的。并且在读写操作时只锁定某排书（也就是行级锁定），粒度更细，这样就更能频繁地执行读操作和写操作。

***需要注意的是mysql还支持同时使用多种存储引擎***，也就是说在图书馆里如果有一些冷门分类，很少有新书入库的，那就用myisam这种类型的管理方式，如果非常热门的分类，每天都有很多用户来买书，每天书店也需要频繁补货的，就应该用innodb。当然，如果我们把mysql看作是图书馆的话，不同图书馆的特性（规矩、规章制度）也不同，比如说oracle或者sql server这种的就比较死板，图书馆开店营业之前就定好了所有书架的管理模式（也就是存储引擎），之后再也不能修改，更不存在说不同分类使用不同的管理模式一说了。

另外，还需要注意一个问题，编织目录（索引）的具体方法和该“图书分类”（存储引擎）的映射关系。众所周知，对于不同图书分类也应该使用不同的方式来编写目录。比如说R树适用于myisam（也有B+Tree），hash适用于memory，B+Tree则适用于InnoDB。





:::tip

```yaml
- "***mysql 的查询语句的具体执行？比如 sql 语句有 select from where orderby，为啥查询语句执行的先后顺序是 FWG(H)SDO (from-where-group by-having-select-order by)？***"


```




:::











## 02 日志系统：一条SQL更新语句是如何执行的？

[02 日志系统：一条SQL更新语句是如何执行的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/02%20%20%e6%97%a5%e5%bf%97%e7%b3%bb%e7%bb%9f%ef%bc%9a%e4%b8%80%e6%9d%a1SQL%e6%9b%b4%e6%96%b0%e8%af%ad%e5%8f%a5%e6%98%af%e5%a6%82%e4%bd%95%e6%89%a7%e8%a1%8c%e7%9a%84%ef%bc%9f.md)

```markdown
分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。
```

还是从cpoe入手，parser经过lexical analysis知道是更新语句，executor负责执行具体的更新操作

```markdown
与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。
```
redolog和binlog，2PC

因为更新操作涉及到一致性问题（以及分布式下的一致性问题），本质上是DT的2PC方案


```markdown
不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。

如果有人要赊账或者还账的话，掌柜一般有两种做法：

一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；
另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。
在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。

这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？

同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。

而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。

具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。

与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。
```

![redolog.png](img/mysql-45-lessons/redolog.png)

```markdown
write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。

要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。
```


这个粉板和账本的类比很恰当。

redolog就是粉板，




:::tip

[//]: # (TODO x)


结合 [庖丁解InnoDB之REDO LOG | CatKang的博客](https://catkang.github.io/2020/02/27/mysql-redo.html)

所以这段内容就解决了以下问题：

```yaml
- redolog 是啥？为什么需要记录 redolog？
- 需要什么样的 redolog？
- redolog 中记录了什么内容？
- redolog 是怎么组织的？
- 如何高效地写 redolog？
- 如何安全地清除 redolog？
- "***checkpoint是啥? 只跟redolog 相关吗? 跟其他日志有关吗?***"
```

*undolog是逻辑日志，redolog是物理日志。但是redolog是由undolog产生的*

redolog其实就是WAL，通过先记录日志再写入数据的方式，确保了事务的持久性，并通过Checkpoint技术有效管理了日志空间和恢复时间

为了获得更好的读写性能，innoDB 将数据缓存到内存 (innoDB Buffer Pool)，对磁盘数据的修改也会落后于内存，如果进程崩溃就会导致内存数据丢失，所以 innoDB 就维护了 redolog，内存数据丢失后，innoDB 会在重启时，通过重放 REDO，恢复数据



如何安全地清除 redolog?

其实就是刷盘操作（当然还有其他刷盘操作，具体的触发条件、执行方式和优化策略不同，比如同步写入、异步写、定时写等等）

用来把内存中的脏页（尚未写入磁盘的修改数据页）写入磁盘，并更新相关的日志信息，这个操作是为了保证数据的一致性，以防止系统崩溃时数据丢失。

- sharp checkpoint: mysql关闭时，会触发把所有的脏页都刷入到磁盘上
- fuzzy checkpoint: mysql运行时，部分刷入磁盘

:::







## 12 为什么我的MySQL会“抖”一下？

[12 为什么我的MySQL会“抖”一下？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/12%20%20%e4%b8%ba%e4%bb%80%e4%b9%88%e6%88%91%e7%9a%84MySQL%e4%bc%9a%e2%80%9c%e6%8a%96%e2%80%9d%e4%b8%80%e4%b8%8b%ef%bc%9f.md)









## 03 事务隔离：为什么你改了我还看不见？

[03 事务隔离：为什么你改了我还看不见？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/03%20%20%e4%ba%8b%e5%8a%a1%e9%9a%94%e7%a6%bb%ef%bc%9a%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%a0%e6%94%b9%e4%ba%86%e6%88%91%e8%bf%98%e7%9c%8b%e4%b8%8d%e8%a7%81%ef%bc%9f.md)







## 06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？


[06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/06%20%20%e5%85%a8%e5%b1%80%e9%94%81%e5%92%8c%e8%a1%a8%e9%94%81%20%ef%bc%9a%e7%bb%99%e8%a1%a8%e5%8a%a0%e4%b8%aa%e5%ad%97%e6%ae%b5%e6%80%8e%e4%b9%88%e6%9c%89%e8%bf%99%e4%b9%88%e5%a4%9a%e9%98%bb%e7%a2%8d%ef%bc%9f.md)



## 07 行锁功过：怎么减少行锁对性能的影响？



## 08 事务到底是隔离的还是不隔离的？


[08 事务到底是隔离的还是不隔离的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/08%20%20%e4%ba%8b%e5%8a%a1%e5%88%b0%e5%ba%95%e6%98%af%e9%9a%94%e7%a6%bb%e7%9a%84%e8%bf%98%e6%98%af%e4%b8%8d%e9%9a%94%e7%a6%bb%e7%9a%84%ef%bc%9f.md) 这章就是MVCC相关了














## index




[//]: # (TODO index bptree)


```yaml

    - q: innodb索引树的高度由什么决定?
      u: https://www.bilibili.com/video/BV1jb421e7iS/
      x: 单条数据的大小会影响索引树的高度。bptree是由16k的page组成的，非叶子node只存index，叶子node存储index和数据本身。

```

[面试爱问的MySQL索引，一个动画就了解了！ - YouTube](https://www.youtube.com/watch?v=93f0xoqR2aU)



### index 创建原则

```yaml
- 左选小写修（最左前缀索引、选择性、小字段、写操作频率、修改索引） # 最主要的索引创建原则其实就是最左前缀和选择性。除此之外就是一些tips，比如什么查询频率、写操作频率（更新非常频繁的字段不适合创建索引）、小字段（对于大的文本字段甚至超长字段，不要建索引）、反向开闭（用修改代替新增）之类的
- 在什么情况下会使用最左前缀?
- 最左前缀的本质是啥? # “最左前缀”实际上就是前缀索引在复合索引场景下的使用，也就是说，复合索引中field顺序也要按照“index创建原则”来排序。最左前缀的本质就是ICP，ICP只在满足"最左前缀"条件时起作用。如果查询条件中包含了索引的非最左前缀列，ICP将无法生效，MySQL会在存储引擎层面进行完整的行过滤，这可能会导致性能下降。总结来说，"最左前缀"原则和ICP的本质是基于索引列的前缀进行索引范围扫描，以减少需要访问的行数，提高查询性能。
- Index选择性是啥?  # 就是字段不重复的比例 `count(distinct col)/count(*)`（不重复的索引值（也称为基数 cardinality) 和数据表的记录总数的比值），区间为`(0,1]`，***识别度越高，扫描相同行数，需要的次数就越少，这是由 B+ 树的性质决定的***
- 前缀索引、 ***尽量使用前缀来索引，如果索引字段的值很长，最好使用值的前缀来索引*** 例如，TEXT 和 BLOG 类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度

```






### 09 普通索引和唯一索引，应该怎么选择？

[09 普通索引和唯一索引，应该怎么选择？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/09%20%20%e6%99%ae%e9%80%9a%e7%b4%a2%e5%bc%95%e5%92%8c%e5%94%af%e4%b8%80%e7%b4%a2%e5%bc%95%ef%bc%8c%e5%ba%94%e8%af%a5%e6%80%8e%e4%b9%88%e9%80%89%e6%8b%a9%ef%bc%9f.md) 开篇抛出来的问题好啊，很常见的应用场景，身份证号要加unique index还是index。这种场景我一直是加唯一索引的。但是本文通过读操作和写操作两种场景，尤其是时写操作下change buffer机制对index的优化。




### 10 MySQL为什么有时候会选错索引？

[10 MySQL为什么有时候会选错索引？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/10%20%20MySQL%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e6%97%b6%e5%80%99%e4%bc%9a%e9%80%89%e9%94%99%e7%b4%a2%e5%bc%95%ef%bc%9f.md)



### 11 怎么给字符串字段加索引？


```markdown
在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：

直接创建完整索引，这样可能比较占用空间；
创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。


在实际应用中，你要根据业务字段的特点选择使用哪种方式。

```

这章很实用啊














## mysql replication


### 23 MySQL是怎么保证数据不丢的？

[23 MySQL是怎么保证数据不丢的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/23%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e6%95%b0%e6%8d%ae%e4%b8%8d%e4%b8%a2%e7%9a%84%ef%bc%9f.md)



redolog和binlog是mysql最核心的两个日志，“只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复”，***如果想实现replication，首先就要确保redolog能够写入磁盘***


```markdown
其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。

可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。

图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。
```

![binlog-write.png](img/mysql-45-lessons/binlog-write.png)
<center>*binlog写入机制*</center>


---

redolog写入机制





:::tip

```yaml

```

总结：

这章讲的是binlog和redolog的写入机制

- binlog写入机制：正如上图所示，***分为事务执行和事务提交两部分，事务提交之后就是write+fsync，而事务执行可以理解为大文件分片上传，有个组装逻辑***，事务执行时把日志写入binlog cache，事务提交时，executor吧binlog cache里的完整事务写入binlog（就是write），再fsync到disk
- redolog写入机制

:::







### 24 MySQL是怎么保证主备一致的？]

[24 MySQL是怎么保证主备一致的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/24%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e4%b8%bb%e5%a4%87%e4%b8%80%e8%87%b4%e7%9a%84%ef%bc%9f.md)



![replication.png](img/mysql-45-lessons/replication.png)



这章都是一些binlog相关的基础知识，


:::tip

```yaml
- binlog 有哪些日志格式？
- binlog的刷盘时机（什么时候把 binlog 从内存刷到磁盘）？

```


- `mixd`，*mix 是 statement 和 row 的混合。正常而言都是用 statement 来存，但是像主从这种没有逻辑的则用 row 格式来存*
- `statement`，每一条会修改数据的 sql 都会记录在 binlog 中
- `row`，binlog 中可以不记录执行的 sql 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了

---

binlog 的刷盘时机？什么时候把 binlog 从内存刷到磁盘？(跟 redis 的 sync 机制类似)



mysql 用`sync_binlog`参数控制 binlog 的刷盘时机，默认设置为 1

- 0：不去强制要求，由系统自行判断何时写入磁盘
- 1：每次 commit 的时候都要将 binlog 写入磁盘，最安全的设置
- N：每 N 个事务，才会将 binlog 写入磁盘


:::




### 25 MySQL是怎么保证高可用的？

[25 MySQL是怎么保证高可用的？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/25%20%20MySQL%e6%98%af%e6%80%8e%e4%b9%88%e4%bf%9d%e8%af%81%e9%ab%98%e5%8f%af%e7%94%a8%e7%9a%84%ef%bc%9f.md) 这章就是讲 replication lagging 了








:::tip


:::





### 26 备库为什么会延迟好几个小时？


[26 备库为什么会延迟好几个小时？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/26%20%20%e5%a4%87%e5%ba%93%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bc%9a%e5%bb%b6%e8%bf%9f%e5%a5%bd%e5%87%a0%e4%b8%aa%e5%b0%8f%e6%97%b6%ef%bc%9f.md)


:::tip

:::




### 27 主库出问题了，从库怎么办？










### 28 读写分离有哪些坑？



[28 读写分离有哪些坑？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/28%20%20%e8%af%bb%e5%86%99%e5%88%86%e7%a6%bb%e6%9c%89%e5%93%aa%e4%ba%9b%e5%9d%91%ef%bc%9f.md)



```markdown
接下来，我们就看一下客户端直连和带 proxy 的读写分离架构，各有哪些特点。

1. 客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。 你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。
2. 带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。
理解了这两种方案的优劣，具体选择哪个方案就取决于数据库团队提供的能力了。但目前看，趋势是往带 proxy 的架构方向发展的。

但是，不论使用哪种架构，你都会碰到我们今天要讨论的问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。

这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。

前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能 100% 避免的。

不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。

接下来，我们就来讨论怎么处理过期读问题。

这里，我先把文章中涉及到的处理过期读的方案汇总在这里，以帮助你更好地理解和掌握全文的知识脉络。这些方案包括：

- 强制走主库方案；
- sleep 方案；
- 判断主备无延迟方案；
- 配合 semi-sync 方案；
- 等主库位点方案；
- 等 GTID 方案。
```





[gtid](http://mysql.taobao.org/monthly/2020/05/09/)


:::danger






:::





### 29 如何判断一个数据库是不是出问题了？

[29 如何判断一个数据库是不是出问题了？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/29%20%20%e5%a6%82%e4%bd%95%e5%88%a4%e6%96%ad%e4%b8%80%e4%b8%aa%e6%95%b0%e6%8d%ae%e5%ba%93%e6%98%af%e4%b8%8d%e6%98%af%e5%87%ba%e9%97%ae%e9%a2%98%e4%ba%86%ef%bc%9f.md)













## 其他



### 13 为什么表数据删掉一半，表文件大小不变？

[13 为什么表数据删掉一半，表文件大小不变？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/13%20%20%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a1%a8%e6%95%b0%e6%8d%ae%e5%88%a0%e6%8e%89%e4%b8%80%e5%8d%8a%ef%bc%8c%e8%a1%a8%e6%96%87%e4%bb%b6%e5%a4%a7%e5%b0%8f%e4%b8%8d%e5%8f%98%ef%bc%9f.md)


### 14 count()这么慢，我该怎么办？

[14 count()这么慢，我该怎么办？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/14%20%20count%28%29%e8%bf%99%e4%b9%88%e6%85%a2%ef%bc%8c%e6%88%91%e8%af%a5%e6%80%8e%e4%b9%88%e5%8a%9e%ef%bc%9f.md)







### 31 误删数据后除了跑路，还能怎么办？


### 32 为什么还有kill不掉的语句？



### 33 我查这么多数据，会不会把数据库内存打爆？



### 34 到底可不可以使用join？


### 35 join语句怎么优化？



### 36 为什么临时表可以重名？



### 37 什么时候会使用内部临时表？






### 38 都说InnoDB好，那还要不要使用Memory引擎？

[38 都说InnoDB好，那还要不要使用Memory引擎？](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/38%20%20%e9%83%bd%e8%af%b4InnoDB%e5%a5%bd%ef%bc%8c%e9%82%a3%e8%bf%98%e8%a6%81%e4%b8%8d%e8%a6%81%e4%bd%bf%e7%94%a8Memory%e5%bc%95%e6%93%8e%ef%bc%9f.md)

```markdown
可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：

- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
- 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。

---
从中我们可以看出，这两个引擎的一些典型不同：

- InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
- 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
- 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
- InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
- InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

```

:::tip

这里延伸出的问题：

***heap table(堆表), IOT(索引组织表Index Organization Table), HOT(Heap Organized Table) 的区别***

- heap table: pgsql, mysql memory
- IOT: mysql innodb
- HOT: mysql myisam

oracle中既支持堆表，也支持IOT

:::


```markdown

Innodb的PAGE结构与HEAP结构的类似，不过在空闲空间管理上是完全不同的。前面是FILE HEADER/PAGE HEADER，中间是数据记录，数据记录也是从低地址往高地址写，和Oracle相反。这是因为BTREE存储结构不需要和slotted page一样，在块里放一个指示器，其行指示器的功能被BTREE替代了。

Innodb的这种存储结构，并不存在一个十分友好的类似Oracle的记录物理地址的ROWID这样的结构。所以要想定位某条数据记录，需要使用主键或者簇主键的方式来实现。主键可以定义某条记录的唯一性地址，因此Mysql的某张表上的其他索引(secondary index)的索引中存储的键值不像Oracle那样存储ROWID就可以了，而是存储的是主键中这一行的地址指针。基于一个secondary index的查询首先找出某些行的主键，然后再去扫描一次主键索引，才能找到相关行的地址，再找到这条记录。比起有rowid的Oracle数据库，这里多了一次主键索引的扫描。

可能有些朋友会觉得，是不是heap结构一定优于BTREE结构呢?其实还是回到今天的标题，没有完美的存储引擎。针对不同的应用场景，heap和BTREE各有优势。BTREE结构写入数据时按主键排序的，而且并发写入时数据并不是按照插入顺序写入数据块，如果主键存在一定的无序性，那么并发写入的数据可以被打散到多个块中，从而缓解热块冲突的压力。而二级索引的结构虽然对读取数据的操作有影响，对于存在多条索引的数据写入，数据修改，是有优势的。因为只要主键的键值不变，行数据的变化，行在数据块中存储的变化，不需要变更第二索引。

因此我们可以十分明确的肯定，不同的存储结构都各有利弊，并不能很直接的说哪种更好。不过在开发高并发，大数据量的系统的时候，了解存储引擎的一些特点，可以有效的避免一些问题。比如在Mysql、达梦等数据库中建表，尽可能定义一个显式的主键，从而避免系统自动添加主键。另外如果某张表的热块冲突特别严重的时候，主键可以考虑选择随机性的数据，而不是单边增长的数据，就可以有效的进行数据打散，从而降低热块冲突的可能性。

```



```markdown
Heap表，即使用MEMORY存储引擎的表，这种表的数据存储在内存中，由于硬件问题或者断电，数据容易丢失，所以只能从其他数据表中读取数据作为临时表或者只读缓存来使用。
```

storage, transaction, persist 几个方面




### 39 自增主键为什么不是连续的？

这个问题在之前看 [为什么 MySQL 的自增主键不单调也不连续 - 面向信仰编程](https://draveness.me/whys-the-design-mysql-auto-increment/) 时，就大概了解。

我先简要写下我目前的回答：

主键自增很重要，是为了保证使用bptree（innodb）能够尽量顺序写，避免页分裂嘛。但是在mysql8之前，auto_increment都是直接存在内存里的，如果mysql挂了重启，这个数据就没了。会重新根据主键id+1，重新获取auto_increment值，





### 41 mysql 数据复制


### 42 grant之后要跟着flush privileges吗？


### 43 分区表有什么问题，为什么公司规范不让使用分区表呢？



### 45 自增id用完怎么办？


```markdown
今天这篇文章，我给你介绍了 MySQL 不同的自增 id 达到上限以后的行为。数据库系统作为一个可能需要 7*24 小时全年无休的服务，考虑这些边界是非常有必要的。

每种自增 id 有各自的应用场景，在达到上限后的表现也不同：

- 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
- row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
- Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
- InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
- thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。

当然，在 MySQL 里还有别的自增 id，比如 table_id、binlog 文件序号等，就留给你去验证和探索了。
```














## [2024-09-29] 补充










